---
title: 'Practice Final'
author: "Moretz_Brandon"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  pdf_document:
    toc: yes
  html_document:
    df_print: paged
    theme: spacelab
    toc: yes
    toc_float: yes
---

```{r additional-libraries, echo=FALSE}

library(data.table, quietly = TRUE, warn.conflicts = FALSE)

assignInNamespace("cedta.pkgEvalsUserCode", c(data.table:::cedta.pkgEvalsUserCode, "rtvs"), "data.table")

library(dplyr, quietly = TRUE, warn.conflicts = FALSE)
library(ggplot2, quietly = TRUE, warn.conflicts = FALSE)
library(ggthemes, quietly = TRUE, warn.conflicts = FALSE)
library(gridExtra, quietly = TRUE, warn.conflicts = FALSE)
library(kableExtra, quietly = TRUE, warn.conflicts = FALSE)

theme_set(theme_light())

# Theme Overrides
theme_update(plot.title = element_text(hjust = 0.5),
			 axis.text.x = element_text(size = 10),
			 axis.text.y = element_text(size = 10),
			 axis.title = element_text(face = "bold", size = 12, colour = "steelblue4"),
			 legend.position = "top", legend.title = element_blank())

pretty_kable <- function(data, title, dig = 2) {
  kable(data, caption = title, digits = dig, big.mark = "'") %>%
    kable_styling(bootstrap_options = c("striped", "hover"))
}

pretty_vector <- function(vec, label = "") {
  pander::pander(vec)
}

```

Notes:

__Procedure Used to Test for Significance__

Whenever we perform a significance test, it involves comparing a test value that we have calculated to some critical value for the statistic. It doesn't matter what type of statistic we are calculating (e.g., a t-statistic, a chi-square statistic, an F-statistic, etc.), the procedure to test for significance is the same.

+ Decide on the critical alpha level you will use (i.e., the error rate you are willing to accept).
+ Conduct the research.
+ Calculate the statistic.
+ Compare the statistic to a critical value obtained from a table.

__If your statistic is higher than the critical value from the table:__ _Your finding is significant._

+ You reject the null hypothesis.
+ The probability is small that the difference or relationship happened by chance, and __p is less than the critical alpha level (p < alpha ).__

__If your statistic is lower than the critical value from the table:__ _Your finding is not significant._

+ You fail to reject the null hypothesis.
+ The probability is high that the difference or relationship happened by chance, and __p is greater than the critical alpha level (p > alpha ).__

_See Example __#16__ for an example_

## 1.) Combinations and Permutations

Suppose that a class of 30 students is assigned to write an essay.

a. Suppose 4 essays are randomly chosen to appear on the class bulletin board. How many different groups of 4 are possible? Selection order is not important.
b. Suppose 4 essays are randomly chosen for awards of $10, $7, $5 and $3. How many different groups of 4 are possible? Selection order is important.
c. Explain the differences between problems 1 and 2.


```{r q1}

pretty_vector( c("a.)" = choose(30, 4) ))

pretty_vector(c("b.)" = choose(30, 4) * factorial(4)))

```

__c.)__ Item __(a)__ asks for the combinations or groups of four possible. There isn't a sense
in which the order of the four essays selected is meaningful. Item __(b)__ asks for the
permutations possible when four are selected from 30. Here, there is a meaningful
difference in the order - i.e. prizes awarded - of the four selected. 

## 2.) Basic Stats

For the given probability distribution, find the mean, variance, standard deviation, median and mode.

```{r q2_setup, echo = F}

x <- c(0, 1, 2, 3, 4)
P.x <- c(0.37, 0.12, 0.06, 0.15, 0.30)

q2_data <- data.frame(rbind(x,P.x))
rownames(q2_data) <- c("x", "P(x)")
colnames(q2_data) <- rep("", ncol(q2_data))

pretty_kable(q2_data, "Probabilities")

```

```{r q2}

ev <- sum(x * P.x)
var <- sum(P.x * (x - ev) ^ 2)
sd <- sqrt(var)
med <- 2 # look at the cdf
mode <- x[P.x == max(P.x)]

```


```{r q2_display, echo = F}

    pretty_vector(c("Mean" = ev, "Variance" = var, "Standard Deviation" = sd, "Median" = med, "Mode" = mode))
    plot(x, cumsum(P.x), main = "cdf for P.x", type = "h", ylim = c(0, 1.0))
    abline(h = 0.5, col = "red")

```

## 3.) Normal Probability

For a standard normal distribution, find the percentage of data that are __more than 2 standard
deviations below the mean__ _or_ __more than 3 standard deviations above the mean__.

+ __a.) 2.41%__
+ b.) 0.26% 
+ c.) 4.56%
+ d.) 97.59%

```{r q3_display, echo = F}

area <- 1 - (pnorm(2) - pnorm(3, lower.tail = F))

ggplot(data.table(X = seq(-4, 4, length = 2000 )), aes(x = X)) +
	stat_function(fun = dnorm) +
	stat_function(fun = dnorm, xlim = c(-4, -2), geom = "area", fill = "steelblue") +
	stat_function(fun = dnorm, xlim = c(4, 3), geom = "area", fill = "steelblue") +
    labs(title = paste("AUC = ", round(area, 5) * 100 ))

```

```{r q3, echo = F}

pretty_vector( c( Probability = round( pnorm(-2, 0, 1, lower.tail = TRUE) + pnorm(3, 0, 1, lower.tail = FALSE), 5) * 100 ))

```

## 4.) Bayes' Therom

Use the results summarized in the table. One of the 100 test subjects is selected at random. If the person approves of the Mayor, what is the probability that they vote Democrat? Use Bayes’ theorem.

+ a.) 0.674
+ b.) 0.581
+ c.) 0.391
+ __d.) 0.545__

```{r q4_setup, echo = F}

q4_data <- data.frame(rbind(
	c(8, 17),
	c(18, 13),
	c(7, 37)))

rownames(q4_data) <- c("Republican", "Democrat", "Independent")
colnames(q4_data) <- c("Approve of Mayor", "Do not approve of Mayor")

pretty_kable(q4_data, "Votes")

```

```{r q4}

# We know the person approves of the Mayor. Let's look at only those individuals.
# Of the "Mayor approvers," 18 vote Democrat.

pretty_vector( c( ShortWay = 18 / (8 + 18 + 7) ))# [1] 0.5454545

# Long Way

n <- sum(q4_data)

p.approve <- sum( q4_data[,1] ) / n
p.disaprove <- 1 - p.approve

p.democrat <- sum(q4_data[2,]) / n
p.not_democrat <- 1 - p.democrat

p.democrat.approves <- 18 / sum( q4_data[2,] )
p.not_democrat.approves <- sum(q4_data[c(1, 3), 1]) / sum( q4_data[c(1,3),] )

q4 <- (p.democrat * p.democrat.approves) / ((p.democrat * p.democrat.approves) + (p.not_democrat * p.not_democrat.approves))

pretty_vector(c(LongWay = q4))

```

## 5.) Chi-Squared Test

Use the results summarized in the table above and test at the 5% level if party affiliation and approval of the Mayor are independent of each other using Pearson’s Chi-square test of independence.

+ __a.) df = 2, p-value > 0.05, don’t reject__
+ b.) df = 2, p-value < 0.05, reject
+ c.) df = 5, p-value < 0.05, don’t reject
+ d.) df = 5, p-value > 0.05, reject

```{r q5}

alpha <- 0.05

approve <- c(8, 18, 7)
not.approve <- c(17, 13, 37)
vote <- cbind(approve, not.approve)

results <- chisq.test(vote, correct = FALSE)

```


```{r q5_results, echo = F}
pretty_vector(c("p-value" = round( results$p.value, 3 ) ))
pretty_vector(c("p-value Result" = ifelse(results$p.value < alpha, "Fail to Reject", "Reject")))
```

## 6.) Basic Stats #2

A police department states that the probabilities for 0, 1, 2, and 3 burglaries reported in a given day are 0.46, 0.41, 0.09, and 0.04, respectively. 

+ Find the mean, variance, standard deviation, median and mode. Round the answer to the nearest hundredth.

```{r q6}

x <- c(0, 1, 2, 3)
P.x <- c(0.46, 0.41, 0.09, 0.04)

ev <- sum(P.x * x)
var <- sum(P.x * (x - ev) ^ 2)
sd <- sqrt(var)
med <- 1

mode <- x[ P.x == max(P.x) ]

```

```{r q6_display, echo = F}

    pretty_vector(c("Mean" = ev, "Variance" = var, "Standard Deviation" = sd, "Median" = med, "Mode" = mode))
    plot(x, cumsum(P.x), main = "cdf for P.x", type = "h", ylim = c(0, 1.0))
    abline(h = 0.5, col = "red")

```

## 7.) Uniform Distribution

Assume weight loss for the first month of a diet program varies between 6 pounds and 12 pounds, and is spread evenly forming a uniform distribution. 

+ Find the probability of losing between 8.5 and 10 pounds. 
+ Also, find the probability of losing between 10 and 14 pounds. 

_Round to two decimal places._

+ __A.) 1/4 and 1/3__
+ B.) 1/2 and 2/3 
+ C.) 1/3 and 1/3 
+ D.) 1/4 and 2/3

```{r q7}

punif(10, 6, 12, lower.tail = T) - punif(8.5, 6, 12, lower.tail = T)

punif(10, 6, 12, lower.tail = F)

```

```{r q7_display, echo = F}

ggplot(data.table(X = seq(6, 12, length = 2000)), aes(x = X)) +
	stat_function(fun = dunif)
```

## 8.) Z-Score (Normal)


Find the indicated z-score. 

The graph depicts the standard normal distribution with mean equal 0 and standard deviation equal 1 with a shared area of 0.0901.

+ __a.) -1.34__ 
+ b.) -1.26
+ c.) -1.39 
+ d.) -1.45


```{r q8_setup, echo = F}

q8_prob <- .0901
q8_area <- qnorm(q8_prob)

ggplot(data.table(X = seq(-4, 4, length = 2000)), aes(x = X)) +
	stat_function(fun = dnorm) +
	stat_function(fun = dnorm, xlim = c(-4, q8_area), geom = "area", fill = "steelblue") +
	geom_text(aes(x = q8_area + .5, y = .05), label = q8_prob) +
    labs( title = paste( "Z-Score:", round(q8_area,2) ))

```

```{r q8}

pretty_vector(c("Z-Score" = qnorm(q8_prob)))

```

## 9.) Binomial and Poisson

Here are two discrete probability distributions: dist_A and dist_B. 

By construction each may be either a binomial or a Poisson distribution. 

The mean and variance for dist_A are 5.00 and 5.00. The mean and variance for dist_B are 5.00 and 3.33. 

_Pick the best answer._

+ __a.) Dist_A is Poisson, Dist_B is binomial.__
+ b.) Dist_A is binomial, Dist_B is Poisson.
+ c.) Both are Poisson
+ d.) Both are binomial

```{r q9}
x <- seq(0, 15)
dist_A <- round(dpois(x, 5), digits = 4)
dist_A[16] <- 0.0003
dist_B <- round(dbinom(x, 15, 1 / 3), digits = 4)
plot(x, dist_A, type = "b", ylim = c(0, 0.25), col = "red", ylab = "probability",
	 lwd = "2", main = "Plot of Two Discrete Probability Distributions")
lines(x, dist_B, col = "green", lwd = "2", type = "b")
legend("topright", legend = c("dist_A is red", "dist_B is green"))

# Solution
mean_A <- round(sum(x * dist_A), digits = 2) # [1] 5.0003
variance_A <- round(sum(dist_A * (x - mean_A) ^ 2), digits = 2) #  [1] 5.0019
mean_B <- round(sum(x * dist_B), digits = 2) #  [1] 4.9995
variance_B <- round(sum(dist_B * (x - mean_B) ^ 2), digits = 2) #  [1] 3.332
mean_A
variance_A
mean_B
variance_B

#  dist_A is Poisson.  The variance equals the mean, whereas dist_B is Binomial.
#  The variance is less than the mean, i.e., n*p > n*p*(1-p).  p = 1/3.

```

## 10.) Normal Approximation

This problem involves estimating probabilities for a binomial variable X with p = 0.4 and n = 15. 

Use the normal approximation with continuity correction to estimate the probabilities for the following three outcomes; X = 0, X = 6 and X >= 10. 

_Select the best answer from the following choices:_

__Note:__

Normal approximation to the binomial uses *z = (x - n*p)/sqrt(n * p * (1-p))*

```{r q10_setup, echo = F}

q10_data <- data.frame(rbind(
    c(0.0011, 0.2071, 0.0340),
	c(0.0019, 0.2079, 0.0325),
	c(0.0014, 0.2103, 0.0227),
	c(0.0008, 0.2079, 0.0175)))

rownames(q10_data) <- c("A", "B", "C", "D")
colnames(q10_data) <- c("P[X = 0]", "P[X = 6]", "P[X >= 10]")

pretty_kable(q10_data, "Answer Choices", dig = 4)

```

```{r q10}

x <- seq(0, 15)
n <- 15
p <- .4

m <- which.max(dbinom(x, n, p)) # midpoint

exp <- n * p
std <- exp * (1 - p)

# 0
p_0 <- pnorm((0 - exp + 0.5) / sqrt(std), 0, 1, lower.tail = TRUE)

# 6
p_6 <- pnorm(((m - 1) - exp + 0.5) / sqrt(std), 0, 1, lower.tail = TRUE) -
	pnorm(((m - 1) - exp - 0.5) / sqrt(std), 0, 1, lower.tail = TRUE)

# 10
p_tg10 <- pnorm(10 - 0.5, n * p, sqrt(n * p * (1 - p)), lower.tail = FALSE)

```

```{r q10_display, echo = F}

# Results
pretty_vector(c("Prob = 0" = round(p_0, 4), "Prob = 6" = round(p_6, 4), "Prob >= 10 " = round(p_tg10, 4)))

prob.norm <- function(x) {
	pnorm(((x) - exp + 0.5) / sqrt(std), 0, 1, lower.tail = TRUE) -
	pnorm(((x) - exp - 0.5) / sqrt(std), 0, 1, lower.tail = TRUE)
}

plot(x, dbinom(x, n, p))
lines(x - 0.5, prob.norm(x), col = "red", type = "s")
abline(v = m - 1)

```

## 11.) Power Test

True or False: in a hypothesis test, an increase in alpha will cause a decrease in the power of the test provided the sample size is kept fixed.

+ a.) True 
+ __b.) False__

__FALSE__. 

> The power of a test - the probability of rejecting the null hypothesis when
the alternative hypothesis is true - decreases as a function of beta; the probability
of failing to reject the null hypothesis when the alternative hypothesis is true. An
increase in alpha will decrease beta, thus increasing power. 

_However, please remember that alpha and beta aren't symmetric and we won't try to control one via the other._

## 12.) Type II Error with Means

True or False: in a hypothesis test regarding a population mean, the probability of a type II error, beta, depends on the true value of the population mean.

+ __a.) True__
+ b.) False

__TRUE__. 

> The probability of a type II error - failure to reject a false null
hypothesis - is dependent on the "true value" of the test statistic. In a broad 
sense, either type error will have some relationship with the true mean. However, 
alpha is much more directly related to the test statistic - the probability 
associated with our data given the null hypothesis. Power, however, is related 
directly to the difference between the true and hypothesized mean and how easily, 
how "powerfully" we can resolve smaller and smaller differences between the true 
and hypothetical mean.

## 13.) Hypothesis Test Sample Size

True or False: in a hypothesis test regarding a population mean, if the sample size is increased and the probability of a type II error is fixed and does not change then the type I error rate does not change.

+ A.) True 
+ __B.) False__

__FALSE__. 

> Keeping the power the same, an increase in sample size provides more data 
for the statistical test making it less likely that a type I error will occur.  

## 14.) Hypothesis Test Mean Errors

True or False: in a hypothesis test regarding a population mean, if the sample size is increased and the probability of a type I error is fixed and does not change then the type II error rate will decrease.

+ A.) True 
+ B.) False

__TRUE__. 

> With alpha constant, an increase in sample size provides more data for the 
statistical test increasing the power.  Thus it less likely that a type II error 
will occur.

## 15.) Hypothesis Tests

Suppose that you perform a hypothesis test regarding a population mean, and that the evidence does not warrant rejection of the null hypothesis. 
When formulating the conclusion to the test, why is phrase “fail to reject the null hypothesis” more accurate than the phrase “accept the null hypothesis?”

> A hypothesis test does not "prove" the null hypothesis. Rather, it is meant to determine
whether or not there is sufficient evidence to reject it. Insufficient evidence does not
validate the null hypothesis; it just leaves us without grounds for rejecting it.

## 16.) Identify Test

_Identify the null hypothesis, alternative hypothesis, test statistic, p-value, conclusion about the null hypothesis, and the final conclusion that addresses the original claim._

> According to a recent poll, 53% of Americans would vote for the incumbent president. If a random sample of 100 people results in 45% who would vote for the incumbent, 
test the claim that the actual percentage is 53%. Use a 0.10 significance level.

+ H0:  p  = 0.53  (null hypothesis)
+ H1:  p != 0.53  (alternative hypothesis)
+ z = -1.60
+ p = 0.1095986
+ critical z = -1.645

```{r q16}

sig.level <- .10

# Calculate z-score:
stdDev <- sqrt((100 * 0.53) * (1 - 0.53))

z <- (45 - (100 * 0.53)) / stdDev
pretty_vector( c( "Z-Score" = round(z, 2) )) # [1] -1.602888

# Estimate p-value:
p_estimate <- 2 * pnorm(-1.60) # [1] 0.1095986

pretty_vector(c("Point Estimate" = round(p_estimate, 3)))

# Calculate critical z score:
critcal_z <- qnorm(1 - sig.level / 2, lower.tail = F) # [1] -1.644854

```


```{r q16_results, echo = F}

pretty_vector(c("Critical Z-Score" = round(critcal_z, 2)))

pretty_vector(c("p-value Result" = ifelse(p_estimate > sig.level, "Fail to Reject", "Reject")))
pretty_vector(c("Test Result" = ifelse(z > critcal_z, "Fail To Reject", "Reject")))

```

> Given our p-value and adopted significance level, 0.110 > 0.10, we fail to reject the
null hypothesis. There is insufficient evidence to reject the claim that the “true”
percentage is 53%.

## 17.) Linear Correlation

What does the linear correlation coefficient tell us regarding the usefulness of a regression equation for making predictions?

> The linear regression equation is appropriate for predictions when there is
a significant linear correlation between two variables. The linear correlation 
coefficient quantifies the strength of a linear relationship, and significant
magnitudes indicate the likely usefulness of the linear regression equation for
the purpose of prediction.

## 18.) Type I Error

A hypothesis test of the given claim will be conducted. A cereal company claims that the mean weight of the cereal in its packets is 14 oz. Identify the type I error for the test.

+ a.) Fail to reject the claim that the mean weight is 14 oz. when it is actually different from 14 oz.
+ b.) Reject the claim that the mean weight is 14 oz. when it is actually greater than 14 oz.
+ __c.) Reject the claim that the mean weight is 14 oz. when it is actually 14 oz.__
+ d.) Reject the claim that the mean weight is different from 14 oz. when it is actually 14 oz.

__A type I error is the incorrect rejection of a "true" null hypothesis.__

## 19.) Test Scores

Scores on a test are normally distributed with a mean of 68.2 and a standard deviation of 10.4. Estimate the probability that at least 20 of 75 randomly selected students score greater than 78.

+ a.) 0.0166 
+ b.) 0.0113 
+ __c.) 0.0278__
+ d.) 0.1736

```{r q19}

mu <- 68.2
sd <- 10.4
gt <- 78

# We need to determine the z-score associated with our score of interest, 78.
z <- (gt - mu) / sd

# We need to determine the probability associated with a random value being greater than 78
p <- pnorm(z, 0, 1, lower.tail = F)

# This sequence "provides" the => 20 possible instances (56 of a total 75) that we need for
# summing our probabilities:
x <- seq(20, 75, 1)

q19_prob <- sum(dbinom(x, 75, p))

# We may want the normal approximation, for which:

# This formula returns a z-score for the normal approximation:
b <- (19.5 - p * 75) / sqrt(75 * p * (1 - p))

# This returns the probability associated with our "corrected" z-score:
q19_normal_approx <- pnorm(b, 0, 1, lower.tail = FALSE)

```

```{r q19_results, echo = F}
pretty_vector(c("True Prob:" = round(q19_prob, 4), "Normal Approx.:" = round(q19_normal_approx, 4)))
```

> __EXPLANATION__:  We assume a normal distribution, but we rely on a binomial distribution
when we want the likelihood of => 20 "successes". So, 0.173 is the probability associated
with any "random" test taker scoring greater than 78; this we solve assuming (and
employing a normal distribution; pnorm()). However, when we go to look at the likelihood
that at least 20 of our test takers achieve this score we rely on a binomial, even though
we still assume (and rightly) that our test scores are normally distributed.

> So, looking at the sum(dbinom(x, 75, p)). This is the exact binomial probability associated
with our conditions; 20 or more successes (test score > 78) out of 75 test takers. What we
want is to correct for the fact that we've had to use a discrete distribution (binomial) to
approach a continuous, normally distributed problem/reality.

_The (19.5 - p * 75)/ sqrt(75 * p * (1-p)) gives us our "corrected" z-score that we can then
"plug in" to our cumulative probability function, pnorm()._

## 20.) Correlation

Find the value of the linear correlation coefficient, r, using the following data. Determine if the null hypothesis of zero correlation is rejected with a 5% alpha (Type I error rate).

```{r q20_setup, echo = F}

q20_data <- data.frame(rbind(c(62, 53, 64, 52, 52, 54, 58), c(158, 176, 151, 164, 164, 174, 162)))
rownames(q20_data) <- c("x", "y")
colnames(q20_data) <- rep(c(""), 7)

pretty_kable(q20_data, "")

```

+ a.) 0.754, don’t reject 
+ b.) __-0.775, reject__
+ c.) -0.081, don’t reject 
+ d.) 0.754, reject

```{r q20}

alpha <- 0.05

x <- as.numeric(q20_data[1,])
y <- as.numeric(q20_data[2,])

c <- cor( x, y ) # [1] -0.7749395
t <- cor.test(x, y)

```


```{r q20_results, echo = F}

pretty_vector( c( "Correlation" = round(c, 3 ) ))

t

pretty_vector(c("p-value Test Result" = ifelse(t$p.value < alpha, "Reject", "Fail to Reject")))

```

## 21.) Sample Size (Unknown mu & var)

A researcher wants to estimate what proportion of U.S. refinery workers are contract workers. The researcher wants to be __95%__ confident of her results and be within __0.05__ of the actual proportion. 
There have been no prior studies. The researcher has no idea what is the actual population proportion. How large a sample size should be taken? Round to the next largest integer.

+ a.) n = 664 
+ __b.) n = 385__
+ c.) n = 271 
+ d.) n = 543

```{r q21}

z <- qnorm(1 - (1 - 0.95) / 2)
moe <- 0.05
n = .25 * (z / moe) ** 2

```

```{r q_21_result, echo = F}

pretty_vector( c( "Sample Size:" = ceiling( n ) ))

```

## 22.) Traditional Test

Use the traditional method to test the given hypothesis. 

+ Assume that the samples are independent and that they have been randomly selected. 
+ Use the given sample data to test the claim that p1 > p2. Use a significance level of 0.01.


```{r q22_setup, echo = F}

q22_data <- data.frame(c("n1 = 85", "x1 = 38"), c("n2 = 90", "x2 = 23"))
colnames(q22_data) <- c("Sample 1", "Sample 2")

pretty_kable(q22_data, "Samples")

```

```{r q22}

alpha <- 0.01

x1 <- 38
n1 <- 85

x2 <- 23
n2 <- 90

p1 <- x1 / n1
p2 <- x2 / n2

# Calculate pooled sample proportion:
p <- (((p1) * n1) + ((p2) * n2)) / (n1 + n2)

# Calculate standard error:
stdErr <- sqrt(p * (1 - p) * ((1 / n1) + (1 / n2)))

z <- (p1 - p2) / stdErr
z # [1] 2.657104

# Calculate the critical z-score:
critcal_z <- qnorm(1 - 0.01) # [1] 2.326348

```


```{r q22_results, echo = F}
pretty_vector(c("Z-Score" = round(z, 3), "Critical Z-Score" = critcal_z))

pretty_vector(c("p-value Result" = ifelse(p > alpha, "Reject", "Fail to Reject")))
pretty_vector(c("Test Result" = ifelse(z > critical_z, "Reject", "Fail to Reject")))

```

## 23.) T-Test (unequal sd)

A researcher was interested in comparing the average length of time (in hours) spent watching television by women and by men. Independent simple random samples of 14 women and 17 men were selected, 
and each person was asked how many hours he or she had watched television during the previous week. 

_The summary statistics are as follows_:

```{r q23_setup, echo = F}

q23_data <- data.frame(c("x1 = 12.5 hr", "s1 = 3.9 hr", "n1 = 14"), c("x2 = 13.8 hr", "s2 = 5.2 hr", "n2 = 17"))
colnames(q23_data) <- c("Women", "Men")

pretty_kable(q23_data, "Samples")

```

+ Use a 0.05 significance level to test the claim that the average length of time spent watching television by women is smaller than the average length amount of time spent watching television by men. 
+ Use a t test for hypothesis testing. 

__Do not assume that the population standard deviations are equal.__

+ H0 = avg(women) < avg(men)
+ Ha = avg(women) > avg(men)

```{r q23}

x1 <- 12.5
s1 <- 3.9
n1 <- 14

x2 <- 13.8
s2 <- 5.2
n2 <- 17

# Calculate our t:
t <- (x1 - x2) / sqrt(s1 ^ 2 / n1 + s2 ^ 2 / n2)
t # [1] -0.7945437

s1n1 <- s1 ^ 2 / n1
s2n2 <- s2 ^ 2 / n2

df.calculated <- ((s1n1 + s2n2) ^ 2) / (s1n1 ^ 2 / (n1 - 1) + s2n2 ^ 2 / (n2 - 1))

alt.df <- n1 + n2 - 2 # Alt. Df, 29

# Calculate the critical t:
critcal_t <- qt(1 - 0.05, df = df.calculated, lower.tail = F) # [1] -1.699535

```


```{r q23_display, echo = F}
pretty_vector(c("Df Calculated" = round(df.calculated, 3), "Alt Df" = alt.df))

pretty_vector(c("T-Score" = round(t, 3), "Critical T-Score" = critcal_t))
pretty_vector(c("Test Result" = ifelse(t > critcal_t, "Reject", "Fail to Reject")))
```

_At our adopted significance level (0.05), we fail to reject the null hypothesis._

> There is insufficient evidence for the claim that the mean amount of time spent
watching television by women is smaller than the mean amount of time spent
watching television by men.

## 24.) T-Test (equal sd)

A researcher was interested in comparing the average length of time spent watching television by women and by men. 
Independent simple random samples of 14 women and 17 men were selected, and each person asked how many hours he or she had watched television during the previous week. 

_The summary statistics are as follows_:

```{r q24_setup, echo = F}

q24_data <- data.frame(c("x1 = 11.4 hr", "s1 = 4.1 hr", "n1 = 14"), c("x2 = 16.8 hr", "s2 = 4.7 hr", "n2 = 17"))
colnames(q24_data) <- c("Women", "Men")

pretty_kable(q24_data, "Samples")

```

Use a 0.05 significance level to test the claim that the average length of time spent watching television by women is smaller than the average length of time spent watching television by men. 
Use the traditional method of hypothesis testing. 

__Assume that the population standard deviations are equal.__

+ H0 = avg(women) < avg(men)
+ Ha = avg(women) > avg(men)

```{r q24}

x1 <- 11.4
s1 <- 4.1
n1 <- 14

x2 <- 16.8
s2 <- 4.7
n2 <- 17

# Calculate our pooled standard deviation
s <- sqrt(((n1 - 1) * s1 ^ 2 + (n2 - 1) * s2 ^ 2) / (n1 + n2 - 2))

# Calculate our t:
t <- (x1 - x2) / (s * sqrt(1 / n1 + 1 / n2))

# Calculate the critical t:
critcal_t <- qt(1 - 0.05, df = n1 + n2 - 2, lower.tail = F) # [1] -1.699127

```

```{r q24_display, echo = F}

pretty_vector(c("T-Score" = round(t, 3), "Critical T-Score" = critcal_t))
pretty_vector(c("Test Result" = ifelse(t < critcal_t, "Reject", "Fail to Reject")))

```

> At our adopted significance level (0.05), we reject the null hypothesis. There
is sufficient evidence for the claim that the mean amount of time spent watching
television by women is smaller than the mean amount of time spent watching
television by men.

## 25.) Population Proportions

Construct a 90% confidence interval for the difference between population proportions, (p1 - p2). 

Assume that the samples are independent and that they have been randomly selected.

x1 = 15, n1 = 50 and x2 = 23, n2 = 60. 

__Do not use a continuity correction__.

+ __a.) -0.232 < (p1 - p2) < 0.065__
+ b.) 0.151 < (p1 - p2) < 0.449
+ c.) 0.477 < (p1 - p2) < 0.122 
+ d.) 0.123 < (p1 - p2) < 0.477

```{r}

x1 <- 15
n1 <- 50

x2 <- 23
n2 <- 60

p1 <- x1 / n1
p2 <- x2 / n2

# Calculate the standard deviation of the difference between proportions:
s <- sqrt(p1 * (1 - p1) / n1 + p2 * (1 - p2) / n2)

# Calculate the critical z:
critical_z <- qnorm(1 - 0.10 / 2) # [1] 1.644854

p1 <- (p1 - p2) - (qnorm(1 - 0.10 / 2) * s) # [1] -0.2317335
p2 <- (p1 - p2) + (qnorm(1 - 0.10 / 2) * s) # [1] 0.06506688

# Alternative calculation

c1 <- c(15, 23)
c2 <- c(50, 60)
c2 <- c2 - c1
x <- cbind(c1, c2)

t <- qt(0.054861 / 2, 1, lower.tail = TRUE)

prop.test(x, alternative = c("two.sided"), conf.level = 0.90, correct = FALSE)

```

```{r q25_results, echo = F}
pretty_vector(c("Z-Score" = round(z, 3), "Critical Z-Score" = critcal_z))
pretty_vector(c("p1" = round(p1, 3), "p2" = round(p2,3)))
pretty_vector(c("Test Result" = ifelse(critcal_z < z, "Reject", "Can't Reject")))
```

## 26.) Regression Line

Use the given data to find the equation of the regression line. Round the final values to three significant digits. The variable y denotes the predicted value for the dependent variable y.


```{r q26_setup, echo = F}

q26_data <- data.frame(rbind(c(6, 8, 20, 28, 36), c(2,4,13,20,30)))
rownames(q26_data) <- c("x", "y")
colnames(q26_data) <- rep(c(""), 5)

pretty_kable(q26_data, "")

```

+ a.) y = -2.79 + 0.897x 
+ b.) y -2.79 + 0.950x 
+ c.) y = -.79 + 0.801x 
+ __d.) y = -3.79 +0.897x__


```{r q26}

x <- c(6, 8, 20, 28, 36)
y <- c(2, 4, 13, 20, 30)

lm.fit <- lm(y ~ x)

```


```{r q26_results, echo = F}

pretty_vector(lm.fit$coefficients, "Coefficients")

```

## 27.) Confidence Intervals

Using the data in problem 26, construct 95% confidence intervals for the coefficients in the resulting regression model.


```{r q27_setup, echo = F}

q27_data <- data.frame(rbind(
	c("(-6.73, 1.148)", "(-6.73, 1.148)", "(-7.73, 0.148)", "(-4.73, 4.148)"),
    c("(0.724, 1.071)", "(0.774, 1.121)", "(0.724, 1.071)", "(0.654, 1.001)")))

rownames(q27_data) <- c("intercept", "x")
colnames(q27_data) <- c("A", "B", "C", "D")

pretty_kable(q27_data, "Answer Choices")

```


```{r q27}

lm.sum <- summary(lm.fit)

result <- confint(lm.fit, level = .95)

```

__Answer: C__ 

```{r q27_results, echo = F}
pretty_kable(as.data.table(result), "95% Confidence Intervals", dig = 3 )
```

## 28.) Chi-Squared Test (independence)

A web service is interested in whether or not having signed up for email updates and offers is independent of purchasing choice (has purchased or has not). 
Conduct a chi-square test of independence. 
State the hypotheses, determine chi- square statistic and p-value using the contingency table below:

```{r q28_setup, echo = F}

q28_data <- data.frame(rbind(
	c(30, 60),
	c(20, 75)))

rownames(q28_data) <- c("Has signed up.", "Has not signed up.")
colnames(q28_data) <- c("Has made purchase.", "Has not made purchase.")

pretty_kable(q28_data, "Contingency Table")

```


```{r q28}

chisq.test(q28_data, correct = FALSE)

```

## 29.) Chi-Squared (Uniform)

An urgent care center is interested in whether visits per day of the week are uniformly distributed. 
Conduct a chi-square goodness of fit test. State the null and alternative hypotheses. 

_Provide the chi-square value and associated p-value_.


```{r q29_setup, echo = F}

q29_data <- data.frame( cbind(c(24), c(19), c(26), c(29), c(30), c(23)))
colnames(q29_data) <- c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday")

pretty_kable(q29_data, "Visits")

```


```{r q29}

chisq.test(q29_data)

```

## 30.) Correlation Test

Test the hypothesis of a zero correlation using the procedure shown by Wilcox in Basic Statistics. 

Assume __n = 47__, __r = -0.286__. 

Test the null hypothesis of zero correlation versus the alternative that the correlation is negative at 95% confidence. 

_Also calculate the p-value_.

```{r q30}

r <- -0.286
n <- 47
df <- n - 2

t <- r * sqrt( df / ( 1 - ( r ) ^ 2 ) )

critical_t <- qt(1 - 0.05, df, lower.tail = F)

p <- 1 - pt(abs(t), df = n - 2)

```

> The T test statistic has a Student’s t-distribution with 45 degrees
of freedom.  The test statistic value is -2.00.  The critical value
is -1.679.  Since T = -2.00 < -1.679 the null hypothesis can be
rejected.  The p-value is 0.0258 < 0.05.

```{r q30_results, echo = F}

pretty_vector(c("T" = round(t, 3), "Critical T" = critical_t))

pretty_vector(c("p" = round(p, 3)))
pretty_vector(c("Test Result" = ifelse(t < critical_t, "Reject", "Can't Reject")))

```

## 31.) Hypergeometric Distribution

A project manager is trying to assemble a five-member team. She has a list of 30 volunteers that she intends to draw five (5) from randomly, so as not to alienate anyone. 
However, only four (4) of the 30 have a specific certification that the project manager knows she’ll need. 

+ What is the likelihood that two of the five members randomly selected will be one of the four with the needed certification? 
+ What is the probability that at least one of the five members randomly selected will have the needed certification?

```{r q31}

N <- 30 # size of population
k <- 4 # number of "successes"
n <- 5 # sample size, without replacement
x <- 2 # quantity of interest

((factorial(k) / (factorial(x) * factorial(k - x))) *
	(factorial(N - k) / (factorial(n - x) * factorial((N - k) - (n - x))))) /
	(factorial(N) / (factorial(n) * factorial(N - n)))

# Or, using the dhyper() function:
dhyper(2, 4, (30 - 4), 5) # [1] 0.1094691


# What is the probability that at least one of the five members randomly selected
# will have the needed certification?

1 - phyper(0, 4, (30 - 4), 5) # [1] 0.5384054

```

## 32.) T-Test

Consumers are asked to rate a company both before and after viewing a video on the company twice a day for a week. Use the paired data given below. 
Test at the 1% significance level if the “after” results are less than the “before” results. Assume the data are normally distributed.


```{r q32_setup, echo = F}

q32_data <- data.frame(rbind(
	c(1, 2, 3, 4, 5, 6, 7, 8, 9),
	c(38, 27, 30, 41, 36, 38, 33, 36, 44),
	c(22, 28,21,38,38,26,19,31,35)))

rownames(q32_data) <- c("pair", "before", "after")
colnames(q32_data) <- rep(c(""), ncol(q32_data))

pretty_kable(q32_data, "Raitings")

```


```{r q32}

alpha <- 0.01

delta <- q32_data["before",] - q32_data["after",]

sd <- sd(delta)

t <- qt(1 - alpha, 8, lower.tail = T)

results <- t.test( delta, alternative = c("greater"), mu = 0, paired = F, conf.level = 1 - alpha)

```

```{r q32_results, echo = F}
pretty_vector(c("Test Result" = ifelse(results$p.value < alpha, "Reject", "Can't Reject")))
```

> At our adopted significance level, we reject the null hypothesis of no difference.

## 33.) Difference of Means

Random samples of men from two different towns were obtained and the weights of the men measured in pounds. 
Using the data below test the claim there is more variation in weights of men from town A versus the weights of men from town B. 

_Use a 5% significance level_.


```{r q33_setup, echo = F}

q33_data <- data.frame(rbind(
	c(41, 165.1, 26.2),
	c(21, 159.5, 24.1)))

rownames(q33_data) <- c("Town A", "Town B")
colnames(q33_data) <- c("sample size", "sample average", "Sample standard deviation")

pretty_kable(q33_data, "Samples")

```


```{r q33}

sA <- 26.2
sB <- 24.1
nA <- 41
nB <- 21
dfA <- nA - 1
dfB <- nB - 1

f_stat <- (sA / sB) ^ 2 # 1.181867
f_crit <- qf(0.95, dfA, dfB, lower.tail = TRUE) # 1.993819

prob <- pf(F_Stat, dfA, dfB, lower.tail = FALSE) # 0.3518687

```

```{r q33_results}
pretty_vector(c( "P Value" = prob ))
pretty_vector(c("Test Result" = ifelse(f_crit < f_stat, "Reject", "Can't Reject")))
```

## 34.) Chi-Squared

Use the p-value method to test the claim that the population standard deviation of the systolic blood pressures of adults aged 40-50 is equal to 22 mmHG. 

Use the following sample statistics: 

+ n = __23__
+ sample mean = __132.3__ mmHg, and 
+ sample standard deviation s = __26.6__ mmHg. 

Determine the value of the test statistic, the p-value and your conclusion. 

Use a 5% significance level. 

Assume normality. 

This is a two-sided test. 

Also, calculate a 95% confidence interval for the population standard deviation.

```{r q34}

alpha <- 0.05 / 2 # two-sided test, so divide by two

n <- 23
ev <- 132.3
sd <- 26.6

chi <- (n - 1) * (sd / (n - 1)) ^ 2

# p-value
p <- pchisq(chi, n - 1, lower.tail = FALSE)

# critical value

critical.values <- c(qchisq(0.975, n - 1, lower.tail = T), qchisq(0.025, n - 1, lower.tail = T))

inverted <- sqrt(((n - 1) * 26.6 ^ 2) / critical.values)

```

> Since the p-value is greater than 2.5%, the null hypothesis of variance
equality can not be rejected.

```{r q34_results, echo = F}

pretty_vector( c( "p-value" = p) )
pretty_vector( c( "Test Result" = ifelse( alpha < p, "Can't Reject", "Reject" ) ))
pretty_vector( c( "Critical Values" = inverted ) )

```

## 35.) ANOVA Table

Fill in the missing entries in the following one-way ANOVA table and determine the p-value and the critical value for the F-statistic.

```{r q35_setup, echo = F}

q35_data <- data.frame(rbind(
	c("3", "", "", "11.16"),
	c("", "13.72", "0.686", ""),
	c("", "", "", "")))

rownames(q35_data) <- c("Treatment", "Error", "Total")
colnames(q35_data) <- c("Source", "SS", "MS=SS/df", "F-statistic")

pretty_kable(q35_data, "ANOVA Table")

```


```{r q35}

ms.error <- 0.686
ss.error <- 13.72
treatment <- 3
f.stat <- 11.16

error <- ss.error / ms.error
total <- treatment + error

#  (F-statistic * MS_Error)
ms.treatment <- round( f.stat * ms.error, 2)

# MS, Treatment (F-statistic * MS_Error)
ss.treatment <- round( ms.treatment * treatment, 2 )

ss.total <- round( ss.treatment + ss.error, 2 )

q35 <- data.frame(rbind(
	c(treatment, ss.treatment, ms.treatment, f.stat),
	c(error, ss.error, ms.error, ""),
	c(total, ss.total, "", " ")))

p <- pf( f.stat, treatment, error, lower.tail = FALSE) # p-value = 0.0001607934
# 99% Critical Value
crit <- qf(0.99, treatment, error, lower.tail = TRUE) # critical value = 4.938

test.statistic <- ms.treatment / ms.error # F-statistic

```


```{r q35_results, echo = F}

rownames(q35) <- c("Treatment", "Error", "Total")
colnames(q35) <- c("Source", "SS", "MS=SS/df", "F-statistic")

pretty_kable(q35, "ANOVA Table")

pretty_vector(c( "Test Statistic" = test.statistic, "p-value" = round( p, 3 ), "Critical Value" = round( crit, 3 )))

```

## 36.) Pearson Linear Coefficient

For the data below, determine the value of thelinear correlation coefficient r between y and x2.


```{r q36_setup, echo = F}

q36_data <- data.frame(rbind(
	c( 1.2, 2.7, 4.4, 6.6, 9.5 ),
	c(1.6, 4.7, 9.9, 24.5, 39.0)))

rownames(q36_data) <- c("x", "y")
colnames(q36_data) <- c("", "", "", "")

```


```{r q36}

x <- as.numeric( q36_data[1,] )
y <- as.numeric(q36_data[2,])

x_sq <- x ^ 2

correlation <- cor(x_sq, y, method = c("pearson"))

```


```{r q36_results}
pretty_vector( c( "Correlation" = correlation))
```

## 37.) Chi-Squared Frequency

In studying the occurrence of genetic characteristics, the following sample data were obtained. At the 0.05 significance level, test the claim
that the characteristics occur with the same frequency.

```{r q37_data, echo = F}

q37_values <- c(28, 30, 45, 48, 38, 39)

q37_data <- data.frame(rbind(
	c("A", "B", "C", "D", "E", "F"),
    q37_values))

rownames(q37_data) <- c("Characteristic", "Frequency")
colnames(q37_data) <- rep(c(""), length(q37_values))

pretty_kable(q37_data, "Data")

```

+ This is a Chi-square goodness-of-fit test. The counts are expected to be equal under the null hypothesis.
+ The expectation is 38 which needs to be compared against the observed counts.

```{r q37}

alpha <- .05

obs <- q37_values
ec <- rep(sum(obs) / length(obs), times = 6 )

diff <- sum((obs - ec) ^ 2 / ec) # f-statistic, 8.263158

df <- length(obs) - 1

p.value <- pchisq(diff, df, lower.tail = F) # p-value
f.stat <- qchisq(1 - alpha, df, lower.tail = T) # f critical

diff > f.stat
p.value < alpha

```


```{r q37_results}
pretty_vector(c("p-value" = p.value, "f-statistic" = f.stat))

pretty_vector(c("p-value Result" = ifelse(p.value < alpha, "Reject", "Fail to Reject")))
pretty_vector(c("Test Result" = ifelse(diff > f.stat, "Reject", "Fail To Reject")))

```

## 38.) Pearson's Chi-squared Test

Customers in a store were selected at random to participate in a taste test. Two hundred people participated and expressed a 
preference for one of two beverages. Use the taste test data in the following table to test the hypothesis of
equal preferences for the two beverages in the study.

+ Test at the 5% level.
+ Use an uncorrected Chi-square test.

```{r q38_data, echo = F}

alpha <- 0.05

bev_a <- c(35, 23, 42)
bev_b <- c(25, 30, 45)

q38_data <- data.frame(rbind( bev_a, bev_b))

rownames(q38_data) <- c("Beverage A", "Beverage B")
colnames(q38_data) <- c("children", "men", "women")

pretty_kable(q38_data, "Beverages")

```


```{r q38}

data <- matrix(c(bev_a, bev_b), nrow = 2, byrow = T)

results <- chisq.test(data, correct = F)

qchisq(.95, 2, lower.tail = T)

```


```{r q38_results}
pretty_vector(c("p-value" = results$p.value))
pretty_vector(c("p-value Result" = ifelse(results$p.value < alpha, "Reject", "Fail to Reject")))
```

## 39.) Quantiles

The systolic blood pressures of the patients at the hospital are normally distributed with a mean of 138 mm Hg
and aa standard deviation of 13.5 mm Hg. Find the two blood pressures having these properties:

+ The mean is midway between them and 
+ 90% of all blood pressures are between them.

__Answer:__


```{r q39}

upper <- qnorm(0.95, 138, 13.5)
lower <- qnorm(0.05, 138, 13.5, lower.tail = T)

```

```{r q39_result}
pretty_vector(c("Lower" = lower, "Upper" = upper))

```

## 40.) Two-sided Confidence Interval

Assume a binomial experiment has been completed and two independent random samples were collected.
For the first sample there were 18 successes out of 50 trials (__p1 = 18/50__). For the second sample
there were 30 successes out of 60 trials (__p2 = 30/60__).

+ Construct a 90% two-sided confidence interval for the difference p1 - p2.
+ Determine if this is a statistically significant difference.

```{r q40}

alpha <- .1

n1 <- 50
s1 <- 18

n2 <- 60
s2 <- 30

p1 <- s1 / n1
p2 <- s2 / n2

p_hat <- p1 - p2

# Section 10.4, Business Statistics

p_bar <- ( s1 + s2 ) / (n1 + n2)
std <- sqrt(p_bar * (1 - p_bar) * (1 / n1 + 1 / n2))
z <- p_hat / std

p <- round(pnorm(z), 4)

q.z <- qnorm(1 - (alpha / 2)) # divide by two for two-sided confidence interval

conf_int <- p_hat + round(c(-q.z, q.z) * std, digits = 4)

```


```{r q40_result, echo = F}
pretty_vector(c("p-value" = p ))
pretty_vector(c("p-value Result" = ifelse(p < alpha, "Reject", "Fail to Reject")))
```

## 41.) Discrete Statistics

A discrete random variable has the follow outcomes:

```{r q41_setup, echo = F}
x <- c(0, 1, 2, 3, 4, 5, 6)
P.x <- c(0.215, 0.230, 0.240, 0.181, 0.130, 0.003, 0.001)

q40_data <- data.frame(rbind(x, P.x))
rownames(q40_data) <- c("x", "P(x)")
colnames(q40_data) <- rep("", ncol(q40_data))

pretty_kable(q40_data, "Probabilities")

```

+ Determine the value of _median_, _mean_, _mode_ and _variance_ for this variable.

Quantiles for a discrete random variable are selected from the possible values of the variable based upon the probability distribution.


```{r q41}

avg <- round(sum(x * P.x), digits = 3) # 1.794
var <- round(sum(P.x * (x - avg) ^ 2), digits = 3) # 1.792
mode <- x[ P.x == max(P.x) ] # 2
sd <- sqrt(var)
med <- 2 # look at the cdf

```

```{r q41_display, echo = F}

    pretty_vector(c("Mean" = ev, "Variance" = var, "Standard Deviation" = sd, "Median" = med, "Mode" = mode))
    plot(x, cumsum(P.x), main = "cdf for P.x", type = "h", ylim = c(0, 1.0))
    abline(h = 0.5, col = "red")

```

## 42.) T-Test (unequal sd)

A researcher was interested in comparing the average length of time (in hours) spent watching television by women and by men. Independent simple random samples of 14 women and 17 men were selected, 
and each person was asked how many hours he or she had watched television during the previous week. 

_The summary statistics are as follows_:

```{r q42_setup, echo = F}

q23_data <- data.frame(c("x1 = 11.4 hr", "s1 = 4.1 hr", "n1 = 14"), c("x2 = 16.8 hr", "s2 = 4.7 hr", "n2 = 17"))
colnames(q23_data) <- c("Women", "Men")

pretty_kable(q23_data, "Samples")

```

+ Use a 0.05 significance level to test the claim that the average length of time spent watching television by women is smaller than the average length amount of time spent watching television by men. 
+ Use the t radition method of hypothesis testing. 

__Assume that the population variances are equal.__

+ H0 = avg(women) < avg(men)
+ Ha = avg(women) > avg(men)

__For this problem, a one-sided test is required. The alternative will be framed as a positive.__

```{r q42}

alpha <- 0.05

s1.2 <- 4.1 ^ 2
s2.2 <- 4.7 ^2

n1 <- 14
n2 <- 17

df <- n1 + n2 - 2

pool <- sqrt((s1.2 * (n1 - 1) + s2.2 * (n2 - 1)) / df)

den <- pool * sqrt( 1 / n1 + 1 / n2)

x1 <- 11.4
x2 <- 16.8

t <- (x2 - x1) / den

p.value <- pt(t, df, lower.tail = F)

critical_t <- qt(0.95, df, lower.tail = T)

```


```{r q42_display, echo = F}

pretty_vector(c("p-value" = round(p.value,3)))
pretty_vector(c("T-Score" = round(t, 3), "Critical T-Score" = critcal_t))

pretty_vector(c("p-value Test Result" = ifelse(p.value < alpha, "Reject", "Fail to Reject")))
pretty_vector(c("Test Statistic Result" = ifelse(t > critcal_t, "Reject", "Fail to Reject")))

```
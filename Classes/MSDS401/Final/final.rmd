---
title: 'Practice Final'
author: "Moretz_Brandon"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  pdf_document:
    toc: yes
  html_document:
    df_print: paged
    theme: spacelab
    toc: yes
    toc_float: yes
---

```{r additional-libraries, echo=FALSE}

library(data.table, quietly = TRUE, warn.conflicts = FALSE)

assignInNamespace("cedta.pkgEvalsUserCode", c(data.table:::cedta.pkgEvalsUserCode, "rtvs"), "data.table")

library(dplyr, quietly = TRUE, warn.conflicts = FALSE)
library(ggplot2, quietly = TRUE, warn.conflicts = FALSE)
library(ggthemes, quietly = TRUE, warn.conflicts = FALSE)
library(gridExtra, quietly = TRUE, warn.conflicts = FALSE)
library(kableExtra, quietly = TRUE, warn.conflicts = FALSE)

theme_set(theme_light())

# Theme Overrides
theme_update(plot.title = element_text(hjust = 0.5),
			 axis.text.x = element_text(size = 10),
			 axis.text.y = element_text(size = 10),
			 axis.title = element_text(face = "bold", size = 12, colour = "steelblue4"),
			 legend.position = "top", legend.title = element_blank())

pretty_kable <- function(data, title, dig = 2) {
  kable(data, caption = title, digits = dig, big.mark = "'") %>%
    kable_styling(bootstrap_options = c("striped", "hover"))
}

pretty_vector <- function(vec, label = "") {
  pander::pander(vec)
}

```


## 1.) Combinations and Permutations

Suppose that a class of 30 students is assigned to write an essay.

a. Suppose 4 essays are randomly chosen to appear on the class bulletin board. How many different groups of 4 are possible? Selection order is not important.
b. Suppose 4 essays are randomly chosen for awards of $10, $7, $5 and $3. How many different groups of 4 are possible? Selection order is important.
c. Explain the differences between problems 1 and 2.


```{r q1}

pretty_vector( c("a.)" = choose(30, 4) ))

pretty_vector(c("b.)" = choose(30, 4) * factorial(4)))

```

__c.)__ Item __(a)__ asks for the combinations or groups of four possible. There isn't a sense
in which the order of the four essays selected is meaningful. Item __(b)__ asks for the
permutations possible when four are selected from 30. Here, there is a meaningful
difference in the order - i.e. prizes awarded - of the four selected. 

## 2.) Basic Stats

For the given probability distribution, find the mean, variance, standard deviation, median and mode.

```{r q2_setup, echo = F}

x <- c(0, 1, 2, 3, 4)
P.x <- c(0.37, 0.12, 0.06, 0.15, 0.30)

q2_data <- data.frame(rbind(x,P.x))
rownames(q2_data) <- c("x", "P(x)")
colnames(q2_data) <- rep("", ncol(q2_data))

pretty_kable(q2_data, "Probabilities")

```

```{r q2}

ev <- sum(x * P.x)
var <- sum(P.x * (x - ev) ^ 2)
sd <- sqrt(var)
med <- median(x)

mode <- x[P.x == max(P.x)]

```


```{r q2_display, echo = F}

    pretty_vector(c("Mean" = ev, "Variance" = var, "Standard Deviation" = sd, "Median" = med, "Mode" = mode))
    plot(x, cumsum(P.x), main = "cdf for P.x", type = "h", ylim = c(0, 1.0))
    abline(h = 0.5, col = "red")

```

## 3.) Normal Probability

For a standard normal distribution, find the percentage of data that are __more than 2 standard
deviations below the mean__ _or_ __more than 3 standard deviations above the mean__.

+ __a.) 2.41%__
+ b.) 0.26% 
+ c.) 4.56%
+ d.) 97.59%

```{r q3_display, echo = F}

area <- 1 - (pnorm(2) - pnorm(3, lower.tail = F))

ggplot(data.table(X = seq(-4, 4, length = 2000 )), aes(x = X)) +
	stat_function(fun = dnorm) +
	stat_function(fun = dnorm, xlim = c(-4, -2), geom = "area", fill = "steelblue") +
	stat_function(fun = dnorm, xlim = c(4, 3), geom = "area", fill = "steelblue") +
    labs(title = paste("AUC = ", round(area, 5) * 100 ))

```

```{r q3}

pretty_vector( c( Probability = round( pnorm(-2, 0, 1, lower.tail = TRUE) + pnorm(3, 0, 1, lower.tail = FALSE), 5) * 100 ))

```

## 4.) Bayes' Therom

Use the results summarized in the table. One of the 100 test subjects is selected at random. If the person approves of the Mayor, what is the probability that they vote Democrat? Use Bayes’ theorem.

+ a.) 0.674
+ b.) 0.581
+ c.) 0.391
+ __d.) 0.545__

```{r q4_setup, echo = F}

q4_data <- data.frame(rbind(
	c(8, 17),
	c(18, 13),
	c(7, 37)))

rownames(q4_data) <- c("Republican", "Democrat", "Independent")
colnames(q4_data) <- c("Approve of Mayor", "Do not approve of Mayor")

pretty_kable(q4_data, "Votes")

```

```{r q4}

# We know the person approves of the Mayor. Let's look at only those individuals.
# Of the "Mayor approvers," 18 vote Democrat.

pretty_vector( c( ShortWay = 18 / (8 + 18 + 7) ))# [1] 0.5454545

# Long Way

n <- sum(q4_data)

p.approve <- sum( q4_data[,1] ) / n
p.disaprove <- 1 - p.approve

p.democrat <- sum(q4_data[2,]) / n
p.not_democrat <- 1 - p.democrat

p.democrat.approves <- 18 / sum( q4_data[2,] )
p.not_democrat.approves <- sum(q4_data[c(1, 3), 1]) / sum( q4_data[c(1,3),] )

q4 <- (p.democrat * p.democrat.approves) / ((p.democrat * p.democrat.approves) + (p.not_democrat * p.not_democrat.approves))

pretty_vector(c(LongWay = q4))

```

## 5.) Chi-Squared Test

Use the results summarized in the table above and test at the 5% level if party affiliation and approval of the Mayor are independent of each other using Pearson’s Chi-square test of independence.

+ __a.) df = 2, p-value > 0.05, don’t reject__
+ b.) df = 2, p-value < 0.05, reject
+ c.) df = 5, p-value < 0.05, don’t reject
+ d.) df = 5, p-value > 0.05, reject

```{r q5}

approve <- c(8, 18, 7)
not.approve <- c(17, 13, 37)
vote <- cbind(approve, not.approve)

results <- chisq.test(vote, correct = FALSE)

ifelse( results$p.value < 0.05, "Don't Reject", "Reject")

```

## 6.) Basic Stats #2

A police department states that the probabilities for 0, 1, 2, and 3 burglaries reported in a given day are 0.46, 0.41, 0.09, and 0.04, respectively. 

+ Find the mean, variance, standard deviation, median and mode. Round the answer to the nearest hundredth.

```{r q6}

x <- c(0, 1, 2, 3)
P.x <- c(0.46, 0.41, 0.09, 0.04)

ev <- sum(P.x * x)
var <- sum(P.x * (x - ev) ^ 2)
sd <- sqrt(var)
med <- 1

mode <- x[ P.x == max(P.x) ]

```

```{r q6_display, echo = F}

    pretty_vector(c("Mean" = ev, "Variance" = var, "Standard Deviation" = sd, "Median" = med, "Mode" = mode))
    plot(x, cumsum(P.x), main = "cdf for P.x", type = "h", ylim = c(0, 1.0))
    abline(h = 0.5, col = "red")

```

## 7.) Uniform Distribution

Assume weight loss for the first month of a diet program varies between 6 pounds and 12 pounds, and is spread evenly forming a uniform distribution. 

+ Find the probability of losing between 8.5 and 10 pounds. 
+ Also, find the probability of losing between 10 and 14 pounds. 

_Round to two decimal places._

+ __A.) 1/4 and 1/3__
+ B.) 1/2 and 2/3 
+ C.) 1/3 and 1/3 
+ D.) 1/4 and 2/3

```{r q7}

punif(10, 6, 12, lower.tail = T) - punif(8.5, 6, 12, lower.tail = T)

punif(10, 6, 12, lower.tail = F)

```

```{r q7_display, echo = F}

ggplot(data.table(X = seq(6, 12, length = 2000)), aes(x = X)) +
	stat_function(fun = dunif)
```

## 8.) Z-Score (Normal)


Find the indicated z-score. 

The graph depicts the standard normal distribution with mean equal 0 and standard deviation equal 1 with a shared area of 0.0901.

+ __a.) -1.34__ 
+ b.) -1.26
+ c.) -1.39 
+ d.) -1.45


```{r q8_setup, echo = F}

q8_prob <- .0901
q8_area <- qnorm(q8_prob)

ggplot(data.table(X = seq(-4, 4, length = 2000)), aes(x = X)) +
	stat_function(fun = dnorm) +
	stat_function(fun = dnorm, xlim = c(-4, q8_area), geom = "area", fill = "steelblue") +
	geom_text(aes(x = q8_area + .5, y = .05), label = q8_prob) +
    labs( title = paste( "Z-Score:", round(q8_area,2) ))

```

```{r q8}

pretty_vector(c("Z-Score" = qnorm(q8_prob)))

```

## 9.) Binomial and Poisson

Here are two discrete probability distributions: dist_A and dist_B. 

By construction each may be either a binomial or a Poisson distribution. 

The mean and variance for dist_A are 5.00 and 5.00. The mean and variance for dist_B are 5.00 and 3.33. 

_Pick the best answer._

+ __a.) Dist_A is Poisson, Dist_B is binomial.__
+ b.) Dist_A is binomial, Dist_B is Poisson.
+ c.) Both are Poisson
+ d.) Both are binomial

```{r q9}
x <- seq(0, 15)
dist_A <- round(dpois(x, 5), digits = 4)
dist_A[16] <- 0.0003
dist_B <- round(dbinom(x, 15, 1 / 3), digits = 4)
plot(x, dist_A, type = "b", ylim = c(0, 0.25), col = "red", ylab = "probability",
	 lwd = "2", main = "Plot of Two Discrete Probability Distributions")
lines(x, dist_B, col = "green", lwd = "2", type = "b")
legend("topright", legend = c("dist_A is red", "dist_B is green"))

# Solution
mean_A <- round(sum(x * dist_A), digits = 2) # [1] 5.0003
variance_A <- round(sum(dist_A * (x - mean_A) ^ 2), digits = 2) #  [1] 5.0019
mean_B <- round(sum(x * dist_B), digits = 2) #  [1] 4.9995
variance_B <- round(sum(dist_B * (x - mean_B) ^ 2), digits = 2) #  [1] 3.332
mean_A
variance_A
mean_B
variance_B

#  dist_A is Poisson.  The variance equals the mean, whereas dist_B is Binomial.
#  The variance is less than the mean, i.e., n*p > n*p*(1-p).  p = 1/3.

```

## 10.) Normal Approximation

This problem involves estimating probabilities for a binomial variable X with p = 0.4 and n = 15. 

Use the normal approximation with continuity correction to estimate the probabilities for the following three outcomes; X = 0, X = 6 and X >= 10. 

_Select the best answer from the following choices:_

__Note:_

Normal approximation to the binomial uses *z = (x - n*p)/sqrt(n * p * (1-p))*

```{r q10_setup, echo = F}

q10_data <- data.frame(rbind(
    c(0.0011, 0.2071, 0.0340),
	c(0.0019, 0.2079, 0.0325),
	c(0.0014, 0.2103, 0.0227),
	c(0.0008, 0.2079, 0.0175)))

rownames(q10_data) <- c("A", "B", "C", "D")
colnames(q10_data) <- c("P[X = 0]", "P[X = 6]", "P[X >= 10]")

pretty_kable(q10_data, "Answer Choices", dig = 4)

```

```{r q10}

x <- seq(0, 15)
n <- 15
p <- .4

m <- which.max(dbinom(x, n, p)) # midpoint

exp <- n * p
std <- exp * (1 - p)

# 0
p_0 <- pnorm((0 - exp + 0.5) / sqrt(std), 0, 1, lower.tail = TRUE)

# 6
p_6 <- pnorm(((m - 1) - exp + 0.5) / sqrt(std), 0, 1, lower.tail = TRUE) -
	pnorm(((m - 1) - exp - 0.5) / sqrt(std), 0, 1, lower.tail = TRUE)

# 10
p_tg10 <- pnorm(10 - 0.5, n * p, sqrt(n * p * (1 - p)), lower.tail = FALSE)

# Results
pretty_vector(c("Prob = 0" = round(p_0,4), "Prob = 6" = round(p_6,4), "Prob >= 10 " = round(p_tg10,4)))

```

```{r q10_display, echo = F}

prob.norm <- function(x) {
	pnorm(((x) - exp + 0.5) / sqrt(std), 0, 1, lower.tail = TRUE) -
	pnorm(((x) - exp - 0.5) / sqrt(std), 0, 1, lower.tail = TRUE)
}

plot(x, dbinom(x, n, p))
lines(x - 0.5, prob.norm(x), col = "red", type = "s")
abline(v = m - 1)

```

## 11.) Power Test

True or False: in a hypothesis test, an increase in alpha will cause a decrease in the power of the test provided the sample size is kept fixed.

+ a.) True 
+ __b.) False__

__FALSE__. 

> The power of a test - the probability of rejecting the null hypothesis when
the alternative hypothesis is true - decreases as a function of beta; the probability
of failing to reject the null hypothesis when the alternative hypothesis is true. An
increase in alpha will decrease beta, thus increasing power. 

_However, please remember that alpha and beta aren't symmetric and we won't try to control one via the other._

## 12.) Type II Error with Means

True or False: in a hypothesis test regarding a population mean, the probability of a type II error, beta, depends on the true value of the population mean.

+ __a.) True__
+ b.) False

__TRUE__. 

> The probability of a type II error - failure to reject a false null
hypothesis - is dependent on the "true value" of the test statistic. In a broad 
sense, either type error will have some relationship with the true mean. However, 
alpha is much more directly related to the test statistic - the probability 
associated with our data given the null hypothesis. Power, however, is related 
directly to the difference between the true and hypothesized mean and how easily, 
how "powerfully" we can resolve smaller and smaller differences between the true 
and hypothetical mean.

## 13.) Hypothesis Test Sample Size

True or False: in a hypothesis test regarding a population mean, if the sample size is increased and the probability of a type II error is fixed and does not change then the type I error rate does not change.

+ A.) True 
+ __B.) False__

__FALSE__. 

> Keeping the power the same, an increase in sample size provides more data 
for the statistical test making it less likely that a type I error will occur.  

## 14.) Hypothesis Test Mean Errors

True or False: in a hypothesis test regarding a population mean, if the sample size is increased and the probability of a type I error is fixed and does not change then the type II error rate will decrease.

+ A.) True 
+ B.) False

__TRUE__. 

> With alpha constant, an increase in sample size provides more data for the 
statistical test increasing the power.  Thus it less likely that a type II error 
will occur.

## 15.) Hypothesis Tests

Suppose that you perform a hypothesis test regarding a population mean, and that the evidence does not warrant rejection of the null hypothesis. 
When formulating the conclusion to the test, why is phrase “fail to reject the null hypothesis” more accurate than the phrase “accept the null hypothesis?”

> A hypothesis test does not "prove" the null hypothesis. Rather, it is meant to determine
whether or not there is sufficient evidence to reject it. Insufficient evidence does not
validate the null hypothesis; it just leaves us without grounds for rejecting it.

## 16.) Identify Test

_Identify the null hypothesis, alternative hypothesis, test statistic, p-value, conclusion about the null hypothesis, and the final conclusion that addresses the original claim._

> According to a recent poll, 53% of Americans would vote for the incumbent president. If a random sample of 100 people results in 45% who would vote for the incumbent, 
test the claim that the actual percentage is 53%. Use a 0.10 significance level.

+ H0:  p  = 0.53  (null hypothesis)
+ H1:  p != 0.53  (alternative hypothesis)
+ z = -1.60
+ p = 0.1095986
+ critical z = -1.645

```{r q16}

sig.level <- .10

# Calculate z-score:
stdDev <- sqrt((100 * 0.53) * (1 - 0.53))

z <- (45 - (100 * 0.53)) / stdDev
pretty_vector( c( "Z-Score" = round(z, 2) )) # [1] -1.602888

# Estimate p-value:
p_estimate <- 2 * pnorm(-1.60) # [1] 0.1095986

pretty_vector(c("Point Estimate" = round(p_estimate, 3)))

# Calculate critical z score:
critcal_z <- qnorm(1 - sig.level / 2, lower.tail = F) # [1] -1.644854

pretty_vector(c("Critical Z-Score" = round(critcal_z, 2)))

pretty_vector( c("Result" = ifelse( p_estimate < sig.level, "Reject", "Fail to Reject" ) ))

```

> Given our p-value and adopted significance level, 0.110 > 0.10, we fail to reject the
null hypothesis. There is insufficient evidence to reject the claim that the “true”
percentage is 53%.

## 17.) Linear Correlation

What does the linear correlation coefficient tell us regarding the usefulness of a regression equation for making predictions?

> The linear regression equation is appropriate for predictions when there is
a significant linear correlation between two variables. The linear correlation 
coefficient quantifies the strength of a linear relationship, and significant
magnitudes indicate the likely usefulness of the linear regression equation for
the purpose of prediction.

## 18.) Type I Error

A hypothesis test of the given claim will be conducted. A cereal company claims that the mean weight of the cereal in its packets is 14 oz. Identify the type I error for the test.

+ a.) Fail to reject the claim that the mean weight is 14 oz. when it is actually different from 14 oz.
+ b.) Reject the claim that the mean weight is 14 oz. when it is actually greater than 14 oz.
+ __c.) Reject the claim that the mean weight is 14 oz. when it is actually 14 oz.__
+ d.) Reject the claim that the mean weight is different from 14 oz. when it is actually 14 oz.

__A type I error is the incorrect rejection of a "true" null hypothesis.__

## 19.)

Scores on a test are normally distributed with a mean of 68.2 and a standard deviation of 10.4. Estimate the probability that at least 20 of 75 randomly selected students score greater than 78.

+ A.) 0.0166 
+ B.) 0.0113 
+ C.) 0.0278 
+ D.) 0.1736

```{r q19}

q19 <- pnorm(78, 68.2, 10.4, lower.tail = F)

pretty_vector(q19)

```

## 20.)

Find the value of the linear correlation coefficient, r, using the following data. Determine if the null hypothesis of zero correlation is rejected with a 5% alpha (Type I error rate).


```{r q20_setup}

q20_data <- data.frame(rbind(c(62, 53, 64, 52, 52, 54, 58), c(158, 176, 151, 164, 164, 174, 162)))
rownames(q20_data) <- c("x", "y")
colnames(q20_data) <- rep(c(""), 7)

pretty_kable(q20_data, "")

```

+ A.) 0.754, don’t reject 
+ B.) -0.775, reject
+ C.) -0.081, don’t reject 
+ D.) 0.754, reject

```{r q20}

```

## 21.)

A researcher wants to estimate what proportion of U.S. refinery workers are contract workers. The researcher wants to be 95% confident of her results and be within 0.05 of the actual proportion. 
There have been no prior studies. The researcher has no idea what is the actual population proportion. How large a sample size should be taken? Round to the next largest integer.

+ A.) n = 664 
+ B.) n = 385 
+ C.) n = 271 
+ D.) n = 543

```{r q21}

```

## 22.)

Use the traditional method to test the given hypothesis. 

+ Assume that the samples are independent and that they have been randomly selected. 
+ Use the given sample data to test the claim that p1 > p2. Use a significance level of 0.01.


```{r q22_setup, echo = F}

q22_data <- data.frame(c("n1 = 85", "x1 = 38"), c("n2 = 90", "x2 = 23"))
colnames(q22_data) <- c("Sample 1", "Sample 2")

pretty_kable(q22_data, "Samples")

```

```{r q22}

```

## 23.)

A researcher was interested in comparing the average length of time (in hours) spent watching television by women and by men. Independent simple random samples of 14 women and 17 men were selected, 
and each person was asked how many hours he or she had watched television during the previous week. 

_The summary statistics are as follows_:

```{r q23_setup, echo = F}

q23_data <- data.frame(c("x1 = 12.5 hr", "s1 = 3.9 hr", "n1 = 14"), c("x2 = 13.8 hr", "s2 = 5.2 hr", "n2 = 17"))
colnames(q23_data) <- c("Women", "Men")

pretty_kable(q23_data, "Samples")

```

+ Use a 0.05 significance level to test the claim that the average length of time spent watching television by women is smaller than the average length amount of time spent watching television by men. 
+ Use a t test for hypothesis testing. Do not assume that the population standard deviations are equal.


```{r q23}

```

## 24.)

A researcher was interested in comparing the average length of time spent watching television by women and by men. 
Independent simple random samples of 14 women and 17 men were selected, and each person asked how many hours he or she had watched television during the previous week. 

_The summary statistics are as follows_:

```{r q24_setup, echo = F}

q24_data <- data.frame(c("x1 = 11.4 hr", "s1 = 4.1 hr", "n1 = 14"), c("x2 = 16.8 hr", "s2 = 4.7 hr", "n2 = 17"))
colnames(q24_data) <- c("Women", "Men")

pretty_kable(q24_data, "Samples")

```

Use a 0.05 significance level to test the claim that the average length of time spent watching television by women is smaller than the average length of time spent watching television by men. 
Use the traditional method of hypothesis testing. 

__Assume that the population standard deviations are equal__

## 25.)

Construct a 90% confidence interval for the difference between population proportions, (p1 - p2). 

Assume that the samples are independent and that they have been randomly selected.

x1 = 15, n1 = 50 and x2 = 23, n2 = 60. 

__Do not use a continuity correction__.


+ A.) -0.232 < (p1 - p2) < 0.065 
+ B.) 0.151 < (p1 - p2) < 0.449
+ C.) 0.477 < (p1 - p2) < 0.122 
+ D.) 0.123 < (p1 - p2) < 0.477

```{r}

```

## 26.)

Use the given data to find the equation of the regression line. Round the final values to three significant digits. The variable y denotes the predicted value for the dependent variable y.


```{r q26_setup, echo = F}

q26_data <- data.frame(rbind(c(6, 8, 20, 28, 36), c(2,4,13,20,30)))
rownames(q26_data) <- c("x", "y")
colnames(q26_data) <- rep(c(""), 5)

pretty_kable(q26_data, "")

```

+ A.) y = -2.79 + 0.897x 
+ B.) y -2.79 + 0.950x 
+ C.) y = -.79 + 0.801x 
+ D.) y = -3.79 +0.897x


```{r q26}

```

## 27.)

Using the data in problem 26, construct 95% confidence intervals for the coefficients in the resulting regression model.


```{r q27_setup, echo = F}

q27_data <- data.frame(rbind(
	c("(-6.73, 1.148)", "(-6.73, 1.148)", "(-7.73, 0.148)", "(-4.73, 4.148)"),
    c("(0.724, 1.071)", "(0.774, 1.121)", "(0.724, 1.071)", "(0.654, 1.001)")))

rownames(q27_data) <- c("intercept", "x")
colnames(q27_data) <- c("A", "B", "C", "D")

pretty_kable(q27_data, "Answer Choices")

```


```{r q27}

```

## 28.)

A web service is interested in whether or not having signed up for email updates and offers is independent of purchasing choice (has purchased or has not). 
Conduct a chi-square test of independence. 
State the hypotheses, determine chi- square statistic and p-value using the contingency table below:


```{r q28_setup, echo = F}

q28_data <- data.frame(rbind(
	c(30, 60),
	c(20, 75)))

rownames(q28_data) <- c("Has signed up.", "Has not signed up.")
colnames(q28_data) <- c("Has made purchase.", "Has not made purchase.")

pretty_kable(q28_data, "Contingency Table")

```


```{r q28}

```

## 29.)

An urgent care center is interested in whether visits per day of the week are uniformly distributed. 
Conduct a chi-square goodness of fit test. State the null and alternative hypotheses. 

_Provide the chi-square value and associated p-value_.


```{r q29_setup, echo = F}

q29_data <- data.frame( cbind(c(24), c(19), c(26), c(29), c(30), c(23)))
colnames(q29_data) <- c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday")

pretty_kable(q29_data, "Visits")

```

## 30.)

Test the hypothesis of a zero correlation using the procedure shown by Wilcox in Basic Statistics. 

Assume n = 47, r = -0.286. 

Test the null hypothesis of zero correlation versus the alternative that the correlation is negative at 95% confidence. 

_Also calculate the p-value_.


```{r q30}

```

## 31.)

A project manager is trying to assemble a five-member team. She has a list of 30 volunteers that she intends to draw five (5) from randomly, so as not to alienate anyone. 
However, only four (4) of the 30 have a specific certification that the project manager knows she’ll need. 

+ What is the likelihood that two of the five members randomly selected will be one of the four with the needed certification? 
+ What is the probability that at least one of the five members randomly selected will have the needed certification?

```{r q31}

```

## 32.)

Consumers are asked to rate a company both before and after viewing a video on the company twice a day for a week. Use the paired data given below. 
Test at the 1% significance level if the “after” results are less than the “before” results. Assume the data are normally distributed.


```{r q32_setup, echo = F}

q32_data <- data.frame(rbind(
	c(1, 2, 3, 4, 5, 6, 7, 8, 9),
	c(38, 27, 30, 41, 36, 38, 33, 36, 44),
	c(22, 28,21,38,38,26,19,31,35)))

rownames(q32_data) <- c("pair", "before", "after")
colnames(q32_data) <- rep(c(""), ncol(q32_data))

pretty_kable(q32_data, "Raitings")

```

## 33.)

Random samples of men from two different towns were obtained and the weights of the men measured in pounds. 
Using the data below test the claim there is more variation in weights of men from town A versus the weights of men from town B. 

_Use a 5% significance level_.


```{r q33_setup, echo = F}

q33_data <- data.frame(rbind(
	c(41, 165.1, 26.2),
	c(21, 159.5, 24.1)))

rownames(q33_data) <- c("Town A", "Town B")
colnames(q33_data) <- c("sample size", "sample average", "Sample standard deviation")

pretty_kable(q33_data, "Samples")

```

## 34.)

Use the p-value method to test the claim that the population standard deviation of the systolic blood pressures of adults aged 40-50 is equal to 22 mmHG. 

Use the following sample statistics: n = 23, sample mean = 132.3 mmHg, and sample standard deviation s = 26.6 mmHg. 

Determine the value of the test statistic, the p-value and your conclusion. 

Use a 5% significance level. 

Assume normality. 

This is a two-sided test. 

Also, calculate a 95% confidence interval for the population standard deviation.

```{r q35}

```

## 35.)

Fill in the missing entries in the following one-way ANOVA table and determine the p-value and the critical value for the F-statistic.

```{r q35_setup, echo = F}

q35_data <- data.frame(rbind(
	c("3", "", "", "11.16"),
	c("", "13.72", "0.686", ""),
	c("", "", "", "")))

rownames(q35_data) <- c("Treatment", "Error", "Total")
colnames(q35_data) <- c("Source", "SS", "MS=SS/df", "F-statistic")

pretty_kable(q35_data, "ANOVA Table")

```

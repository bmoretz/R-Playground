update.packages()
update.packages()
install.packages("moments")
install.packages("moments", dependencies = TRUE)
library(moments)
library(moments) homeuser = file.path("C:", "Projects", "Books") chap <- "ChapIII" setwd(paste(homeuser, "/FinAnalytics/", chap, sep = "")) deck.cards <- 52 deck.hand <- 5 deck.faces <- 13 options(digits = 13) choose.long <- function(n, k) { 	as.integer( factorial( n )/ ( factorial( k ) * factorial( n - k ) ) ) } short <- choose(deck.cards, deck.hand) long <- choose.long(deck.cards, deck.hand) stopifnot(short == long) # 4 of same card (aces, for example) = # 52 cards, take 4 we need (aces), + *any* 1 additional resulting card to fill the hand. prob.card <- ( deck.cards - ( deck.hand - 1 ) ) / choose(deck.cards, deck.hand) round(prob.card * 100, 4) # 4 of a kind (same face) # 13 faces, 1 way to get it to be all the same. prob.kind <- ( deck.faces * deck.cards - ( deck.hand - 1 ) ) / choose(deck.cards, deck.hand) round(prob.kind * 100, 4) # single pair in a 5 card hand # prob pair = 13, 4 choose 2 ways of picking the pair, 13 choose 2 for picking the non-pair, 4^3 ways of choosing from non-pair faces prob.onepair <- deck.faces * choose(4, 2) * choose(12, 3) * 4 ^ 3 / choose(deck.cards, deck.hand) round(prob * 100, 2) # Annualized historic volatility from a time series (1 yr, monthly) S = c(1.3, 1.2, 1.3, 1.4, 1.5, 1.4, 1.3, 1.4, 1.5) volatility <- function( R ) { 	diffLogR <- diff( log( R ) )  	diffLogRmean <- mean(diffLogR) 	N = length(diffLogR) 	histVol = sqrt(1 / (N - 1) * sum((diffLogR - diffLogRmean) ^ 2)) 	annHistVol = histVol * sqrt(length(R)) 	annHistVol } volatility(S)
library(moments) homeuser = file.path("C:", "Projects", "Books") chap <- "ChapIII" setwd(paste(homeuser, "/FinAnalytics/", chap, sep = "")) deck.cards <- 52 deck.hand <- 5 deck.faces <- 13 options(digits = 13) choose.long <- function(n, k) { 	as.integer( factorial( n )/ ( factorial( k ) * factorial( n - k ) ) ) } short <- choose(deck.cards, deck.hand) long <- choose.long(deck.cards, deck.hand) stopifnot(short == long) # 4 of same card (aces, for example) = # 52 cards, take 4 we need (aces), + *any* 1 additional resulting card to fill the hand. prob.card <- ( deck.cards - ( deck.hand - 1 ) ) / choose(deck.cards, deck.hand) round(prob.card * 100, 4) # 4 of a kind (same face) # 13 faces, 1 way to get it to be all the same. prob.kind <- ( deck.faces * deck.cards - ( deck.hand - 1 ) ) / choose(deck.cards, deck.hand) round(prob.kind * 100, 4) # single pair in a 5 card hand # prob pair = 13, 4 choose 2 ways of picking the pair, 13 choose 2 for picking the non-pair, 4^3 ways of choosing from non-pair faces prob.onepair <- deck.faces * choose(4, 2) * choose(12, 3) * 4 ^ 3 / choose(deck.cards, deck.hand) round(prob.onepair * 100, 2) # Annualized historic volatility from a time series (1 yr, monthly) S = c(1.3, 1.2, 1.3, 1.4, 1.5, 1.4, 1.3, 1.4, 1.5) volatility <- function( R ) { 	diffLogR <- diff( log( R ) )  	diffLogRmean <- mean(diffLogR) 	N = length(diffLogR) 	histVol = sqrt(1 / (N - 1) * sum((diffLogR - diffLogRmean) ^ 2)) 	annHistVol = histVol * sqrt(length(R)) 	annHistVol } volatility(S)
library(moments)
skewness(S)
kurtosis(X)
kurtosis(S)
kurtosis(S)
require(RevoScaleR) require(data.table) homeuser = file.path("C:", "Projects", "Books") chap <- "ChapIII" setwd(paste(homeuser, "/FinAnalytics/", chap, sep = ""))
install.packages("data.table")
require(RevoScaleR) require(data.table) homeuser = file.path("C:", "Projects", "Books") chap <- "ChapIII" setwd(paste(homeuser, "/FinAnalytics/", chap, sep = ""))
install.packages("data.table")
require(RevoScaleR) require(data.table) homeuser = file.path("C:", "Projects", "Books") chap <- "ChapIII" setwd(paste(homeuser, "/FinAnalytics/", chap, sep = ""))
install.packages("foreign")
require(foreign)
require(foreign)
install.packages("foreign")
library(foreign)
require(data.table)
library(foreign)
.libPaths(c(.libPaths(), "~/userLibrary"))
.libPaths()
.libPaths()
dest <- .libPaths()
install.packages("data.table", lib = .libPaths(), dependencies = TRUE)
library(zoo)
install.packages("foreign", lib = .libPaths(), dependencies = TRUE)
library(foreign)
install.packages("foreign", lib = .libPaths(), dependencies = TRUE)
library(foreign)
install.packages("foreign", destdir = = .libPaths(), dependencies = TRUE)
install.packages("foreign", destdir = .libPaths(), dependencies = TRUE)
install.packages("foreign", destdir = .libPaths(), dependencies = TRUE)install.packages("foreign", destdir = .libPaths(), dependencies = TRUE)
install.packages("foreign", destdir = .libPaths(), dependencies = TRUE)
install.packages("data.table", destdir = .libPaths(), dependencies = TRUE)
install.packages("data.table", lib = .libPaths(), dependencies = TRUE)
library(foreign)
library(foreign)
installed.packages()
version()
version
.libPaths()
install.packages("data.table", , dependencies = TRUE)
install.packages("data.table", dependencies = TRUE)
install.packages("foreign", dependencies = TRUE)
library(foreign)
homeuser = file.path("C:", "Projects", "Books") chap <- "ChapIII" setwd(paste(homeuser, "/FinAnalytics/", chap, sep = ""))
version()
version
read.dta
funda <- read.dta("funda.dta")
msft <- read.dta("msf.dat")
msft <- read.dta("msf.dta")
data.file <- read.dta("funda.dta")
rm(funda)
rm(msft)
loadDtaFile(sqlConnection, "funda.dta", "funda")
require(RevoScaleR) require(data.table) library(foreign) homeuser = file.path("C:", "Projects", "Books") chap <- "ChapIII" setwd(paste(homeuser, "/FinAnalytics/", chap, sep = "")) # SQL sqlConnection <- "Driver=SQL Server; Server=DATACENTER; Database=Playground; User Id=bmoretz; Password=letmein;"; # Common loadDtaFile <- function(sqlConnection, fileName, sqlTable) { 	data.file <- read.dta("funda.dta") 	data.table <- RxSqlServerData( 	  connectionString = sqlConnection, 	  table = sqlTable) 	rxDataStep(inData = data.file, outFile = data.table, overwrite = T) } loadDtaFile(sqlConnection, "funda.dta", "funda") loadDtaFile(sqlConnection, "msf.dta", "msf")
require(RevoScaleR) require(data.table) library(foreign) homeuser = file.path("C:", "Projects", "Books") chap <- "ChapIII" setwd(paste(homeuser, "/FinAnalytics/", chap, sep = "")) # SQL sqlConnection <- "Driver=SQL Server; Server=DATACENTER; Database=Playground; uid=bmoretz; Password=letmein;"; # Common loadDtaFile <- function(sqlConnection, fileName, sqlTable) { 	data.file <- read.dta("funda.dta") 	data.table <- RxSqlServerData( 	  connectionString = sqlConnection, 	  table = sqlTable) 	rxDataStep(inData = data.file, outFile = data.table, overwrite = T) } loadDtaFile(sqlConnection, "funda.dta", "funda") loadDtaFile(sqlConnection, "msf.dta", "msf")
sqlConnection <- "Driver=SQL Server; Server=DATACENTER; Database=Playground; uid=bmoretz; Password=letmein;";
require(RevoScaleR) require(data.table) library(foreign) homeuser = file.path("C:", "Projects", "Books") chap <- "ChapIII" setwd(paste(homeuser, "/FinAnalytics/", chap, sep = "")) # SQL sqlConnection <- "Driver=SQL Server; Server=DATACENTER; Database=Playground; Uid=bmoretz; Pwd=letmein;"; # Common loadDtaFile <- function(sqlConnection, fileName, sqlTable) { 	data.file <- read.dta("funda.dta") 	data.table <- RxSqlServerData( 	  connectionString = sqlConnection, 	  table = sqlTable) 	rxDataStep(inData = data.file, outFile = data.table, overwrite = T) } loadDtaFile(sqlConnection, "funda.dta", "funda") loadDtaFile(sqlConnection, "msf.dta", "msf")
require(RevoScaleR) require(data.table) library(foreign) homeuser = file.path("C:", "Projects", "Books") chap <- "ChapIII" setwd(paste(homeuser, "/FinAnalytics/", chap, sep = "")) # SQL sqlConnection <- "Driver=SQL Server; Server=DATACENTER; Database=Playground; Uid=bmoretz; Pwd=letmein;"; # Common loadDtaFile <- function(sqlConnection, fileName, sqlTable) { 	data.file <- read.dta("funda.dta") 	data.table <- RxSqlServerData( 	  connectionString = sqlConnection, 	  table = sqlTable) 	rxDataStep(inData = data.file, outFile = data.table, overwrite = T) } loadDtaFile(sqlConnection, "funda.dta", "funda") loadDtaFile(sqlConnection, "msf.dta", "msf")
msf <- read.dta("msf.dta")
require(RevoScaleR) require(data.table) library(foreign) homeuser = file.path("C:", "Projects", "Books") chap <- "ChapIII" setwd(paste(homeuser, "/FinAnalytics/", chap, sep = "")) # SQL sqlConnection <- "Driver=SQL Server; Server=DATACENTER; Database=Playground; Uid=bmoretz; Pwd=letmein;"; # Common loadDtaFile <- function(sqlConnection, fileName, sqlTable) { 	data.file <- read.dta(fileName) 	data.table <- RxSqlServerData( 	  connectionString = sqlConnection, 	  table = sqlTable) 	rxDataStep(inData = data.file, outFile = data.table, overwrite = T) } loadDtaFile(sqlConnection, "funda.dta", "funda") loadDtaFile(sqlConnection, "msf.dta", "msf")
require(RevoScaleR) require(data.table) homeuser = file.path("C:", "Projects", "Books") chap <- "ChapIII" setwd(paste(homeuser, "/FinAnalytics/", chap, sep = "")) # SQL sqlConnection <- "Driver=SQL Server; Server=DATACENTER; Database=Playground; Uid=bmoretz; Pwd=letmein;"; sqlReturnData <- RxSqlServerData( 	connectionString = sqlConnection, 	sqlQuery = sprintf(' 		SELECT 			[tsymbol], 			[ret] 		FROM 			dbo.[msf] 		WHERE 			[date] BETWEEN \'%s\' AND \'%s\'  			AND 			[tsymbol] in (\'%s\', \'%s\' ) 	;', '2005-01-01', '2013-12-31', 'AAPL', 'SPY'), 	stringsAsFactors = FALSE, 	useFastRead = TRUE ) raw.data <- as.data.table(rxImport(sqlReturnData, overwrite = TRUE, stringsAsFactors = FALSE))
y <- raw.data[ raw.data$tsymbol == 'AAPL', ]$ret
x <- raw.data[raw.data$tsymbol == 'SPY',]$ret
cov(x, y) / var(x)
beta <- cov(x, y) / var(x)
summary(lm(y ~ x + 1))
cov(x, y) / var(x)
summary(lm(y ~ x + 1))
shapiro.test(x)
shapiro.test(y)
plot(x,y)
require(RevoScaleR) require(data.table) homeuser = file.path("C:", "Projects", "Books") chap <- "ChapIII" setwd(paste(homeuser, "/FinAnalytics/", chap, sep = "")) # SQL sqlConnection <- "Driver=SQL Server; Server=DATACENTER; Database=Playground; Uid=bmoretz; Pwd=letmein;"; sqlReturnData <- RxSqlServerData( 	connectionString = sqlConnection, 	sqlQuery = sprintf(' 		SELECT 			[tsymbol], 			[ret] 		FROM 			dbo.[msf] 		WHERE 			[date] BETWEEN \'%s\' AND \'%s\'  			AND 			[tsymbol] in (\'%s\', \'%s\' ) 	;', '2005-01-01', '2013-12-31', 'AAPL', 'SPY'), 	stringsAsFactors = FALSE, 	useFastRead = TRUE ) raw.data <- as.data.table(rxImport(sqlReturnData, overwrite = TRUE, stringsAsFactors = FALSE)) y <- raw.data[raw.data$tsymbol == 'AAPL',]$ret x <- raw.data[raw.data$tsymbol == 'SPY',]$ret beta_ratio <- cov(x, y) / var(x) beta_lm <- summary(lm(y ~ x + 1)) shapiro.test(x) shapiro.test(y) plot(x,y)
dt <- read.csv("dt.csv")
getwd()
getwd()
data.file.path <- file.path("C:", "Projects", "R", "Playground", "Scripts", "DataCamp", "data.table")
dt <- read.csv(data.file.path)
dt <- read.csv(data.file.path)
dt.wd <- file.path("C:", "Projects", "R", "Playground", "Scripts", "DataCamp", "data.table")
setwd(dt.wd)
dt <- read.csv("dt.csv")
require(data.table) dt.wd <- file.path("C:", "Projects", "R", "Playground", "Scripts", "DataCamp", "data.table") setwd(dt.wd) DT <- as.data.table( read.csv("dt.csv") )
require(data.table) dt.wd <- file.path("C:", "Projects", "R", "Playground", "Scripts", "DataCamp", "data.table") setwd(dt.wd) DT <- as.data.table( read.csv("dt.csv") )
DT[, c(lapply(.SD, sum), .N), by = x, .SDcols = c("x", "y", "z")]
require(data.table) dt.wd <- file.path("C:", "Projects", "R", "Playground", "Scripts", "DataCamp", "data.table") setwd(dt.wd)
# load DT DT <- as.data.table( read.csv("dt.csv") )
# Sum of all columns and the number of rows
DT[, c(lapply(.SD, sum), .N), by = x, .SDcols = c("x", "y", "z")]
colnames(DT)
DT <- as.data.table( read.csv("dt.csv") )
setNames(DT, c("x", "y", "z") DT[, c(lapply(.SD, sum), .N), by = x, .SDcols = c("x", "y", "z")]
DT <- as.data.table( read.csv("dt.csv") )
setNames(DT, c("x", "y", "z"))
# Sum of all columns and the number of rows
DT[, c(lapply(.SD, sum), .N), by = x, .SDcols = c("x", "y", "z")]
DT
t <- read.csv("dt.csv")
t <- read.csv("dt.csv", make.names = FALSE)
t <- read.csv("dt.csv", make.names = TRUE)
t <- read.csv("dt.csv", header = TRUE)
t <- read.csv("dt.csv", header = TRUE, col.names = c("x","y","z") DT <- as.data.table( read.csv("dt.csv", header = TRUE) ) DT <- as.data.table( read.csv("dt.csv", header = TRUE) )
DT <- as.data.table( read.csv("dt.csv", header = TRUE) )
DT <- as.data.table(read.csv("dt.csv", header = TRUE, col.names = c("x", "y", "z")))
setNames(DT, c("x", "y", "z"))
DT[, c(lapply(.SD, sum), .N), by = x, .SDcols = c("x", "y", "z")]
DT[DT[, z > 8,]][, lapply(.SD, cumsum), by1 = x, .SDcols = c("x", "y", "z")]
require(data.table) dt.wd <- file.path("C:", "Projects", "R", "Playground", "Scripts", "DataCamp", "data.table") setwd(dt.wd)
# load DT DT <- as.data.table(read.csv("dt.csv", header = TRUE, col.names = c("x", "y", "z"))) setNames(DT, c("x", "y", "z"))
DT # spot check
# Sum of all columns and the number of rows
DT[, c(lapply(.SD, sum), .N), by = x, .SDcols = c("x", "y", "z")]
require(data.table) dt.wd <- file.path("C:", "Projects", "R", "Playground", "Scripts", "DataCamp", "data.table") setwd(dt.wd)
# load DT DT <- as.data.table(read.csv("dt.csv", header = TRUE, col.names = c("x", "y", "z")))
# Sum of all columns and the number of rows
DT[, c(lapply(.SD, sum), .N), by = x, .SDcols = c("x", "y", "z")]
DT[DT[, z > 8,]][, c.( lapply(.SD, cumsum), .N) , by1 = x, .SDcols = c("x", "y", "z")]
DT[DT[, z > 8,]][, c.( lapply(.SD, cumsum), .N) , by = x, .SDcols = c("x", "y", "z")]
DT[DT[, z > 8,]][, c( lapply(.SD, cumsum), .N) , by = x, .SDcols = c("x", "y", "z")]
DT[DT[, z > 8,]][, lapply(.SD, cumsum), by = x, .SDcols = c("x", "y", "z")]
DT[, c(z > 8, lapply(.SD, cumsum)), by = x, .SDcols = c("x", "y", "z")]
DT[, c(by1 = z > 8, lapply(.SD, cumsum)), by = x, .SDcols = c("x", "y", "z")]
DT[, z > 8,][, c(lapply(.SD, cumsum)), by = x, .SDcols = c("x", "y", "z")]
DT[, z > 8,][, lapply(.SD, cumsum), by = x, .SDcols = c("x", "y", "z")]
DT[, z > 8,]
DT[ DT[, z > 8,] ]
DT[, .( g := z > 8),]
DT[, .(g := z > 8),]
DT[, z > 8,][, lapply(.SD, cumsum), by = by1 = x, .SDcols = c("x", "y", "z")]
DT[, lapply(.SD, cumsum), by = by1 = x, .SDcols = c("x", "y", "z")]
DT[, lapply(.SD, cumsum), by = c(by1 = x), .SDcols = c("x", "y", "z")]
DT[, lapply(.SD, cumsum), by = c(by1 = x), .SDcols = c("x", "y")]
DT[, lapply(.SD, cumsum), by = x, .SDcols = c("x", "y")]
DT[, lapply(.SD, cumsum), by = x, .SDcols = c("x", "y")]
DT
DT[, lapply(.SD, cumsum), by = z, .SDcols = c("x", "y")]
DT[, c.( lapply(.SD, cumsum) ), by = z, .SDcols = c("x", "y")]
DT[, c( lapply(.SD, cumsum) ), by = z, .SDcols = c("x", "y")]
DT[, c( lapply(.SD, cumsum) ), by = z, .SDcols = c("x", "y")]
DT[, c( lapply(.SD, cumsum) ), by = x, .SDcols = c("x", "y")]
DT[, lapply(.SD, cumsum), by = x, .SDcols = c("x", "y")]
DT[, lapply(.SD, cumsum), by1 = x, .SDcols = c("x", "y")]
DT[, z > 8]
DT[, z > 8,]
DT[, z > 8]
DT[ DT[, z > 8] ]
DT[DT[, z > 8]][, lapply(.SD, cumsum), by = x, .SDcols = c("x", "y")]
DT[, , by = c(x, z > 8 )]
DT[, , by = list(x, z > 8 )]
DT[, by1 = z > 8,]
DT[, by1 := z > 8,]
DT[, by1 := z > 8,]
DT
DT[, c( by1 = x, by1 := z > 8 ),]
DT[, c( by1 := x, by1 := z > 8 ),]
DT[, c( by1 = x, by1 = z > 8 ),]
DT[, by1 := z > 8, by = x]
DT
DT[, by1 := z > 8,][, lapply(.SD, cumsum), by = c(x, by1), .SDcols = c("x", "y")]
DT[, by1 := z > 8,][, lapply(.SD, cumsum), by = c(x, by1), .SDcols = c("x", "y")]
DT[, by1 := z > 8,][, lapply(.SD, cumsum), by = c("x", "by1"), .SDcols = c("x", "y")]
DT[, by2 := z > 8,][, c( by1 = x, lapply(.SD, cumsum), by = c("x", "by1") ), .SDcols = c("x", "y")]
DT[, by2 := z > 8,][, c( by1 = x, lapply(.SD, cumsum), by = c("by1", "by2") ), .SDcols = c("x", "y")]
DT[, by2 := z > 8,][, c( by1 = x, lapply(.SD, cumsum), by = c("by1", "by2") ), .SDcols = c("x", "y")]
DT[, by2 := z > 8,][, c( by1 = x, lapply(.SD, cumsum), by = c("x", "by2") ), .SDcols = c("x", "y")]
DT <- as.data.table(read.csv("dt.csv", header = TRUE, col.names = c("x", "y", "z")))
DT[, by2 := z > 8,][, c( by1 = x, lapply(.SD, cumsum), by = c("x", "by2") ), .SDcols = c("x", "y")]
DT
DT[, by2 := z > 8,][, lapply(.SD, cumsum), by = c("x", "by2"), .SDcols = c("x", "y")]
DT[, by2 := z > 8,][, .( by1 = x, lapply(.SD, cumsum) ), by = c("x", "by2"), .SDcols = c("x", "y")]
DT[, by2 := z > 8,][, lapply(.SD, cumsum), by = c("x", "by2"), .SDcols = c("x", "y")][, .( by1 = x, by2)]
DT[, by2 := z > 8,][, lapply(.SD, cumsum), by = c("x", "by2"), .SDcols = c("x", "y")][, .( by1 = x, by2, x,y)]
DT[, lapply(.SD, cumsum), by = c("x", "by2"), .SDcols = c("x", "y")][, .( by1 = x, by2, x,y)]
DT[, lapply(.SD, cumsum), by = c("x", "by2"), .SDcols = c("x", "y")][, .( by1 = x, by2, x,y)]
DT <- as.data.table(read.csv("dt.csv", header = TRUE, col.names = c("x", "y", "z")))
DT[, lapply(.SD, cumsum), by = c("x", "by2"), .SDcols = c("x", "y")][, .( by1 = x, by2, x,y)]
DT[, c( by2 = x > 8, lapply(.SD, cumsum), by = c("x", "by2") ), .SDcols = c("x", "y")][, .( by1 = x, by2, x,y)]
DT[, c( by2 = z > 8, lapply(.SD, cumsum), by = c("x", "by2") ), .SDcols = c("x", "y")][, .( by1 = x, by2, x,y)]
DT <- as.data.table(read.csv("dt.csv", header = TRUE, col.names = c("x", "y", "z")))
DT[, c( by2 = z > 8, lapply(.SD, cumsum), by = c("x", "by2") ), .SDcols = c("x", "y")][, .( by1 = x, by2, x,y)]
DT
DT[, c( by2 = z > 8, lapply(.SD, cumsum), by = c("x", "by2") ), .SDcols = c("x", "y")]
DT <- as.data.table(read.csv("dt.csv", header = TRUE, col.names = c("x", "y", "z")))
DT[, c( by2 = z > 8, lapply(.SD, cumsum), by = c("x", "by2") ), .SDcols = c("x", "y")]
DT[, c( by2 = z > 8, lapply(.SD, cumsum), by = c("x", "z") ), .SDcols = c("x", "y")][, .( by1 = x, by2, x,y)]
DT[, lapply(.SD, cumsum), by = .(x, z > 8)]
DT[, lapply(.SD, cumsum), by = .(x, z > 8), .SDcols = c("x","y")]
DT[, lapply(.SD, cumsum), by = .(x, z > 8), .SDcols = c("x", "y")][, .(by1 = x, by2, x, y)]
DT[, lapply(.SD, cumsum), by = .(x, z > 8), .SDcols = c("x", "y")][, .(by1 = x, by2 = z, x, y)]
DT[, lapply(.SD, cumsum), by = .(x, by2 = z > 8), .SDcols = c("x", "y")]
DT[, lapply(.SD, cumsum), by = .(by1 = x, by2 = z > 8), .SDcols = c("x", "y")]
require(data.table)
DT <- data.table(A = letters[c(1, 1, 1, 2, 2)], B = 1:5)
DT[, Total := sum(B) ,]
DT[, Total := sum(B) ,]
DT
DT[, B := B + 1,]
DT[2:4, Total2 := sum(B), by = A]
DT
DT[, Total := NULL, ]
DT[, Total := NULL, ]
DT[[3]]
require(data.table) DT <- data.table(A = letters[c(1, 1, 1, 2, 2)], B = 1:5) # Add column by reference: Total
DT[, Total := sum(B), by = A]
# Add 1 to column B
DT[, B := B + 1,]
# Add a new column Total2
DT[2:4, Total2 := sum(B), by = A]
# Remove the Total column
DT[, Total := NULL, ]
# Select the third column using `[[`
DT[[3]]
DT
DT
DT[2:3, B := NULL ]
DT[2:3, B := NULL,]
DT <- data.table(A = c(1, 1, 1, 2, 2), B = 1:5)
DT[, ':='(B = B + 1L, C = A + B, D = 2)]
DT[, my_cols := NULL,]
DT[, .(my_cols := NULL),]
DT[, my_cols := NULL,]
DT[my_cols := NULL]
DT[,my_cols := NULL,]
DT[, B := NULL,]
DT[, ':='(B = B + 1L, C = A + B, D = 2)]
DT <- data.table(A = c(1, 1, 1, 2, 2), B = 1:5)
DT[, ':='(B = B + 1L, C = A + B, D = 2)]
DT[, ':='(my_cols) = NULL,]
DT[, ':='my_cols = NULL,]
DT[, .(my_cols = NULL),]
DT[, .(my_cols = NULL),]
DT[, .(my_cols := NULL),]
DT[ 3 := NULL ]
DT[ DT[,my_cols,] ]
DT[,my_cols,]
my_cols <- c("B", "C")
DT[, .(my_cols := NULL),]
DT[, my_cols := NULL,]
DT[ DT[,my_cols,] ]
DT[[3]] = NULL
DT <- data.table(A = c(1, 1, 1, 2, 2), B = 1:5)
DT[, ':='(B = B + 1L, C = A + B, D = 2)]
# Delete my_cols
my_cols <- c("B", "C")
DT[, my_cols := NULL,]
DT[, .(my_cols := NULL),]
DT[, paste(my_cols) := NULL,]
DT[[2]] = NULL
rep(1,4)
rep(1:3,4)
require(data.table) dt.wd <- file.path("C:", "Projects", "R", "Playground", "Scripts", "DataCamp", "data.table") setwd(dt.wd) # load DT DT <- as.data.table(read.csv("dt.csv", header = TRUE))
DT
DT <- as.data.table(read.csv("dt.csv", header = TRUE, check.names = FALSE))
DT
require(data.table) dt.wd <- file.path("C:", "Projects", "R", "Playground", "Scripts", "DataCamp", "data.table") setwd(dt.wd) # load DT DT <- as.data.table(read.csv("dt.csv", header = TRUE, check.names = TRUE)) DT
read.csv("dt.csv", header = TRUE, check.names = TRUE)
DT <- as.data.table(read.csv("dt_2.csv", header = TRUE, check.names = TRUE))
DT <- as.data.table(read.csv("dt_2.csv", header = TRUE, check.names = TRUE))
DT <- as.data.table(read.csv("dt_2.csv", header = TRUE, check.names = TRUE))
DT <- as.data.table(read.csv("dt_2.csv", header = TRUE, check.names = TRUE))
DT <- as.data.table(read.csv("dt_2.csv", header = TRUE, check.names = TRUE, stringsAsFactors = FALSE))
read.csv("dt_2.csv", header = TRUE, check.names = TRUE, stringsAsFactors = FALSE)
DT <- as.data.table(read.csv("dt_2.csv", header = TRUE, check.names = TRUE, stringsAsFactors = FALSE))
DT[X := NULL]
DT[,X := NULL,]
 DT
# Set the seed
set.seed(1)
rnorm(3)
sample(1:3)
sample(1:3)
sample(1:10)
sample(1:length(DT))
for (i in 2:4)
	set(DT, i, sample(1:length(DT[[i]])), NA) 		DT
length(DT[[2]]))
DT[[2]]
length(DT[[2]])
for (i in 2:4)
	set(DT, i, sample(1:length(DT[[2]])), NA)
for (i in 2:4)
	set(DT, i, sample(1:10), NA)
for (i in 2:4)
	set(DT, sample(1:length(DT[[2]])), i, NA) 		DT
DT <- as.data.table(read.csv("dt_2.csv", header = TRUE, check.names = TRUE, stringsAsFactors = FALSE)) DT[, X := NULL,] # For loop with set # Loop through columns 2, 3, and 4, and for each one, select 3 rows at random and set the value of that column to NA. for (i in 2:4)
	set(DT, sample(1:3, length(DT[[2]])), i, NA) 		DT
sample(1:3, 10)
sample(10)
sample(10,3)
for (i in 2:4)
	set(DT, sample(10, 3), i, NA) DT
setnames(DT, tolower)
setnames(DT, tolower(colnames(DT)))
DT
DT <- data.table(a = letters[c(1, 1, 1, 2, 2)], b = 1)
paste0(colnames(DT),"_2")
setnames(DT, paste0(colnames(DT),"_2"))
colnames(DT)[1] <- "A2"
colnames(DT) <- rev(colnames(DT))
colnames(DT)[1,] <- "A2"
DT <- data.table(a = letters[c(1, 1, 1, 2, 2)], b = 1)
setnames(DT, paste0(colnames(DT),"_2"))
colnames(DT)[1] <- "A2"
colnames(DT) <- rev(colnames(DT))
# Define DT
DT <- data.table(a = letters[c(1, 1, 1, 2, 2)], b = 1)
# Add a suffix "_2" to all column names
setnames(DT, paste0(colnames(DT),"_2"))
# Change column name "a_2" to "A2"
colnames(DT)[1] <- "A2"
setorder(DT, rev(colnames(DT)))
setorder(DT, rev(colnames(DT)))
DT <- data.table(a = letters[c(1, 1, 1, 2, 2)], b = 1)
# Add a suffix "_2" to all column names
setnames(DT, paste0(colnames(DT),"_2"))
# Change column name "a_2" to "A2"
colnames(DT)[1] <- "A2"
# Reverse the order of the columns
setorder(DT, rev(colnames(DT)))
rev(colnames(DT))
setcolorder(DT, rev(colnames(DT)))
# Define DT DT <- data.table(a = letters[c(1, 1, 1, 2, 2)], b = 1) # Add a suffix "_2" to all column names setnames(DT, paste0(colnames(DT), "_2")) # Change column name "a_2" to "A2" colnames(DT)[1] <- "A2" # Reverse the order of the columns setcolorder(DT, rev(colnames(DT)))
library(data.table)
# The 'keyed' data.table DT
DT <- data.table(A = letters[c(2, 1, 2, 3, 1, 2, 3)],
				 B = c(5, 4, 1, 9, 8, 8, 6),
				 C = 6:12)
setkey(DT, A, B)
# Select the "b" group
DT["b",]
# "b" and "c" groups
DT[c("b","c")]
# The first row of the "b" and "c" groups
# First and last row of the "b" and "c" groups
# Copy and extend code for instruction 4: add printout
DT[1,c("b","c")]
DT[,c("b","c")]
DT[c("b","c")]
DT[c("b","c"),1]
DT[c("b","c")][1]
DT[c("b", "c")][1:N]
DT[c("b","c")]
DT[c("b","c")]
DT[c("b","c")]
DT[c("b","c")]
DT[c("b","c"), by = EACHI]
DT[c("b","c"), mult = "first"]
DT[c("b", "c"), mult = c("first", "last")]
DT[c("b", "c"), mult %in% c("first", "last")]
DT[c("b", "c"), mult %in% c("first", "last")]
DT[c("b", "c"), mult = c("first", "last")]
DT[c("b", "c"), mult = "last"]
DT[c("b", "c")][, mult = "last"]
DT[c("b", "c")][, mult = "first"][, mult = "last"]
DT[c("b", "c"), by = .EACHI]
DT[c("b", "c"), .N, by = .EACHI]
DT[c("b", "c"), 1:.N, by = .EACHI]
# The first row of the "b" and "c" groups
DT[c("b","c"), mult = "first"]
# First and last row of the "b" and "c" groups
DT[c("b", "c"), 1, by = .EACHI]
# The first row of the "b" and "c" groups
DT[c("b","c"), mult = "first"]
# First and last row of the "b" and "c" groups
DT[ DT[c("b", "c"), 1, by = .EACHI] ]
DT[ DT[c("b", "c"), 1:N, by = .EACHI] ]
DT[ DT[c("b", "c"), 1:.N, by = .EACHI] ]
DT[ DT[c("b", "c"), .N, by = .EACHI] ]
DT[ DT[c("b", "c"), 1:3, by = .EACHI] ]
DT[c("b","c"), mult = "first"]
DT[ DT[c("b", "c"), 1, by = .EACHI] ]
print("")
DT[c("b","c"), mult = "first"]
print("")
DT[ DT[c("b", "c"), 1, by = .EACHI] ]
DT[ DT[c("b", "c"), .N = 1, by = .EACHI] ]
DT[ DT[c("b", "c"), .N == 1, by = .EACHI] ]
DT[c("b", "c"), .N == 1, by = .EACHI]
DT[ DT[c("b", "c"), .N == 1, by = .EACHI] ]
DT[ DT[c("b", "c"), .N, by = .EACHI] ]
DT
DT[c("b","c")]
DT[ DT[c("b", "c"), .N, by = .EACHI] ]
DT[c("b","c"), mult = "first"]
DT[ DT[c("b", "c"), .N, by = .EACHI] ]
DT[c("b", "c"), .N, by = .EACHI]
DT[, lapply(.SD, sum), by = .EACHI, .SDCols = c("b", "c")]
DT[, lapply(.SD, sum), by = .EACHI, .SDcols = c("b", "c")]
DT[, lapply(.SD, sum), by = .EACHI, .SDcols = b:c]
DT
DT[, lapply(.SD, sum), by = .EACHI, .SDcols = B:C]
DT[, .SD = 1:.N, by = .EACHI, .SDcols = B:C]
DT[, .SD, by = .EACHI, .SDcols = B:C]
DT[ .SD, by = .EACHI, .SDcols = B:C]
DT[, .SD, by = .EACHI, .SDcols = B:C]
X = data.table(x = c(1, 1, 1, 2, 2, 5, 6), y = 1:7, key = "x") Y = data.table(x = c(2, 6), z = letters[2:1], key = "x")
X[Y]
X
Y
X[Y]
X[Y, .N] # count of matches
X[Y, .N, by = .EACHI] # count of matches, explicit
X[Y, .N, by = .EACHI] # count of group (EACHI) matches, explicit
X[Y, list( Total = sum(.N), Group = .N), by = .EACHI] # count of group (EACHI) matches, explicit
X[Y, list( Total = lapply(.N, sum), Group = .N), by = .EACHI] # count of group (EACHI) matches, explicit
X[Y, list( Total = lapply(.N, sum), Group = .N, .I), by = .EACHI] # count of group (EACHI) matches, explicit
X[Y, list( Total = lapply(.I, sum), Group = .N), by = .EACHI] # count of group (EACHI) matches, explicit
X[Y, list( Total = lapply(.I, count), Group = .N), by = .EACHI] # count of group (EACHI) matches, explicit
X[Y, list( Total = distinct(.I), Group = .N), by = .EACHI] # count of group (EACHI) matches, explicit
X[Y, list( Total = unique(.I), Group = .N), by = .EACHI] # count of group (EACHI) matches, explicit
X[Y, list( Total = sum(.I), Group = .N), by = .EACHI] # count of group (EACHI) matches, explicit
X[Y, list( Total = nrow(.I), Group = .N), by = .EACHI] # count of group (EACHI) matches, explicit
X[Y, list( Total = sum(.I >= 0 ), Group = .N), by = .EACHI] # count of group (EACHI) matches, explicit
X[Y, list( Total = sum(.I > 0 ), Group = .N), by = .EACHI] # count of group (EACHI) matches, explicit
X[Y, list( Group = .N), by = .EACHI][, list( Total = sum(group), Group )]  # count of group (EACHI) matches, explicit
X[Y, list( Group = .N), by = .EACHI][, list( Total = sum(group), .Group )]  # count of group (EACHI) matches, explicit
X[Y, list( Group = .N), by = .EACHI][, list( Total = sum(group), Group )]  # count of group (EACHI) matches, explicit
X[Y, list( Group = .N), by = .EACHI]
X[Y, list( Group = .N), by = .EACHI][, list( Total = sum(Group), Group )]  # count of group (EACHI) matches, explicit
X[Y, list( Group = .N), by = .EACHI][, list( x, Total = sum(Group), Group )]  # count of group (EACHI) matches, explicit
X[Y, list(GroupTotal = .N), by = .EACHI][, list(x, GroupTotal, GrandTotal = sum(Group))] # count of group (EACHI) matches, explicit
X[Y, list(GroupTotal = .N), by = .EACHI][, list(x, GroupTotal, GrandTotal = sum(GroupTotal))] # count of group (EACHI) matches, explicit
X[Y, list(Group = .N), by = .EACHI][, list( X = x, Group, total = sum(Group))] # count of group (EACHI) matches, explicit
DT[c("b","c"), .SD, by = .EACHI]
DT[c("b","c"), list( N = .N, SD = .SD ), by = .EACHI]
DT[c("b","c"), list( N := .N, SD := .SD ), by = .EACHI]
DT[c("b","c"), .N, by = .EACHI]
DT[c("b","c"), .SD, by = .EACHI]
DT[c("b","c"), by = .EACHI, .SDcols = B:C]
DT[,, by = .EACHI, .SDcols = B:C]
DT[,.N, by = .EACHI, .SDcols = B:C]
DT[,.SD, by = .EACHI, .SDcols = B:C]
DT[c("b","c"), lapply(.SD, sum), by = .EACHI, .SDcols = B:C]
DT[c("b", "c"), .SD, by = .EACHI, .SDcols = B:C]
DT[c("b", "c"), list( B, C, N = .SD ), by = .EACHI, .SDcols = B:C]
DT[, list( B, C, N = .SD ), by = .EACHI, .SDcols = B:C]
DT[, list( B, C, N := .SD ), by = .EACHI, .SDcols = B:C]
DT[.SD, , by = .EACHI]
DT[, .SD, by = .EACHI]
set.seed(10238) DT <- data.table(A = rep(1:3, each = 5), B = rep(1:5, 3), 				 C = sample(15), D = sample(15)) DT
DT[, lapply(.SD, sum)]
DT[, lapply(.SD, sum), by = A]
DT[, lapply(.SD, sum), .SDcols = !"A"]
DT[, lapply(.SD, sum), by = B, .SDcols = !"A"]
DT[, lapply(.SD, sum), by = .EACHI, .SDcols = B:C]
DT[, lapply(.SD, sum), 'by' = .EACHI, .SDcols = B:C]
DT[, lapply(.SD, sum), by= EACHI, .SDcols = B:C]
library(data.table)
# The 'keyed' data.table DT
DT <- data.table(A = letters[c(2, 1, 2, 3, 1, 2, 3)],
				 B = c(5, 4, 1, 9, 8, 8, 6),
				 C = 6:12)
setkey(DT, A, B)
# First and last row of the "b" and "c" groups (Use by = .EACHI and .SD to select the first and last row of the "b" and "c" groups.)
DT[, lapply(.SD, sum), by= .EACHI, .SDcols = B:C]
# The first row of the "b" and "c" groups (Select the first row of the "b" and "c" groups using mult.)
DT[c("b","c"), mult = "first"]
# First and last row of the "b" and "c" groups (Use by = .EACHI and .SD to select the first and last row of the "b" and "c" groups.)
DT[, lapply(.SD, sum), by= .EACHI, .SDcols = B:C]
DT[, lapply(.SD, sum), by = B, .SDcols = !"A"]
DT[, lapply(.SD, sum), by= A, .SDcols = B:C]
DT[c("b","c"), mult = "first"]
DT[, lapply(.SD, sum), by= A, .SDcols = A]
DT[, lapply(.SD, sum), by= A, .SDcols = B:C]
DT[, lapply(.SD, first), by= A, .SDcols = B:C]
DT[, lapply(.SD, sum), by= A, .SDcols = B:C]
DT[, .SD, by= A, .SDcols = B:C]
DT[, A := .SD, by= A, .SDcols = B:C]
DT[, A := min(.SD), by= A, .SDcols = B:C]
DT[, A := lapply(.SD,print), by= A, .SDcols = B:C]
DT[, lapply(.SD,print), by= A, .SDcols = B:C]
DT[, lapply(.SD,FUN = function(x){print(x)}), by= A, .SDcols = B:C]
DT[, lapply(.SD,FUN = function(x){print(x)}), by= A, .SDcols = B:C]
DT[, lapply(.SD,sum), by= A, .SDcols = B:C]
DT[, .SD[, sum], by= A, .SDcols = B:C]
DT[, .SD[, sum(B)], by= A, .SDcols = B:C]
DT[, .SD[, which(.N == 1)], by= A, .SDcols = B:C]
DT[, .SD[, which(.N = 1)], by= A, .SDcols = B:C]
DT[, .SD[which(.N == 1)], by= A, .SDcols = B:C]
DT[, .SD[.N == 1], by= A, .SDcols = B:C]
DT[, .SD[1:.N], by= A, .SDcols = B:C]
DT[, .SD[which(.I == 1)], by= A, .SDcols = B:C]
DT[, .SD[,which(.I == 1)], by= A, .SDcols = B:C]
DT[, .SD[which(.I == 1)], by= A, .SDcols = B:C]
DT[, .SD[.I == 1], by= A, .SDcols = B:C]
DT[, .SD[.N == 1], by= A, .SDcols = B:C]
DT[, .SD[.I == 1], by= A, .SDcols = B:C]
DT[, .SD[.I == 1 | .I = .N], by= A, .SDcols = B:C]
DT[, .SD[.I == 1 || .I = .N], by= A, .SDcols = B:C]
DT[, .SD[.I == 1 || .I == .N], by= A, .SDcols = B:C]
# The first row of the "b" and "c" groups (Select the first row of the "b" and "c" groups using mult.)
DT[c("b","c"), mult = "first"]
DT[, .SD[.I == 1 | .I == .N], by= A, .SDcols = B:C]
DT[c("b","c"), .SD[.I == 1 | .I == .N], by= A, .SDcols = B:C]
DT[, .SD[.I == 1 | .I == .N], by= A, .SDcols = B:C]
DT[, .SD[.I == 1 || .I == .N], by= A, .SDcols = B:C]
DT[, .SD[.I == 1 || .I == .N], by= .EACHI, .SDcols = B:C]
DT[, .SD[.I == 1 || .I == .N], by= .EACHI, .SDcols = B:C, mult = "all"]
DT[, .SD[.I == 1 || .I == .N], by= A, .SDcols = B:C]
DT[, .SD[,by = .EACHI], by= A, .SDcols = B:C]
DT[, .SD[, .N == 1,,by = .EACHI], by= A, .SDcols = B:C]
DT[, .SD[, .N == 1,by = .EACHI], by= A, .SDcols = B:C]
DT[, .SD[, .N == 1, by = .EACHI], by= A, .SDcols = B:C]
DT[, .SD[, , by = .EACHI], by= A, .SDcols = B:C]
DT[, .SD[, .N == 1, by = .EACHI], by= A, .SDcols = B:C]
DT[, .SD[ .N == 1, by = .EACHI], by= A, .SDcols = B:C]
DT[, .SD[, 1:2, by = .EACHI], by= A, .SDcols = B:C]
DT[, .SD[1:2,, by = .EACHI], by= A, .SDcols = B:C]
DT[, .SD[.I:.N], by= A, .SDcols = B:C]
DT[, .SD[.I:.N], by= A, .SDcols = B:C]
DT[, .SD[.N], by= A, .SDcols = B:C]
DT[, .SD[1 OR .N], by= A, .SDcols = B:C]
DT[, .SD[1 || .N], by= A, .SDcols = B:C]
DT[, .SD[1 | .N], by= A, .SDcols = B:C]
DT[, .SD[.N == 1 | .N == .N], by= A, .SDcols = B:C]
DT[, .SD[.N], by= A, .SDcols = B:C]
DT[, .SD[.N], by= A, .SDcols = B:C]
DT[, .SD[,.N, by = .EACHI], by= A, .SDcols = B:C]
DT[, , by= A, .SDcols = B:C]
DT[, , by= A, .SDcols = B:C][, .N, by = .EACHI]
DT[, .N == nrow(.SD), by= A, .SDcols = B:C]
DT[, .SD[.N == nrow(.SD)], by= A, .SDcols = B:C]
DT[, .SD[.I == nrow(.SD)], by= A, .SDcols = B:C]
DT[, .SD[.N == nrow(.SD)], by= A, .SDcols = B:C]
DT[, .SD[.N == 1], by= A, .SDcols = B:C]
DT[, .SD[,.N == 1], by= A, .SDcols = B:C]
DT[, .SD[.N == 1], by= A, .SDcols = B:C]
DT[, .SD[.N], by= A, .SDcols = B:C]
DT[, C := .SD[.N], by= A, .SDcols = B:C]
DT[, C := .SD[.N], by= A, .SDcols = B:C]
DT[, Ct := .SD[.N], by= A, .SDcols = B:C]
DT[, Ct := .SD[.N], by= A, .SDcols = B:C]
DT[, Ct := .SD[.N], by= A, .SDcols = B:C]
DT[, (Ct := .SD[.N]), by= A, .SDcols = B:C]
DT[, (Ct = .SD[.N]), by= A, .SDcols = B:C]
DT[, .SD[.N], by= A, .SDcols = B:C]
DT[, .SD[xor(1, .N)], by = A, .SDcols = B:C]
DT[, .SD[xor(.N == 1, .N)], by = A, .SDcols = B:C]
DT[, .SD[xor(.N == 1, .N == .N)], by = A, .SDcols = B:C]
DT[, .SD[or(.N == 1, .N == .N)], by = A, .SDcols = B:C]
DT[, .SD[.N == 1 | .N], by = A, .SDcols = B:C]
DT[, .SD[1 | .N], by = A, .SDcols = B:C]
DT[, .SD[1 || .N], by = A, .SDcols = B:C]
DT[, .SD[1 | .N], by = A, .SDcols = B:C]
DT[, .SD[.N], by = A, .SDcols = B:C]
DT[, .SD[.N] | .SD[1], by = A, .SDcols = B:C]
DT[, .SD[.N] || .SD[1], by = A, .SDcols = B:C]
DT[, .SD[length(.SD)], by = A, .SDcols = B:C]
DT[, .SD[length(.SD), by = .EACHI], by = A, .SDcols = B:C]
DT[, .SD[,length(.SD), by = .EACHI], by = A, .SDcols = B:C]
DT[, .SD[, .SD == length(.SD), by = .EACHI], by = A, .SDcols = B:C]
DT[, .SD[.N], by = A, .SDcols = B:C]
DT[, { .SD[.N]; print(.N) }, by = A, .SDcols = B:C]
DT[, { print(.N) ; .SD[.N] }, by = A, .SDcols = B:C]
DT[, { print(.N) ; .SD[.N] }, by = A, .SDcols = B:C]
DT[, { print(.SD) ; .SD[.N] }, by = A, .SDcols = B:C]
DT[, { print(.SD) ; .SD[1|.N] }, by = A, .SDcols = B:C]
DT[, { print(.SD) ; .SD[c(1, .N)] }, by = A, .SDcols = B:C]
DT[, .SD[c(1, .N)], by = A, .SDcols = B:C]
# Copy and extend code for instruction 4: add printout
DT[, { print(.SD); .SD[c(1, .N)] }, by = A, .SDcols = B:C]
# First and last row of the "b" and "c" groups (Use by = .EACHI and .SD to select the first and last row of the "b" and "c" groups.)
DT[c("b","c"), .SD[c(1, .N)], by = A, .SDcols = B:C]
# Copy and extend code for instruction 4: add printout
DT[c("b", "c"), { print(.SD); .SD[c(1, .N)] }, by = A, .SDcols = B:C]
# The 'keyed' data.table DT
DT <- data.table(A = letters[c(2, 1, 2, 3, 1, 2, 3)],
				 B = c(5, 4, 1, 9, 8, 8, 6),
				 C = 6:12)
setkey(DT, A, B)
DT
DT[,.(B,4)]
DT[,.(B,4),]
DT[,.("b",4),]
DT[,.("b",4)]
DT[.("b",4)]
DT[.("b",4)]
DT[.("b",4), roll = TRUE]
DT[.("b", 4), roll = TRUE]
DT[.("b",4), roll = nearest]
DT[.("b",4), roll = "nearest"]
DT[.("b",4), roll = "nearest"]
DT[.("b",4), roll = -Inf]
DT[.("b", 4), roll = Inf]
DT[.("b", 4), roll = -Inf]
DT[.("b", 4), roll = Inf]
DT[.("b",4), roll = -2]
DT[.("b",4), roll = -1]
DT[.("b",4), roll = -2]
DT[.("b",4), roll = -1]
DT[.("b",3), roll = -1]
DT[.("b",3), roll = -2]
DT[.("b",3), roll = -1]
DT[.("b",3), roll = -1]
DT[.("b", 4), roll = -1]
DT[.("b", 4), roll = 1]
DT[.("b", 3), roll = 1]
DT[.("b", 3), roll = 2]
DT[.("b", 7:8), roll = 2, limit = TRUE]
DT[.("b", 7:8), roll = 2, rollends = TRUE]
DT[.("b", 3), roll = 2]
DT[.("b", 3), roll = 1]
DT[.("b", 3), roll = -1]
DT[.("b", 2), roll = -1]
DT[.("b", 1), roll = -1]
DT[.("b", 2), roll = -1]
DT[.("b", 2), roll = 2]
DT[.("b", 2), roll = 1]
DT[.("b", 2), roll = 1]
DT[.("b",3), roll = -1]
DT[.("b", 7:8), roll = 2, rollends = TRUE]
# Keyed data.table DT
DT <- data.table(A = letters[c(2, 1, 2, 3, 1, 2, 3)],
				 B = c(5, 4, 1, 9, 8, 8, 6),
				 C = 6:12,
				 key = "A,B")
# Get the key of DT
# Row where A == "b" and B == 6
# Return the prevailing row
# Return the nearest row
key(DT)
library(data.table)
# Keyed data.table DT
DT <- data.table(A = letters[c(2, 1, 2, 3, 1, 2, 3)],
				 B = c(5, 4, 1, 9, 8, 8, 6),
				 C = 6:12,
				 key = "A,B")
# Get the key of DT
key(DT)
DT[.("b",6)]
DT[.("b", 6), roll = TRUE]
DT[.("b", 6), roll = "nearest"]
DT[-2:10,by=B]
DT[-2:10]
DT[,-2:10]
DT[,-2:10, by = B]
DT[.("b", -2:10)]
DT[.("b", -2:10), roll = TRUE]
DT[.("b", -2:10)]
DT[.("b", -2:10), roll = TRUE]
DT[.("b", -2:10), roll = TRUE, rolllimit = -1]
DT[.("b", -2:10), roll = TRUE, rollends = TRUE]
function(school = "private", acad_motivation = 0, relig_motivation = 0) {
	eval(.expression)
}
test_case <- function(school = "private", acad_motivation = 0, relig_motivation = 0) {
	eval(.expression)
}
test_scores(school = "private", 			acad_motivation = 1, 			relig_motivation = 3)
test_scores <- function(school = "private", acad_motivation = 0, relig_motivation = 0) {
	eval(.expression)
}
test_scores(school = "private", 			acad_motivation = 1, 			relig_motivation = 3)
test_scores(school = "public", 			acad_motivation = 0, 			relig_motivation = 0)
install.packages(mosiac)
install.packages("mosiac")
install.packages("statisticalModeling")
install.packages("statisticalModeling")
install.packages("mosaicData")
install.packages("mosaic")
library(mosiac)
library(mosiac)
library(mosiac)
install.packages("mosaic")
library(mosiac)
library(mosaic)
data(cp"CPS85", package = "mosiacData")
data("CPS85", package = "mosiacData")
library(mosaicData)
data("CPS85", package = "mosiacData")
data("CPS85", package = "mosaicData")
data(CPS85)
install.packages("statisticalModeling")
names(mosaicData::Riders)
# Use data() to load Trucking_jobs
data("Trucking_jobs", package = "statisticalModeling")
# View the number rows in Trucking_jobs
nrow(Trucking_jobs)
# Use names() to find variable names in mosaicData::Riders
names(mosaicData::Riders)
# Load ggplot2 package
library(ggplot2)
# Look at the head() of diamonds
head(diamonds)names(mosaicData::Riders)
data("Trucking_jobs", package = "mosaicData")
library(mosaicData)
# Use data() to load Trucking_jobs
data("Trucking_jobs", package = "mosaicData")
# View the number rows in Trucking_jobs
nrow(Trucking_jobs)
# Use names() to find variable names in mosaicData::Riders
names(mosaicData::Riders)
# Load ggplot2 package
library(ggplot2)
# Look at the head() of diamonds
head(diamonds)
data("Trucking_jobs")
getwd()
load("DataCamp")
load("DataCamp\stastical.modeling_1\data\Trucking_jobs.rda")
load("DataCamp\\stastical.modeling_1\\data\\Trucking_jobs.rda")
# Use data() to load Trucking_jobs
load("DataCamp\\stastical.modeling_1\\data\\Trucking_jobs.rda")
# View the number rows in Trucking_jobs
nrow(Trucking_jobs)
# Use names() to find variable names in mosaicData::Riders
names(mosaicData::Riders)
# Load ggplot2 package
library(ggplot2)
# Look at the head() of diamonds
head(diamonds)load("DataCamp\\stastical.modeling_1\\data\\Trucking_jobs.rda")
library(mosaicData)
head(diamonds)
library(mosaicData)
# Use data() to load Trucking_jobs
load("DataCamp\\stastical.modeling_1\\data\\Trucking_jobs.rda")
# View the number rows in Trucking_jobs
nrow(Trucking_jobs)
# Use names() to find variable names in mosaicData::Riders
names(mosaicData::Riders)
# Load ggplot2 package
library(ggplot2)
# Look at the head() of diamonds
head(diamonds)
source("C:/Projects/R/Playground/Scripts/DataCamp/stastical.modeling_1/_working.R", encoding = "Windows-1252")
library(mosaicData)
# Use data() to load Trucking_jobs
load("DataCamp\\stastical.modeling_1\\data\\Trucking_jobs.rda")
# View the number rows in Trucking_jobs
nrow(Trucking_jobs)
# Use names() to find variable names in mosaicData::Riders
names(mosaicData::Riders)
# Load ggplot2 package
library(ggplot2)
# Look at the head() of diamonds
head(diamonds)
load("DataCamp\\stastical.modeling_1\\data\\AARP.rda")
names(AARP)
mosaic::mean(cost ~ sex, data = AARP)
names(AARP)
mosaic::mean(Cost ~ sex, data = AARP)
mosaic::mean(Cost ~ Sex, data = AARP)
library(ggplot2)
ggplot(AARP, aes(Cost ~ Sex))
ggplot(AARP, aes(Cost,Sex))
ggplot(AARP, aes( x = Cost, y = Sex))
ggplot(AARP, aes( x = Cost, y = Sex)) %>% box()
geom_boxplot(AARP, aes( x = Cost, y = Sex))
ggplot(AARP, aes( x = Cost, y = Sex)) + geom_boxplot()
ggplot(AARP, aes( Cost ~ Sex)) + geom_boxplot()
x =  ggplot(Cost ~ Sex,datat = AARP) + geom_boxplot()
ggplot(aes(Cost ~ Sex),datat = AARP) + geom_boxplot()
ggplot(aes(Cost ~ Age), datat = AARP) + geom_boxplot()
ggplot(aes(Cost ~ Age), datat = AARP) + geom_point()
ggplot(aes(Cost, Age), datat = AARP) + geom_point()
ggplot(aes(x = Cost, y = Age), datat = AARP) + geom_point()
ggplot(aes(x = Cost, y = Age), datat = AARP) + geom_point()
ggplot(aes(Cost ~ Sex), datat = AARP) + geom_boxplot()
ggplot(aes(x=Cost, y=Sex), datat = AARP) + geom_boxplot()
ggplot(aes(x=Cost, y=Sex), data = AARP) + geom_boxplot()
ggplot(aes(x = Cost, y = Age), data = AARP) + geom_point()
ggplot(aes(x=Cost, y=Sex), data = AARP) + geom_boxplot()
ggplot(aes(x=Sex, y=Cost), data = AARP) + geom_boxplot()
# Create a boxplot using base, lattice, or ggplot2
ggplot(aes(x=Sex, y=Cost), data = AARP) + geom_boxplot()
# Make a scatterplot using base, lattice, or ggplot2
ggplot(aes(x = Cost, y = Age), data = AARP) + geom_point()
ggplot(Sex ~ Cost, data = AARP) + geom_boxplot()
ggplot(aes(Sex ~ Cost), data = AARP) + geom_boxplot()
gf_boxplot(Sex ~ Cost)
ggplot(aes(x=Sex, y=Cost), data = AARP) + geom_boxplot()
file <- "DataCamp\importing.data_1\swimming_pools.csv"
library(utils) file <- "DataCamp\importing.data_1\swimming_pools.csv"
file <- "DataCamp\\importing.data_1\swimming_pools.csv"
library(utils) file <- "DataCamp\\importing.data_1\\swimming_pools.csv"
library(utils) file.sp <- "DataCamp\\importing.data_1\\swimming_pools.csv" read.csv(file = file.sp)
library(utils) file.sp <- c(getwd(), "DataCamp\\importing.data_1\\swimming_pools.csv") read.csv(file = file.sp)
library(utils) file.sp <- c(getwd(), "\\DataCamp\\importing.data_1\\swimming_pools.csv") read.csv(file = file.sp)
rm(file)
library(utils) file.sp <- c(getwd(), "\\DataCamp\\importing.data_1\\swimming_pools.csv") read.csv(file = file.sp)
file.sp <- paste0(getwd(), "\\DataCamp\\importing.data_1\\swimming_pools.csv")
read.csv(file = file.sp)
library(utils) file.sp <- paste0("\\DataCamp\\importing.data_1\\swimming_pools.csv") read.csv(file = file.sp)
library(utils) file.sp <- paste0("..\\DataCamp\\importing.data_1\\swimming_pools.csv") read.csv(file = file.sp)
dir()
library(utils) file.sp <- paste0("\\DataCamp\\importing.data_1\\swimming_pools.csv") read.csv(file = file.sp) dir()
dir(file.sp)
read.csv(file = file.sp)
library(utils) file.sp <- paste0("DataCamp\\importing.data_1\\swimming_pools.csv") read.csv(file = file.sp)
RPROJ <- list(PROJHOME = normalizePath(getwd()))
attach(RPROJ)
rm(RPROJ)
file.sp <- file.path(RPROJ, "DataCamp\importing.data_1\data")
file.sp <- file.path(RPROJ, "DataCamp\\importing.data_1\\data")
RPROJ <- list(PROJHOME = normalizePath(getwd())) file.sp <- file.path(RPROJ, "DataCamp\\importing.data_1\\data")
file.sp <- file.path(RPROJ, "DataCamp\\importing.data_1\\data\\swimming_ools.csv")
library(utils) RPROJ <- list(PROJHOME = normalizePath(getwd())) file.sp <- file.path(RPROJ, "DataCamp\\importing.data_1\\data\\swimming_ools.csv") read.csv(file = file.sp)
library(utils) RPROJ <- list(PROJHOME = normalizePath(getwd())) file.sp <- file.path(RPROJ, "DataCamp\\importing.data_1\\data\\swimming_pools.csv") read.csv(file = file.sp)
library(utils) RPROJ <- list(PROJHOME = normalizePath(getwd())) file.sp <- file.path(RPROJ, "DataCamp\\importing.data_1\\data\\swimming_pools.csv") pools <- read.csv(file = file.sp)
library(utils) RPROJ <- list(PROJHOME = normalizePath(getwd())) file.sp <- file.path(RPROJ, "DataCamp\\importing.data_1\\data\\swimming_pools.csv") pools <- read.csv(file = file.sp) str(pools)
library(utils) RPROJ <- list(PROJHOME = normalizePath(getwd())) file.sp <- file.path(RPROJ, "DataCamp\\importing.data_1\\data\\swimming_pools.csv") # Import swimming_pools.csv: pools pools <- read.csv(file = file.sp)
# Print the structure of pools str(pools)
RPROJ <- list(PROJHOME = normalizePath(getwd()))
dir()
t <- dir()
rm(t)
RPROJ <- list(PROJHOME = normalizePath(getwd()))
setwd(RPROJ, "DataCamp\\importing.data_1\\data\\")
RPROJ <- list(PROJHOME = normalizePath(getwd()))
setwd(paste0(RPROJ, "DataCamp\\importing.data_1\\data\\"))
library(utils) RPROJ <- list(PROJHOME = normalizePath(getwd())) swimming_pools <- file.path(RPROJ, "DataCamp\\importing.data_1\\data\\") # Import swimming_pools.csv: pools pools <- read.csv(file = swimming_pools, stringsAsFactors = FALSE)
# Print the structure of pools str(pools)
library(utils) RPROJ <- list(PROJHOME = normalizePath(getwd())) swimming_pools <- file.path(RPROJ, "DataCamp\\importing.data_1\\data\\swimming_pools.csv") # Import swimming_pools.csv: pools pools <- read.csv(file = swimming_pools, stringsAsFactors = FALSE)
# Print the structure of pools str(pools)
library(utils) RPROJ <- list(PROJHOME = normalizePath(getwd())) swimming_pools <- file.path(RPROJ, "DataCamp\\importing.data_1\\data\\swimming_pools.csv") # Import swimming_pools.csv: pools pools <- read.csv(file = swimming_pools)
# Print the structure of pools str(pools) # Import swimming_pools.csv correctly: pools
pools <- read.csv(file = swimming_pools, stringsAsFactors = FALSE)
# Check the structure of pools
str(pools)
# Import swimming_pools.csv: pools pools <- read.csv(file = swimming_pools)
# Print the structure of pools str(pools)
# Import swimming_pools.csv correctly: pools
pools <- read.csv(file = swimming_pools, stringsAsFactors = FALSE)
# Check the structure of pools
# Import swimming_pools.csv correctly: pools
pools <- read.csv(file = swimming_pools, stringsAsFactors = FALSE)
# Check the structure of pools
str(pools)
RPROJ <- list(PROJHOME = normalizePath(getwd()))
DATADIR <- "DataCamp\\importing.data_1\\data\\
RPROJ <- list(PROJHOME = normalizePath(getwd()))
RPROJ <- list(PROJHOME = normalizePath(getwd()))
DATADIR <- paste0(RPROJ, "DataCamp\\importing.data_1\\data\\")
RPROJ <- list(PROJHOME = normalizePath(getwd())) DATADIR <- paste0(RPROJ, normalizePath("DataCamp\\importing.data_1\\data\\"))
rm(file.sp)
RPROJ$PROJHOME
library(utils) RPROJ <- list(PROJHOME = normalizePath(getwd())) RPROJ$DATA <- paste0(RPROJ, normalizePath("DataCamp\\importing.data_1\\data\\"))
RPROJ <- list(HOME = normalizePath(getwd())) RPROJ$DATA <- paste0(RPROJ$HOME, normalizePath("DataCamp\\importing.data_1\\data\\"))
swimming_pools <- file.path(RPROJ$DATA, "swimming_pools.csv")
swimming_pools
RPROJ <- list(HOME = normalizePath(getwd())) RPROJ$DATA <- paste0(RPROJ$HOME, normalizePath("DataCamp\\importing.data_1\\data")) swimming_pools <- file.path(RPROJ$DATA, "swimming_pools.csv")
RPROJ <- list(HOME = normalizePath(getwd())) RPROJ$DATA <- paste0(RPROJ$HOME, normalizePath("DataCamp\\importing.data_1\\data")) swimming_pools <- file.path(RPROJ$DATA, "swimming_pools.csv") swimming_pools
swimming_pools <- normalizePath(RPROJ$DATA, "swimming_pools.csv") swimming_pools
swimming_pools <- normalizePath(RPROJ$DATA, "\\swimming_pools.csv")
RPROJ <- list(HOME = normalizePath(getwd())) RPROJ$DATA <- paste0(RPROJ$HOME, normalizePath("DataCamp\\importing.data_1\\data")) swimming_pools <- file.path(RPROJ$DATA, "swimming_pools.csv")
RPROJ$DATA
RPROJ <- list(HOME = normalizePath(getwd()))
RPROJ$DATA <- paste0(RPROJ$HOME, normalizePath("DataCamp\\importing.data_1\\data\\"))
swimming_pools <- file.path( paste0( RPROJ$DATA, "swimming_pools.csv"))
swimming_pools
swimming_pools <- file.path(paste0( RPROJ$DATA, "swimming_pools.csv"))
hotdogs <- file.path(paste0(RPROJ$DATA, "hotdogs.txt"))
hotdogs.txt <- file.path(paste0(RPROJ$DATA, "hotdogs.txt"))
swimming_pools.csv <- file.path(paste0( RPROJ$DATA, "swimming_pools.csv"))
library(utils) RPROJ <- list(HOME = normalizePath(getwd())) RPROJ$DATA <- paste0(RPROJ$HOME, normalizePath("DataCamp\\importing.data_1\\data\\")) swimming_pools.csv <- file.path(paste0( RPROJ$DATA, "swimming_pools.csv")) ## CSV # Import swimming_pools.csv: pools pools <- read.csv(file = swimming_pools.csv)
# Print the structure of pools str(pools) # Import swimming_pools.csv correctly: pools
pools <- read.csv(file = swimming_pools.csv, stringsAsFactors = FALSE)
# Check the structure of pools
str(pools)
hotdogs.txt <- file.path(paste0(RPROJ$DATA, "hotdogs.txt"))
## TXT / DELM
# Import hotdogs.txt: hotdogs
hotdogs <- read.delim( file = hot)
# Summarize hotdogs
library(utils) RPROJ <- list(HOME = normalizePath(getwd())) RPROJ$DATA <- paste0(RPROJ$HOME, normalizePath("DataCamp\\importing.data_1\\data\\")) swimming_pools.csv <- file.path(paste0( RPROJ$DATA, "swimming_pools.csv")) ## CSV # Import swimming_pools.csv: pools pools <- read.csv(file = swimming_pools.csv)
# Print the structure of pools str(pools) # Import swimming_pools.csv correctly: pools
pools <- read.csv(file = swimming_pools.csv, stringsAsFactors = FALSE)
# Check the structure of pools
str(pools)
hotdogs.txt <- file.path(paste0(RPROJ$DATA, "hotdogs.txt"))
## TXT / DELM
# Import hotdogs.txt: hotdogs
hotdogs <- read.delim( file = hot)
# Summarize hotdogs
swimming_pools.csv <- file.path(paste0( RPROJ$DATA, "swimming_pools.csv"))
pools <- read.csv(file = swimming_pools.csv)
swimming_pools.csv
paste0(RPROJ$DATA, "swimming_pools.csv")
RPROJ$DATA
RPROJ <- list(HOME = normalizePath(getwd()))
RPROJ$DATA <- paste0(RPROJ, normalizePath("DataCamp\\importing.data_1\\data\\"))
RPROJ$DATA
RPROJ <- list(HOME = normalizePath(getwd())) RPROJ$DATA <- normalizePath("DataCamp\\importing.data_1\\data\\") RPROJ$DATA
RPROJ <- list(HOME = normalizePath(getwd()), DATA = normalizePath("DataCamp\\importing.data_1\\data\\"))
swimming_pools.csv <- file.path(paste0(RPROJ$DATA, "swimming_pools.csv"))
paste0(RPROJ$DATA, "swimming_pools.csv")
swimming_pools.csv
library(utils) RPROJ <- list(HOME = normalizePath(getwd()), DATA = normalizePath("DataCamp\\importing.data_1\\data\\")) swimming_pools.csv <- file.path(paste0(RPROJ$DATA, "swimming_pools.csv")) ## CSV # Import swimming_pools.csv: pools pools <- read.csv(file = swimming_pools.csv)
# Print the structure of pools str(pools) # Import swimming_pools.csv correctly: pools
pools <- read.csv(file = swimming_pools.csv, stringsAsFactors = FALSE)
# Check the structure of pools
str(pools)
hotdogs.txt <- file.path(paste0(RPROJ$DATA, "hotdogs.txt"))
## TXT / DELM
# Import hotdogs.txt: hotdogs
hotdogs <- read.delim( file = hot)
# Summarize hotdogs
hotdogs <- read.delim( file = hotdogs.txt)
Summary(hotdogs)
summary(hotdogs)
# Import hotdogs.txt: hotdogs
hotdogs <- read.delim( file = hotdogs.txt, header = FALSE)
# Summarize hotdogs
summary(hotdogs)
path <- file.path(RPROJ$DATA, "hotdogs.txt")
# Path to the hotdogs.txt file: path
path <- file.path(RPROJ$DATA, "hotdogs.txt")
# Import the hotdogs.txt file: hotdogs
hotdogs <- read.table(path,
					  sep = " ",
					  col.names = c("type", "calories", "sodium"))
# Call head() on hotdogs
head(hotdogs)
# Path to the hotdogs.txt file: path
path <- file.path(RPROJ$DATA, "hotdogs.txt")
# Import the hotdogs.txt file: hotdogs
hotdogs <- read.table(path,
					  sep = "",
					  col.names = c("type", "calories", "sodium"))
# Call head() on hotdogs
head(hotdogs)
# Finish the read.delim() call
hotdogs <- read.delim(hotdogs.txt, header = FALSE, col.names = c("type", "calories", "sodium"))
# Select the hot dog with the least calories: lily
lily <- hotdogs[which.min(hotdogs$calories),]
# Select the observation with the most sodium: tom
tom <- hotdogs[which.max(hotdogs$sodium)]
# Print lily and tom
lily
tom
# Finish the read.delim() call
hotdogs <- read.delim(hotdogs.txt, header = FALSE, col.names = c("type", "calories", "sodium"))
# Select the hot dog with the least calories: lily
lily <- hotdogs[which.min(hotdogs$calories),]
# Select the observation with the most sodium: tom
tom <- hotdogs[which.max(hotdogs$sodium),]
lily
tom
str(hotdogs)
# Edit the colClasses argument to import the data correctly: hotdogs2
hotdogs2 <- read.delim("hotdogs.txt", header = FALSE,
					   col.names = c("type", "calories", "sodium"),
					   colClasses = c("factor", "null", "numeric"))
# Edit the colClasses argument to import the data correctly: hotdogs2
hotdogs2 <- read.delim(hotdogs.txt, header = FALSE,
					   col.names = c("type", "calories", "sodium"),
					   colClasses = c("factor", "null", "numeric"))
# Edit the colClasses argument to import the data correctly: hotdogs2
hotdogs2 <- read.delim(hotdogs.txt, header = FALSE,
					   col.names = c("type", "calories", "sodium"),
					   colClasses = c("factor", "NULL", "numeric"))
str(hotdogs2)
library(readr)
library(readr) RPROJ <- list(HOME = normalizePath(getwd()), DATA = normalizePath("DataCamp\\importing.data_1\\data\\"))
potatos.csv <- paste0(RPROJ$DATA, "potatos.csv")
potatos <- read_csv(potatos.csv)
potatoes.csv <- paste0(RPROJ$DATA, "potatoes.csv")
# Import potatoes.csv with read_csv(): potatoes
potatoes.csv <- read_csv(potatos.csv)
rm(potatos.csv, envir = as.environment(".GlobalEnv"))
potatoes.csv <- paste0(RPROJ$DATA, "potatoes.csv")
potatoes.csv <- read_csv(potatoes.csv)
# Load the readr package library(readr)
RPROJ <- list(HOME = normalizePath(getwd()), DATA = normalizePath("DataCamp\\importing.data_1\\data\\"))
potatoes.csv <- paste0(RPROJ$DATA, "potatoes.csv")
# Import potatoes.csv with read_csv(): potatoes
potatoes <- read_csv(potatoes.csv)
potatoes.txt <- paste0(RPROJ$DATA, "potatoes.txt")
potatoes.txt <- paste0(RPROJ$DATA, "potatoes.txt")
# Column names
properties <- c("area", "temp", "size", "storage", "method",
				"texture", "flavor", "moistness")
# Import potatoes.txt: potatoes
potatoes <- read_csv(potatoes.txt, col_names = properties)
# Call head() on potatoes
head(potatoes)
# Import potatoes.txt: potatoes
potatoes <- read_tsv(potatoes.txt, col_names = properties)
# Call head() on potatoes
head(potatoes)
potatoes <- read_delim(potatoes.txt, col_names = properties)
potatoes <- read_delim(potatoes.txt, delim = "\t", col_names = properties)
potatoes
potatoes_fragment <- read_tsv(potatoes.txt,
	skip = 6,
	n_max = 5,
	col_names = properties
)
str(potatoes_fragment)
# Import all data, but force all columns to be character: potatoes_char
potatoes_char <- read_tsv(potatoes.txt, col_types = "cccccccc", col_names = properties)
# Print out structure of potatoes_char
str(potatoes_char)
summary(hotdogs)
# Import without col_types
hotdogs <- read_tsv("hotdogs.txt", col_names = c("type", "calories", "sodium"))
# Display the summary of hotdogs
summary(hotdogs)
hotdogs <- read_tsv(hotdogs.txt, col_names = c("type", "calories", "sodium"))
hotdogs.txt <- paste0(RPROJ$DATA, "hotdogs.txt")
hotdogs <- read_tsv(hotdogs.txt, col_names = c("type", "calories", "sodium"))
summary(hotdogs)
# The collectors you will need to import the data
fac <- col_factor(levels = c("Beef", "Meat", "Poultry"))
int <- col_integer()
# Edit the col_types argument to import the data correctly: hotdogs_factor
hotdogs_factor <- read_tsv("hotdogs.txt",
						   col_names = c("type", "calories", "sodium"),
						   col_types = c(fac, int, int)
# Display the summary of hotdogs_factor
summary(hotdogs) # The collectors you will need to import the data
fac <- col_factor(levels = c("Beef", "Meat", "Poultry"))
int <- col_integer()
# Edit the col_types argument to import the data correctly: hotdogs_factor
hotdogs_factor <- read_tsv("hotdogs.txt",
						   col_names = c("type", "calories", "sodium"),
						   col_types = c(fac, int, int))
# Display the summary of hotdogs_factor
summary(hotdogs)
# Edit the col_types argument to import the data correctly: hotdogs_factor
hotdogs_factor <- read_tsv(hotdogs.txt,
						   col_names = c("type", "calories", "sodium"),
						   col_types = c(fac, int, int))
# Display the summary of hotdogs_factor
summary(hotdogs)
# Edit the col_types argument to import the data correctly: hotdogs_factor
hotdogs_factor <- read_tsv(hotdogs.txt,
						   col_names = c("type", "calories", "sodium"),
						   col_types = list(fac, int, int))
# Display the summary of hotdogs_factor
summary(hotdogs)
# Edit the col_types argument to import the data correctly: hotdogs_factor
hotdogs_factor <- read_tsv(hotdogs.txt,
						   col_names = c("type", "calories", "sodium"),
						   col_types = list(fac, int, int))
# Display the summary of hotdogs_factor
summary(hotdogs)
# Edit the col_types argument to import the data correctly: hotdogs_factor
hotdogs_factor <- read_tsv(hotdogs.txt,
						   col_names = c("type", "calories", "sodium"),
						   col_types = list(fac, int, int))
# Display the summary of hotdogs_factor
summary(hotdogs)
# Edit the col_types argument to import the data correctly: hotdogs_factor
hotdogs_factor <- read_tsv(hotdogs.txt,
						   col_names = c("type", "calories", "sodium"),
						   col_types = list(fac, int, int))
# Display the summary of hotdogs_factor
summary(hotdogs)
hotdogs_factor <- read_tsv(hotdogs.txt,
						   col_names = c("type", "calories", "sodium"),
						   col_types = list(fac, int, int))
update.packages("readr")
hotdogs_factor <- read_tsv(hotdogs.txt,
						   col_names = c("type", "calories", "sodium"),
						   col_types = list(fac, int, int))
# Edit the col_types argument to import the data correctly: hotdogs_factor
hotdogs_factor <- read_tsv(hotdogs.txt,
						   fileEncoding = "UTF-8-BOM",
						   col_names = c("type", "calories", "sodium"),
						   col_types = list(fac, int, int))
# Edit the col_types argument to import the data correctly: hotdogs_factor
hotdogs_factor <- read_tsv(hotdogs.txt,
	col_names = c("type", "calories", "sodium"),
	col_types = list(fac, int, int)
)
# Display the summary of hotdogs_factor
summary(hotdogs)
# Edit the col_types argument to import the data correctly: hotdogs_factor
hotdogs_factor <- read_tsv(hotdogs.txt,
	col_names = c("type", "calories", "sodium"),
	col_types = list(fac, int, int)
)
summary(hotdogs)
# Edit the col_types argument to import the data correctly: hotdogs_factor
hotdogs_factor <- read_tsv(hotdogs.txt,
	col_names = c("type", "calories", "sodium"),
	col_types = list(fac, int, int)
)
# Display the summary of hotdogs_factor
summary(hotdogs_factor)
library(data.table)
install.packages("data.table")
library(data.table)
potatoes <- fread(potatoes.txt)
potatoes
# Import potatoes.csv with fread(): potatoes
potatoes <- fread(potatoes.csv)
# Print out potatoes
potatoes
potatoes <- fread(potatoes.csv, select = c(6,8))
plot(potatoes$texture, potatoes$moistness)
install.packages("readxl")
library(readxl)
RPROJ <- list(HOME = normalizePath(getwd()), DATA = normalizePath("DataCamp\\importing.data_1\\data\\"))
setwd(RPROJ$DATA)
excel_sheets("urbanpop.xlsx")
pop_1 <- read_excel("urbanpop.xlsx", sheet = 1)
pop_2 <- read_excel("urbanpop.xlsx", sheet = 2)
pop_list <- list(pop_1,pop_2)
str(pop_list)
excel_sheets("urbanpop.xlsx")
# Read the sheets, one by one
pop_1 <- read_excel("urbanpop.xlsx", sheet = 1)
pop_2 <- read_excel("urbanpop.xlsx", sheet = 2)
pop_3 <- read_excel("urbanpop.xlsx", sheet = 3)
# Put pop_1, pop_2 and pop_3 in a list: pop_list
pop_list <- list(pop_1,pop_2,pop_3)
# Display the structure of pop_list
str(pop_list)
# Read all Excel sheets with lapply(): pop_list
pop_list <- lapply(excel_sheets("urbanpop.xlsx"),
	FUN = function(sheetName) { read_excel("urbanpop.xlsx", sheetName) }
)
str(pop_list)
# Load the readr package library(readr) library(data.table) RPROJ <- list(HOME = normalizePath(getwd()), DATA = normalizePath("DataCamp\\importing.data\\data\\")) potatoes.csv <- paste0(RPROJ$DATA, "potatoes.csv") # Import potatoes.csv with read_csv(): potatoes potatoes <- read_csv(potatoes.csv) # readr is already loaded potatoes.txt <- paste0(RPROJ$DATA, "potatoes.txt") # Column names properties <- c("area", "temp", "size", "storage", "method", 				"texture", "flavor", "moistness") # Import potatoes.txt: potatoes potatoes <- read_tsv(potatoes.txt, col_names = properties) # Call head() on potatoes head(potatoes) # Import potatoes.txt using read_delim(): potatoes potatoes <- read_delim(potatoes.txt, delim = "\t", col_names = properties) # Print out potatoes potatoes # Import 5 observations from potatoes.txt: potatoes_fragment potatoes_fragment <- read_tsv(potatoes.txt, 	skip = 6, 	n_max = 5, 	col_names = properties ) # Import all data, but force all columns to be character: potatoes_char potatoes_char <- read_tsv(potatoes.txt, col_types = "cccccccc", col_names = properties) # Print out structure of potatoes_char str(potatoes_char) hotdogs.txt <- paste0(RPROJ$DATA, "hotdogs.txt") # Import without col_types hotdogs <- read_tsv(hotdogs.txt, col_names = c("type", "calories", "sodium")) # Display the summary of hotdogs summary(hotdogs) # The collectors you will need to import the data fac <- col_factor(levels = c("Beef", "Meat", "Poultry")) int <- col_integer() # Edit the col_types argument to import the data correctly: hotdogs_factor hotdogs_factor <- read_tsv(hotdogs.txt, 	col_names = c("type", "calories", "sodium"), 	col_types = list(fac, int, int) ) # Display the summary of hotdogs_factor summary(hotdogs_factor) # Import potatoes.csv with fread(): potatoes potatoes <- fread(potatoes.csv) # Print out potatoes potatoes # Import columns 6 and 8 of potatoes.csv: potatoes potatoes <- fread(potatoes.csv, select = c(6,8)) # Plot texture (x) and moistness (y) of potatoes plot(potatoes$texture, potatoes$moistness)
library(utils) RPROJ <- list(HOME = normalizePath(getwd()), DATA = normalizePath("DataCamp\\importing.data\\data\\")) swimming_pools.csv <- file.path(paste0(RPROJ$DATA, "swimming_pools.csv")) ## CSV # Import swimming_pools.csv: pools pools <- read.csv(file = swimming_pools.csv) # Print the structure of pools str(pools) # Import swimming_pools.csv correctly: pools pools <- read.csv(file = swimming_pools.csv, stringsAsFactors = FALSE) # Check the structure of pools str(pools) hotdogs.txt <- file.path(paste0(RPROJ$DATA, "hotdogs.txt")) ## TXT / DELM # Import hotdogs.txt: hotdogs hotdogs <- read.delim( file = hotdogs.txt, header = FALSE) # Summarize hotdogs summary(hotdogs) # Path to the hotdogs.txt file: path path <- file.path(RPROJ$DATA, "hotdogs.txt") # Import the hotdogs.txt file: hotdogs hotdogs <- read.table(path, 					  sep = "", 					  col.names = c("type", "calories", "sodium")) # Call head() on hotdogs head(hotdogs) # Finish the read.delim() call hotdogs <- read.delim(hotdogs.txt, header = FALSE, 	col.names = c("type", "calories", "sodium")) # Select the hot dog with the least calories: lily lily <- hotdogs[which.min(hotdogs$calories),] # Select the observation with the most sodium: tom tom <- hotdogs[which.max(hotdogs$sodium),] # Print lily and tom lily tom # Display structure of hotdogs str(hotdogs) # Edit the colClasses argument to import the data correctly: hotdogs2 hotdogs2 <- read.delim(hotdogs.txt, header = FALSE, 					   col.names = c("type", "calories", "sodium"), 					   colClasses = c("factor", "NULL", "numeric")) # Display structure of hotdogs2 str(hotdogs2)
library(readxl) RPROJ <- list(HOME = normalizePath(getwd()), DATA = normalizePath("DataCamp\\importing.data\\data\\")) setwd(RPROJ$DATA) excel_sheets("urbanpop.xlsx") # Read the sheets, one by one pop_1 <- read_excel("urbanpop.xlsx", sheet = 1) pop_2 <- read_excel("urbanpop.xlsx", sheet = 2) pop_3 <- read_excel("urbanpop.xlsx", sheet = 3) # Put pop_1, pop_2 and pop_3 in a list: pop_list pop_list <- list(pop_1,pop_2,pop_3) # Display the structure of pop_list str(pop_list) # Read all Excel sheets with lapply(): pop_list pop_list <- lapply(excel_sheets("urbanpop.xlsx"), 	FUN = function(sheetName) { read_excel("urbanpop.xlsx", sheetName) } ) # Display the structure of pop_list str(pop_list)
pop_a <- read_excel("urbanpop_nonames.xlsx", sheet = 1)
library(readxl) RPROJ <- list(HOME = normalizePath(getwd()), DATA = normalizePath("DataCamp\\importing.data\\data\\")) setwd(RPROJ$DATA) excel_sheets("urbanpop.xlsx") # Read the sheets, one by one pop_1 <- read_excel("urbanpop.xlsx", sheet = 1) pop_2 <- read_excel("urbanpop.xlsx", sheet = 2) pop_3 <- read_excel("urbanpop.xlsx", sheet = 3) # Put pop_1, pop_2 and pop_3 in a list: pop_list pop_list <- list(pop_1,pop_2,pop_3) # Display the structure of pop_list str(pop_list) # Read all Excel sheets with lapply(): pop_list pop_list <- lapply(excel_sheets("urbanpop.xlsx"), 	FUN = function(sheetName) { read_excel("urbanpop.xlsx", sheetName) } ) # Display the structure of pop_list str(pop_list) # Import the the first Excel sheet of urbanpop_nonames.xlsx (R gives names): pop_a
pop_a <- read_excel("urbanpop_nonames.xlsx", sheet = 1)
# Import the the first Excel sheet of urbanpop_nonames.xlsx (specify col_names): pop_b
cols <- c("country", paste0("year_", 1960:1966))
# Print the summary of pop_a
# Print the summary of pop_b
pop_b <- read_excel("urbanpop_nonames.xlsx", col_names = cols, sheet = 1 )
# Import the the first Excel sheet of urbanpop_nonames.xlsx (R gives names): pop_a
pop_a <- read_excel("urbanpop_nonames.xlsx", sheet = 1)
# Import the the first Excel sheet of urbanpop_nonames.xlsx (specify col_names): pop_b
cols <- c("country", paste0("year_", 1960:1966))
pop_b <- read_excel("urbanpop_nonames.xlsx", col_names = cols, sheet = 1 )
# Print the summary of pop_a
summary(pop_a)
# Print the summary of pop_b
summary(pop_b)
urbanpop_sel <- read_excel("urbanpop_nonames.xlsx", sheet = 2, col_names = FALSE, skip = 21)
head(urbanpop_sel,1)
# Import the second sheet of urbanpop.xlsx, skipping the first 21 rows: urbanpop_sel
urbanpop_sel <- read_excel(path = "urbanpop.xlsx", sheet = 2, skip = 21, col_names = FALSE)
# Print out the first observation from urbanpop_sel
head(urbanpop_sel, 1)
install.packages("gdaga")
install.packages("gdata")
library(gdata)
urban_pop <- read.xls("urbanpop.xlsx", sheet = 2)
urban_pop <- read.xls( file = "urbanpop.xlsx", sheet = 2)
urban_pop <- read.xls( xls = "urbanpop.xlsx", sheet = 2)
urban_pop <- read.xls( xls = "urbanpop.xlsx", sheet = 2)
# Import the second sheet of urbanpop.xls: urban_pop
urban_pop <- read.xls( xls = "urbanpop.xls", sheet = 2)
# Print the first 11 observations using head()
head(urban_pop,11)
install.packages("XLConnect")
library(XLConnect)
my_book <- loadWorkbook("urbanpop.xlsx")
class(my_book)
sheetNames(my_book)
getSheets(my_book)
readWorksheet(my_book, 2)
urbanpop_sel <- readWorksheet(my_book, sheet = 2, startCol = 3, endCol = 5)
countries <- readWorksheet(my_book, sheet = 2, startCol = 1, endCol = 1)
selection <- cbind(urbanpop_sel, countries)
createSheet(my_book, "data_summary")
getSheets(my_book)
# Create data frame: summ
sheets <- getSheets(my_book)[1:3]
dims <- sapply(sheets, function(x) dim(readWorksheet(my_book, sheet = x)), USE.NAMES = FALSE)
summ <- data.frame(sheets = sheets,
				   nrows = dims[1,],
				   ncols = dims[2,])
# Add data in summ to "data_summary" sheet
writeWorksheet(my_book, "data_summary", summ)
# Save workbook as summary.xlsx
saveWorkbook(my_book)
writeWorksheet(my_book, summ, "data_summary")
saveWorkbook(my_book)
saveWorkbook(my_book, "summary.xlsx")
renameSheet(my_book, "data_summary", "summary")
getSheets(my_book)
saveWorkbook(my_book,"renamex.xlsx")
library(readxl) library(gdata) library(XLConnect) RPROJ <- list(HOME = normalizePath(getwd()), DATA = normalizePath("DataCamp\\importing.data\\data\\")) setwd(RPROJ$DATA) excel_sheets("urbanpop.xlsx") # Read the sheets, one by one pop_1 <- read_excel("urbanpop.xlsx", sheet = 1) pop_2 <- read_excel("urbanpop.xlsx", sheet = 2) pop_3 <- read_excel("urbanpop.xlsx", sheet = 3) # Put pop_1, pop_2 and pop_3 in a list: pop_list pop_list <- list(pop_1,pop_2,pop_3) # Display the structure of pop_list str(pop_list) # Read all Excel sheets with lapply(): pop_list pop_list <- lapply(excel_sheets("urbanpop.xlsx"), 	FUN = function(sheetName) { read_excel("urbanpop.xlsx", sheetName) } ) # Display the structure of pop_list str(pop_list) # Import the the first Excel sheet of urbanpop_nonames.xlsx (R gives names): pop_a
pop_a <- read_excel("urbanpop_nonames.xlsx", sheet = 1)
# Import the the first Excel sheet of urbanpop_nonames.xlsx (specify col_names): pop_b
cols <- c("country", paste0("year_", 1960:1966))
pop_b <- read_excel("urbanpop_nonames.xlsx", col_names = cols, sheet = 1 )
# Print the summary of pop_a
summary(pop_a)
# Print the summary of pop_b
summary(pop_b)
# Import the second sheet of urbanpop.xlsx, skipping the first 21 rows: urbanpop_sel
urbanpop_sel <- read_excel(path = "urbanpop.xlsx", sheet = 2, skip = 21, col_names = FALSE)
# Print out the first observation from urbanpop_sel
head(urbanpop_sel, 1)
# Import the second sheet of urbanpop.xls: urban_pop
urban_pop <- read.xls( xls = "urbanpop.xls", sheet = 2)
# Print the first 11 observations using head()
head(urban_pop, 11)
# Column names for urban_pop
columns <- c("country", paste0("year_", 1967:1974))
# Finish the read.xls call
urban_pop <- read.xls("urbanpop.xls", sheet = 2,
					  skip = 50, header = FALSE, stringsAsFactors = FALSE,
					  col.names = columns)
# Print first 10 observation of urban_pop
head(urban_pop, 10)
# Add code to import data from all three sheets in urbanpop.xls
path <- "urbanpop.xls"
urban_sheet1 <- read.xls(path, sheet = 1, stringsAsFactors = FALSE)
urban_sheet2 <- read.xls(path, sheet = 2, stringsAsFactors = FALSE)
urban_sheet3 <- read.xls(path, sheet = 3, stringsAsFactors = FALSE)
# Extend the cbind() call to include urban_sheet3: urban
urban <- cbind(urban_sheet1, urban_sheet2[-1], urban_sheet2[-2])
# Remove all rows with NAs from urban: urban_clean
urban_clean <- na.omit(urban)
# Print out a summary of urban_clean
summary(urban_clean)
# Build connection to urbanpop.xlsx: my_book
my_book <- loadWorkbook("urbanpop.xlsx")
# Print out the class of my_book
class(my_book)
# List the sheets in my_book
getSheets(my_book)
# Import the second sheet in my_book
readWorksheet(my_book, 2)
# Import columns 3, 4, and 5 from second sheet in my_book: urbanpop_sel
urbanpop_sel <- readWorksheet(my_book, sheet = 2, startCol = 3, endCol = 5)
# Import first column from second sheet in my_book: countries
countries <- readWorksheet(my_book, sheet = 2, startCol = 1, endCol = 1)
# cbind() urbanpop_sel and countries together: selection
selection <- cbind(countries, urbanpop_sel)
# Add a worksheet to my_book, named "data_summary"
createSheet(my_book, "data_summary")
# Use getSheets() on my_book
getSheets(my_book)
# Create data frame: summ
sheets <- getSheets(my_book)[1:3]
dims <- sapply(sheets, function(x) dim(readWorksheet(my_book, sheet = x)), USE.NAMES = FALSE)
summ <- data.frame(sheets = sheets,
				   nrows = dims[1,],
				   ncols = dims[2,])
# Add data in summ to "data_summary" sheet
writeWorksheet(my_book, summ, "data_summary")
# Save workbook as summary.xlsx
saveWorkbook(my_book, "summary.xlsx")
# Rename "data_summary" sheet to "summary"
renameSheet(my_book, "data_summary", "summary")
# Print out sheets of my_book
getSheets(my_book)
# Save workbook to "renamed.xlsx"
saveWorkbook(my_book,"renamed.xlsx")
removeSheet(my_book, "summary")
saveWorkbook(my_book, "clean.xlsx")
( int_mat <- matrix(1:12, 3))
class(int_mat)
typeof(int_mat)
( num_mat <- matrix(rnorm(12), 3))
(num_mat <- matrix(rnorm(12), 3)) class(num_mat) typeof(num_mat)
mode(num_mat)
storage.mode(num_mat)
# Look at the definition of type_info()
type_info
# Create list of example variables
some_vars <- list(
  an_integer_vector = rpois(24, lambda = 5),
  a_numeric_vector = rbeta(24, shape1 = 1, shape2 = 1),
  an_integer_array = array(rbinom(24, size = 8, prob = 0.5), dim = c(2, 3, 4)),
  a_numeric_array = array(rweibull(24, shape = 1, scale = 1), dim = c(2, 3, 4)),
  a_data_frame = data.frame(int = rgeom(24, prob = 0.5), num = runif(24)),
  a_factor = factor(month.abb),
  a_formula = y ~ x,
  a_closure_function = mean,
  a_builtin_function = length,
  a_special_function = `if`
)
# Loop over some_vars calling type_info() on each element to explore them
type_info <- function(x) {
	c(
	class = class(x),
	typeof = typeof(x),
	mode = mode(x),
	storage.mode = storage.mode(x)
  )
} # Look at the definition of type_info()
type_info
# Create list of example variables
some_vars <- list(
  an_integer_vector = rpois(24, lambda = 5),
  a_numeric_vector = rbeta(24, shape1 = 1, shape2 = 1),
  an_integer_array = array(rbinom(24, size = 8, prob = 0.5), dim = c(2, 3, 4)),
  a_numeric_array = array(rweibull(24, shape = 1, scale = 1), dim = c(2, 3, 4)),
  a_data_frame = data.frame(int = rgeom(24, prob = 0.5), num = runif(24)),
  a_factor = factor(month.abb),
  a_formula = y ~ x,
  a_closure_function = mean,
  a_builtin_function = length,
  a_special_function = `if`
)
# Loop over some_vars calling type_info() on each element to explore them
type_info
apply(some_vars, type_info)
apply(some_vars, FUN = type_info)
lapply(some_vars, type_info)
(x <- rexp(10))
class(x)
class(x) <- "random_numbers"
class(x)
x
x
typeof(x)
is.numeric(x)
length(x)
mean(x)
summary( c( TRUE, FALSE, NA, TRUE) )
summary(rgamma(1000, 1))
print.function
print.Date
library(plyr)
is_s3_generic("t")
library(plyr)
library(pryr) is_s3_generic("t") # generic transpose function is_s3_method("t.data.frame") # transpose method for data.frames is_s3_method("t.test") # a function for Student's t-tests 
install.packages("plyr")
install.packages("plyr")
update.packages("plyr")
library(plyr)
install.packages("plyr")
install.packages("plyr")
library(pryr) is_s3_generic("t") # generic transpose function is_s3_method("t.data.frame") # transpose method for data.frames is_s3_method("t.test") # a function for Student's t-tests 
library(pryr)
options("repos")[[1]][1]
install.packages("pltr")
install.packages("plyr")
install.packages("C:\Users\bmore\AppData\Local\Temp\RtmpcNiG8z\downloaded_packages\plyr_1.8.4.zip", repos = NULL)
install.packages(normalizePath("C:\Users\bmore\AppData\Local\Temp\RtmpcNiG8z\downloaded_packages\plyr_1.8.4.zip"), repos = NULL)
install.packages(normalizePath("C:\\Users\bmore\AppData\Local\Temp\RtmpcNiG8z\downloaded_packages\plyr_1.8.4.zip"), repos = NULL)
install.packages(normalizePath("\Users\bmore\AppData\Local\Temp\RtmpcNiG8z\downloaded_packages\plyr_1.8.4.zip"), repos = NULL)
install.packages(normalizePath("\Users\bmore\AppData\Local\Temp\RtmpcNiG8z\downloaded_packages\plyr_1.8.4.zip"), repos = NULL)
file.path("C:\Users\bmore\AppData\Local\Temp\RtmpcNiG8z\downloaded_packages\plyr_1.8.4.zip")
normalizePath("C:\Users\bmore\AppData\Local\Temp\RtmpcNiG8z\downloaded_packages\plyr_1.8.4.zip")
R.home()
library(pryr) summary(c(TRUE, FALSE, NA, TRUE)) summary(rgamma(1000, 1)) print.function print.Date is_s3_generic("t") # generic transpose function	 is_s3_method("t.data.frame") # transpose method for data.frames is_s3_method("t.test") # a function for Student's t-tests 
library(pryr)
library(pryr)
library(pryr)
library(pryr) summary(c(TRUE, FALSE, NA, TRUE)) summary(rgamma(1000, 1)) print.function print.Date is_s3_generic("t") # generic transpose function	 is_s3_method("t.data.frame") # transpose method for data.frames is_s3_method("t.test") # a function for Student's t-tests 
# Create get_n_elements
get_n_elements <- function(x, ...) { UseMethod() }
df <- data.frame( C1 = rnorm(10))
df <- data.frame( C1 = rnorm(10), C2 = rnorm(20))
get_n_elements(df)
get_n_elements(df)
# Create get_n_elements
get_n_elements <- function(x, ...) { UseMethod("get_n_elements") }
# Create a data.frame method for get_n_elements
get_n_elements.data.frame <- function(x, ...) { nrows(x) * ncols(x) }
df <- data.frame(C1 = rnorm(10), C2 = rnorm(20))
get_n_elements(df)
get_n_elements.data.frame <- function(x, ...) { nrow(x) * ncols(x) }
get_n_elements(df)
# Create a data.frame method for get_n_elements
get_n_elements.data.frame <- function(x, ...) { nrow(x) * ncol(x) }
df <- data.frame(C1 = rnorm(10), C2 = rnorm(20))
get_n_elements(df)
get_n_elements(df)
get_n_elements(matrix(rnorm(12),3))
ls.str()
t <- list(rnorm(10))
t
size(t)
length
length
methods(class = "glm")
.S3Methods(class = "glm")
.S4Methods(class = "glm")
.S3methods(class = "glm")
.S4methods(class = "glm")
length(methods(class = "data.frame"))
> length(methods(class = "lm"))
> length(methods(class = "factor"))
> length(methods(class = "POSIXct") length(methods(class = "data.frame"))
length(methods(class = "lm"))
length(methods(class = "factor"))
length(methods(class = "POSIXct"))
length(methods(class = "data.frame"))
length(methods(class = "lm"))
length(methods(class = "factor"))
length(methods(class = "POSIXct"))
length(methods(class = "data.frame"))
length(methods(class = "lm"))
length(methods(class = "factor"))
length(methods(class = "POSIXct"))
length(methods(class = "POSIXct"))
length(methods(class = "POSIXct"))
exp
sin
'+'
'+'
'if'
.S3PrimitiveGenerics
all_of_time <- c("1970-01-01", "2012-12-21")
as.Date(all_of_time)
class(all_of_time)
class(all_of_time) <- "date_strings"
as.Date(all_of_time)
length(all_of_time)
length(all_of_time)
.S3PrimitiveGenerics(date)
.S3PrimitiveGenerics
x <-c(1,3,6,10,15)
x <- c(1, 3, 6, 10, 15)
class(x) <- c("triangular_numbers", "natural_numbers", "numeric")
 1 + 2
my_number <- 5
dan <- 100 rob <- 50
total <- dan + rob
6 - 6
# Addition!
3 + 5
# Subtraction!
6 - 4
# Addition!
3 + 5
# Subtraction!
6 - 4
# Addition 
2 + 2
# Subtraction
4 - 1
# Multiplication
3 * 4
# Division
4 / 2
# Exponentiation
s^4
# Modulo
7 %% 3 
# Addition!
3 + 5
# Subtraction!
6 - 4
# Addition 
2 + 2
# Subtraction
4 - 1
# Multiplication
3 * 4
# Division
4 / 2
# Exponentiation
2^4
# Modulo
7 %% 3 
# Assign 200 to savings
savings <- 200
# Print the value of savings to the console
savings
# Assign 100 to my_money
my_money <- 100
# Assign 200 to dans_money
dans_money
# Add my_money and dans_money
my_money + dans_money
# Add my_money and dans_money again, save the result to our_money
our_money <- my_money + dans_money
# Assign 100 to my_money
my_money <- 100
# Assign 200 to dans_money
dans_money < 200
# Add my_money and dans_money
my_money + dans_money
# Add my_money and dans_money again, save the result to our_money
our_money <- my_money + dans_money
# Assign 100 to my_money
my_money <- 100
# Assign 200 to dans_money
dans_money <- 200
# Add my_money and dans_money
my_money + dans_money
# Add my_money and dans_money again, save the result to our_money
our_money <- my_money + dans_money
# Variables for starting_cash and 5% return during January
starting_cash <- 200
jan_ret <- 5
jan_mult <- 1 + (jan_ret / 100)
# How much money do you have at the end of January?
post_jan_cash <- starting_cash * jan_mult
# Variables for starting_cash and 5% return during January
starting_cash <- 200
jan_ret <- 5
jan_mult <- 1 + (jan_ret / 100)
# How much money do you have at the end of January?
post_jan_cash <- starting_cash * jan_mult
# January 10% return multiplier
jan_ret_10 <- 10
jan_mult_10 <- 1 + ( jan_mult_10 / 100 )
# How much money do you have at the end of January now?
post_jan_cash_10 <- jan_mult_10
# January 10% return multiplier
jan_ret_10 <- 10
jan_mult_10 <- 1 + ( jan_mult_10 / 100 )
# How much money do you have at the end of January now?
post_jan_cash_10 <- starting_cash ( jan_mult_10 )
# Print post_jan_cash_10
post_jan_cash_10
jan_ret_10 <- 10
jan_mult_10 <- 1 + (jan_ret_10 / 100)
# How much money do you have at the end of January now?
post_jan_cash_10 <- starting_cash ( jan_mult_10 )
# Print post_jan_cash_10
post_jan_cash_10
# January 10% return multiplier
jan_ret_10 <- 10
jan_mult_10 <- 1 + (jan_ret_10 / 100)
# How much money do you have at the end of January now?
post_jan_cash_10 <- starting_cash * jan_mult_10
# Print post_jan_cash_10
post_jan_cash_10
# Starting cash and returns 
starting_cash <- 200
jan_ret <- 4
feb_ret <- 5
# Multipliers
jan_mult <- 1 + (jan_ret / 100 )
feb_mult <- 1 + (feb_ret / 100 )
total_cash <- starting_cash * jan_mult * feb_mult
total_cash
# Apple's stock price is a numeric
apple_stock <- 150.45
# Bond credit ratings are characters
credit_rating <- "AAA"
# You like the stock market. TRUE or FALSE?
my_answer <- TRUE
# Print my_answer
my_answer
ls()
?class
lapply(ls, function(x) { paste(x) }))
lapply(ls, function(x) { paste(x) })
lapply(ls, function(x) { paste(typeof(x))})
lapply(ls, function(x) { paste(x)})
names(my_answer)
deparse(my_answer)
deparse( substitute( my_answer) )
lapply(ls, function(x) { paste(deparse(substitute(x)), typeof(x)) })
lapply(ls, function(x) { paste(class(x))})
# Another numeric vector
ibm_stock <- c(159.82, 160.02, 159.84)
# Another character vector
finance <- c("stocks", "bonds", "investments")
# A logical vector
logic <- C(TRUE, FALSE, TRUE)
# Another numeric vector
ibm_stock <- c(159.82, 160.02, 159.84)
# Another character vector
finance <- c("stocks", "bonds", "investments")
# A logical vector
logic <- c(TRUE, FALSE, TRUE)
a <- c(1L, "I am a character") b <- c(TRUE, "Hello") c <- c(FALSE, 2)
class(a)
class(c)
a <- c(1L, "I am a character") class(b) b <- c(TRUE, "Hello") class(b) c <- c(FALSE, 2) class(c)
# Vectors of 12 months of returns, and month names
ret <- c(5, 2, 3, 7, 8, 3, 5, 9, 1, 4, 6, 3)
months <- c("Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec")
# Add names to ret
names(ret) <- months
# Print out ret to see the new names!
ret
# Look at the data
apple_stock <- ret
# Plot the data points
plot(apple_stock)
# Plot the data as a line graph
plot(apple_stock, type = "l")
portf_ret <- ( micr * micr ) * ( sony_ret * sony_weight)
# Weights and returns
micr_ret <- 7
sony_ret <- 9
micr_weight <- .2
sony_weight <- .8
# Portfolio return
portf_ret <- ( micr * micr ) * ( sony_ret * sony_weight)
portf_ret <- (micr * micr_weight) * (sony_ret * sony_weight)
# Weights and returns
micr_ret <- 7
sony_ret <- 9
micr_weight <- .2
sony_weight <- .8
# Portfolio return
portf_ret <- (micr * micr_weight) * (sony_ret * sony_weight)
# Weights and returns
micr_ret <- 7
sony_ret <- 9
micr_weight <- .2
sony_weight <- .8
# Portfolio return
portf_ret <- (micr_ret * micr_weight) * (sony_ret * sony_weight)
portf_ret <- micr_ret * micr_weight + sony_ret * sony_weight
ret <- c(7, 9)
weight <- c(.2, .8)
companies <- c("Microsoft", "Sony")
# Weights, returns, and company names
ret <- c(7, 9)
weight <- c(.2, .8)
companies <- c("Microsoft", "Sony")
# Assign company names to your vectors
names(ret) <- companies
names(weight) <- companies
ret_X_weight <- ret * weight
portf_ret <- sum(ret_X_weight)
ret <- c(7, 8, 9)
names(ret) <- c("Microsoft", "Apple", "Sony")
ret
weight <- 1/3
ret_X_weight <- ret * weight
portf_ret <- sum( ret_X_weight )
ret * c(.2, .6)
rm(list = ls())
rm(ls())
rm(list = ls())
ret[1]
ret <- c(5, 2, 3, 7, 8, 3, 5, 9, 1, 4, 6, 3)
ret[1]
c(1:12)
lappy(c(1:12), function(m) { as.Date(x) })
appy(c(1:12), function(m) { as.Date(x) })
apply(c(1:12), function(m) { as.Date(x) })
apply(c(1:12), FUN = function(m) { as.Date(x) })
lapply(c(1:12), FUN = function(m) { as.Date(x) })
lapply(c(1:12), FUN = function(m) { as.Date(m) })
ret <- c(5, 2, 3, 7, 8, 3, 5, 9, 1, 4, 6, 3)
names(ret) < -c("Jan", "Feb", "Mar", 			  "Apr", "May", "Jun", 			  "Jul", "Aug", "Sep", 			  "Oct", "Nov", "Dec")
months <- c("Jan", "Feb", "Mar", 			  "Apr", "May", "Jun", 			  "Jul", "Aug", "Sep", 			  "Oct", "Nov", "Dec")
month.names <- c("Jan", "Feb", "Mar", 			  "Apr", "May", "Jun", 			  "Jul", "Aug", "Sep", 			  "Oct", "Nov", "Dec")
rm( list = ls() )
month.names <- c("Jan", "Feb", "Mar", 			  "Apr", "May", "Jun", 			  "Jul", "Aug", "Sep", 			  "Oct", "Nov", "Dec")
ret <- c(5, 2, 3, 7, 8, 3, 5, 9, 1, 4, 6, 3)
names(ret) <- head(month.names, length(ret))
ret[c(1:6)]
ret[c("March","May")]
ret[c("Mar","May")]
ret[-1]
# A vector of 9 numbers
my_vector <- c(1, 2, 3, 4, 5, 6, 7, 8, 9)
# 3x3 matrix
my_matrix <- matrix(data = my_vector, nrow = 3, ncol = 3)
# Print my_matrix
my_matrix
# Filling across using byrow = TRUE
matrix(data = c(2, 3, 4, 5), nrow = 2, ncol = 2, byrow = TRUE)
apple <- c(109.49, 109.90, 109.11, 109.95, 111.03)
ibm <- c(159.82, 160.02, 159.84, 160.35, 164.79)
cbind(apple, ibm)
rbind(apple, ibm)
cbind_stocks <- cbind(apple, ibm)
rbind_stocks
# cbind the vectors together
rbind_stocks <- rbind(apple, ibm)
# Print rbind_stocks
rbind_stocks
rbind_stocks
rm(list = ls())
apple <- c(109.49, 109.90, 109.11, 109.95, 111.03) ibm <- c(159.82, 160.02, 159.84, 160.35, 164.79) micr <- c(59.2, 59.25, 60.22, 59.95, 61.01)
cbind_stocks <- cbind(apple, ibm, micr)
rbind_stocks <- rbind(apple, ibm, micr)
cor(apple, micr)
apple_micr_matrix <- matrix( data = cbind(apple,micr)  )
apple_micr_matrix <- matrix( data = rbind(apple,micr) )
apple_micr_matrix <- matrix( data = rbind(apple,micr) )
apple_micr_matrix <- matrix( data = rbind(apple,micr), byrow = TRUE )
apple_micr_matrix
apple_micr_matrix <- matrix(data = rbind(apple, micr), nrow = 2)
apple_micr_matrix
cor(apple, micr)
cor(apple_micr_matrix)
apple_micr_matrix
apple_micr_matrix <- matrix(data = cbind(apple, micr, ibm), nrow = 2)
apple_micr_matrix <- matrix(data = cbind(apple, micr, ibm), nrow = 3)
apple_micr_matrix
cor(apple, ibm)
stock_matrix <- matrix(data = cbind(apple, micr, ibm), nrow = 3)
apple_micr_matrix
cor(apple_micr_matrix)
rm(apple_micr_matrix)
cor(stock_matrix)
names(stock_matrix) <- c("AAPL", "MSFT", "IBM")
cor(stock_matrix)
cbind(apple,ibm,micr)
stock_matrix <- matrix(data = cbind(apple, micr, ibm))
cor(stock_matrix)
stock_matrix <- matrix(data = cbind(apple, micr, ibm))
stock_matrix
stock_matrix <- matrix(data = cbind(apple, micr, ibm), nrow = 3)
stock_matrix
cbind(apple,ibm,micr)
stock_matrix <- matrix(data = cbind(apple, micr, ibm), byrow = TRUE)
stock_matrix
stock_matrix <- matrix(data = rbind(apple, micr, ibm), byrow = TRUE)
stock_matrix
cbind(apple, micr, ibm)
cbind(apple,ibm,micr)
stock_matrix <- matrix(data = cbind(apple, micr, ibm), ncol = 5)
stock_matrix
stock_matrix <- matrix(data = cbind(apple, micr, ibm), nrow = 3)
cor(stock_matrix)
stock_matrix <- matrix(data = cbind(apple, micr, ibm), nrow = 3, dimnames = TRUE)
stock_matrix <- matrix(data = cbind(apple, micr, ibm), nrow = 3, dimnames = c("AAPL", "IBM","MSFT") stock_matrix <- matrix(data = cbind(apple, micr, ibm), nrow = 3, dimnames = c("AAPL", "IBM","MSFT")) stock_matrix
names(apple)
data.frame(company = c("A", "A", "B"), cash_flow = c(100, 200, 300), year = c(1, 3, 2))
cash <-data.frame(company, cash_flow, year)
company <- c("A", "A", "A", "B", "B", "B", "B")
cash_flow <- c(1000, 4000, 550, 1500, 1100, 750, 6000)
year <- c(1, 3, 4, 1, 2, 4, 5)
# Data frame
cash <-data.frame(company, cash_flow, year)
# Print cash
cash
head(cash, 4)
tail(cash,3)
str(cash)
cash
cash[3, 2]
cash[5, "year"]
cash[,"year"]
cash[,"cash_flow"] * 2
cash$company <- NULL
cash
# Variables
company <- c("A", "A", "A", "B", "B", "B", "B")
cash_flow <- c(1000, 4000, 550, 1500, 1100, 750, 6000)
year <- c(1, 3, 4, 1, 2, 4, 5)
# Data frame
cash <-data.frame(company, cash_flow, year)
subset(cash, company == "B")
subset(cash, year == 1)
cash$half_cash <- cash$cash_flow * .5
cash
cash$quarter_cash <- cash$half_cash * .5
cash$double_tear <- cash$year * 2
present_value_4k <- 4000
present_value_4k <- 4000 * ( 1 + 5 / 100 ) - 3
cash$present_value <- cash$cash_flow * ( 1 + 5 / 100 ) - cash$year
cash
cash$present_value <- cash$cash_flow * ( 1 + 5 / 100 ) ^ cash$year
# Present value of $4000, in 3 years, at 5%
present_value_4k <- 4000 * ( 1 + 5 / 100 ) ^ 3
# Present value of all cash flows
cash$present_value <- cash$cash_flow * ( 1 + 5 / 100 ) ^ cash$year
cash
present_value_4k <- 4000 * ( 1 + 5 / 100 ) ^ -3
cash$present_value <- cash$cash_flow * ( 1 + 5 / 100 ) ^ cash$year
cash$present_value <- cash$cash_flow * ( 1 + 5 / 100 ) ^ -cash$year
cash
100 * (1.05) ^ -1 # If you expect a cash flow of $100 to be received 1 year from now, the present value of that cash flow at a 5%
100 * (1.05) ^ -1 # If you expect a cash flow of $100 to be received 1 year from now, the present value of that cash flow at a 5%
100 * (1.05) ^ -1 # If you expect a cash flow of $100 to be received 1 year from now, the present value of that cash flow at a 5%
# 95.238
# Present value of $4000, in 3 years, at 5%
present_value_4k <- 4000 * ( 1 + 5 / 100 ) ^ -3
# Present value of all cash flows
cash$present_value <- cash$cash_flow * ( 1 + 5 / 100 ) ^ -cash$year
# Print out cash
cash
cash$present_value <- cash$cash_flow * ( 1 + 5 / 100 ) ^ -cash$year
# Present value of $4000, in 3 years, at 5%
present_value_4k <- 4000 * ( 1 + 5 / 100 ) ^ -3
# Present value of all cash flows
cash$present_value <- cash$cash_flow * ( 1 + 5 / 100 ) ^  cash$year * -1
cash
# Present value of all cash flows
cash$present_value <- cash$cash_flow * ( 1 + 5 / 100 ) ^  ( cash$year * -1 )
cash
# Present value of $4000, in 3 years, at 5%
present_value_4k <- 4000 * ( 1 + 5 / 100 ) ^ -3
# Present value of all cash flows
cash$present_value <- cash$cash_flow * ( 1 + 5 / 100 ) ^  ( -cash$year )
# Print out cash
cash
total_pv <- sum(cash$cash_flow)
total_pv <- sum(cash$present_value)
# Company B information
cash_B <- sum(subset(cash$present_value, company = "B"))
cash_B <- subset(cash, company = "B")
total_pv_B <- sum(cash_B$present_value)
# credit_rating character vector
credit_rating <- c("BB", "AAA", "AA", "CCC", "AA", "AAA", "B", "BB")
# Create a factor from credit_rating
credit_factor <- factor(credit_rating)
credit_factor
str(credit_factor)
# credit_rating character vector
credit_rating <- c("BB", "AAA", "AA", "CCC", "AA", "AAA", "B", "BB")
# Create a factor from credit_rating
credit_factor <- factor(credit_rating)
# Print out your new factor
credit_factor
# Call str() on credit_rating
str(credit_rating)
# Call str() on credit_factor
str(credit_factor)
str(credit_rating)
str(credit_factor)
levels(credit_factor)
levels(credit_factor) < c("2A", "3A", "1B", "3C" )
levels(credit_factor)
levels(credit_factor) < c("2A", "3A", "1B","2B", "3C" )
levels(credit_factor)
levels(credit_factor) <- c("2A", "3A", "1B","2B", "3C" )
credit_factor
plot(credit_factor)
rnorm(100> rnorm(100))
rnorm(100, 70, 1> rnorm(100, 70, 1))
rnorm(100, 70, 1> rnorm(100, 70, 1))
rnorm(100, mean = 0, sd = 2)
rnorm(100, mean = 3, sd = 2)
rnorm(100, mean = 1, sd = 1)
rnorm(100, mean = .5, sd = 1)
rnorm(100, mean = .5, sd = 0)
rnorm(100, mean = .5, sd = 1)
rnorm(100, mean = .5, sd = .75)
runif(100)
runif(100, min = 20, max = 100)
AAA_rank <- runif(100, min = 30, max = 100)runif(100, min = 20, max = 100)
runif(100, min = 30, max = 100)
AAA_rank <- runif(100, min = 30, max = 100)
AAA_rank
AAA_factor <- cut(x = AAA_rank, breaks = 4)
cm(list = ls())
rm(list = ls())
AAA_rank <- runif(100, min = 30, max = 100)
AAA_factor <- cut(x = AAA_rank, breaks = 4)
AAA_factor <- cut(x = AAA_rank, breaks = c(0, 25, 50, 100))
head(AAA_factor)
AAA_factor <- cut(x = AAA_rank, breaks = c(25, 50, 75, 100))
head(AAA_factor)
AAA_factor <- cut(x = AAA_rank, breaks = c(25, 50, 75, 100))
head(AAA_factor)
levels(AAA_factor) <- c("low", "medium", "high", "very_high")
AAA_factor
plot(AAA_factor)
summary(AAA_factor)
AAA_rank <- runif(100, min = 30, max = 100)
# Create 4 buckets for AAA_rank using cut()
AAA_factor <- cut(x = AAA_rank, breaks = c(0, 25, 50, 75, 100))
head(AAA_factor)
# Rename the levels 
levels(AAA_factor) <- c("low", "medium", "high", "very_high")
# Print AAA_factor
AAA_factor
# Plot AAA_factor
plot(AAA_factor)
summary(AAA_factor)
AAA_rank <- runif(100, min = 0, max = 100)
# Create 4 buckets for AAA_rank using cut()
AAA_factor <- cut(x = AAA_rank, breaks = c(0, 25, 50, 75, 100))
head(AAA_factor)
# Rename the levels 
levels(AAA_factor) <- c("low", "medium", "high", "very_high")
# Print AAA_factor
AAA_factor
# Plot AAA_factor
plot(AAA_factor)
summary(AAA_factor)
source("C:/Projects/R/Playground/Scripts/DataCamp/finance/ch_04.R", echo = TRUE, encoding = "Windows-1252")
source("C:/Projects/R/Playground/Scripts/DataCamp/finance/ch_04.R", echo = TRUE, encoding = "Windows-1252")
source("C:/Projects/R/Playground/Scripts/DataCamp/finance/ch_04.R", echo = TRUE, encoding = "Windows-1252")
unique(credit_rating)
credit_factor_ordered <- factor(credit_rating, ordered = TRUE, levels = c("AAA", "AA", "BB", "B"))
plot(credit_factor_ordered)
# Create an ordered factor
credit_factor_ordered <- factor(credit_rating, ordered = TRUE, levels = c("AAA", "AA", "BB", "B", "CCC"))
# Plot credit_factor_ordered
plot(credit_factor_ordered)
keep_level <- credit_factor[c(-3,-7)]
keep_level
plot(keep_level)
drop_level <- keep_level <- credit_factor[c(-3, -7), drop = TRUE]
plot(drop_level)
keep_level <- credit_factor[-c(3,7)]
# Remove the A bonds at positions 3 and 7. Don't drop the A level.
keep_level <- credit_factor[-c(3,7)]
# Plot keep_level
plot(keep_level)
# Remove the A bonds at positions 3 and 7. Drop the A level.
drop_level <- keep_level <- credit_factor[-c(3, 7), drop = TRUE]
# Plot drop_level
plot(drop_level)
# Remove the A bonds at positions 3 and 7. Don't drop the A level.
keep_level <- credit_factor[c(-3,-7)]
# Plot keep_level
plot(keep_level)
# Remove the A bonds at positions 3 and 7. Drop the A level.
drop_level <- keep_level <- credit_factor[c(-3, -7), drop = TRUE]
# Plot drop_level
plot(drop_level)
c(3,7)
-c(3,7)
credit_factor
credit_factor[-c(3,7)]
source("C:/Projects/R/Playground/Scripts/DataCamp/finance/ch_04.R", echo = TRUE, encoding = "Windows-1252")
levels(credit_factor)
unique(credit_factor)
data.frame(c(credit_rating,bond_owners), stringsAsFactors = FALSE)
credit_rating <- c("AAA", "A", "BB")
bond_owners <- c("Dan", "Tom", "Joe")
data.frame(c(credit_rating,bond_owners), stringsAsFactors = FALSE)
str(bonds)
# Create the data frame of character vectors, bonds
bonds <- data.frame(c(credit_rating, bond_owners), stringsAsFactors = FALSE)
# Use str() on bonds
str(bonds)
# Variables
credit_rating <- c("AAA", "A", "BB")
bond_owners <- c("Dan", "Tom", "Joe")
# Create the data frame of character vectors, bonds
bonds <- data.frame(c(credit_rating, bond_owners), stringsAsFactors = FALSE)
# Use str() on bonds
str(bonds)
# Create a factor column in bonds called credit_factor from credit_rating
bonds$credit_factor <- factor(bonds$credit_raiging, ordered = TRUE, levels = c("AAA", "A", "B"))
# Use str() on bonds again
str(bonds)
credit_rating <- c("AAA", "A", "BB")
bond_owners <- c("Dan", "Tom", "Joe")
# Create the data frame of character vectors, bonds
bonds <- data.frame(c(credit_rating, bond_owners), stringsAsFactors = FALSE)
# Use str() on bonds
str(bonds)
# Create a factor column in bonds called credit_factor from credit_rating
bonds$credit_factor <- factor(bonds$credit_rating, ordered = TRUE, levels = c("AAA", "A", "B"))
# Use str() on bonds again
str(bonds)
# Create the data frame of character vectors, bonds
bonds <- data.frame(c(credit_rating, bond_owners), stringsAsFactors = FALSE)
# Use str() on bonds
str(bonds)
# Create the data frame of character vectors, bonds
bonds <- data.frame(credit_rating, bond_owners, stringsAsFactors = FALSE)
str(bonds)
bonds$credit_factor <- factor(bonds$credit_rating, ordered = TRUE, levels = c("AAA", "A", "B"))
str(bonds)
str(bonds)
# List components
name <- "Apple and IBM"
apple <- c(109.49, 109.90, 109.11, 109.95, 111.03)
ibm <- c(159.82, 160.02, 159.84, 160.35, 164.79)
cor_matrix <- cor(cbind(apple, ibm))
# Create a list
portfolio <- list(name, apple, ibm, cor_matrix)
# View your first list
portfolio
names(portfolio) <- c("portfolio_name", "aaple", "ibm", "correlation")
portfolio
portfolio[[2:3]]
portfolio[2:3]
portfolio$correlation
portfolio$weight <- c(apple = 20, ibm = 80)
portfolio
# Change the weight variable: 30% Apple, 70% IBM
portfolio$weight <- c(apple = 30, ibm = 70)
# Print portfolio to see the changes
portfolio
portfolio
portfolio$aaple <- NULL
# Variables
company <- c("A", "A", "A", "B", "B", "B", "B")
cash_flow <- c(1000, 4000, 550, 1500, 1100, 750, 6000)
year <- c(1, 3, 4, 1, 2, 4, 5)
# Data frame
cash <- data.frame(company, cash_flow, year)
cash
# Data frame
cash <- data.frame(company, cash_flow, year)
# Define grouping from year
grouping <- cash$year
# Split cash on your new grouping
split_cash <- split(cash, grouping)
# Look at your split_cash list
split_cash
# Unsplit split_cash to get the original data back.
original_cash <- unsplit(split_cash)
# Print original_cash
original_cash
# Data frame
cash <- data.frame(company, cash_flow, year)
# Define grouping from year
grouping <- cash$year
# Split cash on your new grouping
split_cash <- split(cash, grouping)
# Look at your split_cash list
split_cash
# Unsplit split_cash to get the original data back.
original_cash <- unsplit(split_cash)
original_cash <- unsplit(split_cash, grouping)
original_cash
split_cash
# Data
cash = data.frame(	company <- c("A", "A", "A", "B", "B", "B", "B"),
					cash_flow <- c(1000, 4000, 550, 1500, 1100, 750, 6000),
					year <- c(1, 3, 4, 1, 2, 4, 5))
rm(list = ls())
# Data
cash = data.frame(company <- c("A", "A", "A", "B", "B", "B", "B"),
					cash_flow <- c(1000, 4000, 550, 1500, 1100, 750, 6000),
					year <- c(1, 3, 4, 1, 2, 4, 5))
split_cash <- split(cash, cash$company)
split_cash
cash = data.frame(company <- c("A", "A", "A", "B", "B", "B", "B"),
					cash_flow <- c(1000, 4000, 550, 1500, 1100, 750, 6000),
					year <- c(1, 3, 4, 1, 2, 4, 5))
cash
cash <- data.frame(	company <- c("A", "A", "A", "B", "B", "B", "B"),
					cash_flow <- c(1000, 4000, 550, 1500, 1100, 750, 6000),
					year <- c(1, 3, 4, 1, 2, 4, 5))
cash
# Variables
company <- c("A", "A", "A", "B", "B", "B", "B")
cash_flow <- c(1000, 4000, 550, 1500, 1100, 750, 6000)
year <- c(1, 3, 4, 1, 2, 4, 5)
# Data frame
cash <- data.frame(company, cash_flow, year)
cash
cash <- data.frame(	company = c("A", "A", "A", "B", "B", "B", "B"),
					cash_flow = c(1000, 4000, 550, 1500, 1100, 750, 6000),
					year = c(1, 3, 4, 1, 2, 4, 5))
cash
split_cash <- split(cash, cash$company)
split_cash
split_cash$B$cash_flow
# Data
cash <- data.frame(company = c("A", "A", "A", "B", "B", "B", "B"),
					cash_flow = c(1000, 4000, 550, 1500, 1100, 750, 6000),
					year = c(1, 3, 4, 1, 2, 4, 5))
split_cash <- split(cash, cash$company)
# Print split_cash
split_cash
# Print the cash_flow column of B in split_cash
split_cash$B$cash_flow
# Set the cash_flow column of company A in split_cash to 0
split_cash$A$cash_flow <- 0
# Use the grouping to unsplit split_cash
cash_no_A <- unsplit(split_cash, cash$company)
cash_no_A
# Data Setup
cash <- data.frame(company = c("A", "A", "A", "B", "B", "B", "B"),
					cash_flow = c(1000, 4000, 550, 1500, 1100, 750, 6000),
					year = c(1, 3, 4, 1, 2, 4, 5))
grouping <- cash$company
split_cash <- split(cash, grouping)
# Print split_cash
split_cash
# Print the cash_flow column of B in split_cash
split_cash$B$cash_flow
# Set the cash_flow column of company A in split_cash to 0
split_cash$A$cash_flow <- 0
# Use the grouping to unsplit split_cash
cash_no_A <- unsplit(split_cash, grouping)
# Print cash_no_A
cash_no_A
my_matrix <- matrix(c(1, 2, 3, 4, 5, 6), nrow = 2, ncol = 3)
rownames(my_matrix) <- c("Row1", "Row2")
colnames(my_matrix) <- c("Col1", "Col2", "Col3")
my_factor <- factor(c("A", "A", "B"), ordered = T, levels = c("A", "B"))
attributes(my_matrix)
rm(list = ls())
rm(list = ls())
rm(list = ls())
my_matrix <- matrix(c(1, 2, 3, 4, 5, 6), nrow = 2, ncol = 3)
rownames(my_matrix) <- c("Row1", "Row2")
colnames(my_matrix) <- c("Col1", "Col2", "Col3")
my_factor <- factor(c("A", "A", "B"), ordered = T, levels = c("A", "B"))
# attributes of my_matrix
attributes(my_matrix)
attributes(my_matrix)[,"dim"]
attributes(my_matrix)["dim"]
attributes("my_factor")
attributes("my_factor")
attr(my_matrix)
attr(my_matrix, which = "dim", exact == TRUE)
attr(my_matrix, which == "dim", exact == TRUE)
attr(my_matrix, which == "dim")
attr(my_matrix, which = "dim")
attributes("my_factor")
attributes("my_factor")
my_factor <- factor(c("A", "A", "B"), ordered = T, levels = c("A", "B"))
attributes("my_factor")
attributes(my_factor)
# Load xts
library(xts)
# View the structure of ex_matrix
str(ex_matrix)
# Extract the 3rd observation of the 2nd column of ex_matrix
ex_matrix[3, 2]
# Extract the 3rd observation of the 2nd column of core 
core[3, 2]
install.packages("xts")
# Load xts
library(xts)
# View the structure of ex_matrix
str(ex_matrix)
# Extract the 3rd observation of the 2nd column of ex_matrix
ex_matrix[3, 2]
# Extract the 3rd observation of the 2nd column of core 
core[3, 2]
# Load xts
library(xts)
# View the structure of ex_matrix
str(ex_matrix)
# Extract the 3rd observation of the 2nd column of ex_matrix
ex_matrix[3, 2]
# Extract the 3rd observation of the 2nd column of core 
core[3, 2]
ex_matrix <- matrix( c(as.Date("2016-06-01"), 1, 2 ), nrow = 1 )
ex_matrix
xts(ex_matrix)
matrix <- matrix(1:2, nrow = 2, ncol = 2 )
matrix <- matrix(1:2, nrow = 2, ncol = 2 )
matrix
matrix <- matrix(1:2, nrow = 3, ncol = 2 )
matrix
matrix <- matrix(c(1,2), nrow = 3, ncol = 2 )
matrix
# Load xts
library(xts)
# Create the object data using 5 random numbers
data <- rnorm(5)
# Create dates as a Date class object starting from 2016-01-01
dates <- seq(as.Date("2016-01-01"), length = 5, by = "days")
# Use xts() to create smith
smith <- xts(x = data, order.by = dates)
# Create bday (1899-05-08) using a POSIXct date class object
bday <- as.POSIXct("1899-05-08")
# Create hayek and add a new attribute called born
hayek <- xts(x = data, order.by = dates, born = bday)
# Create dates
dates <- as.Date("2016-01-01") + 0:4
# Create ts_a
ts_a <- xts(x = 1:5, order.by = dates)
# Create ts_b
ts_b <- xts(x = 1:5, order.by = as.POSIXct(dates))
# Extract the rows of ts_a using the index of ts_b
ts_a[index(ts_b)]
# Extract the rows of ts_b using the index of ts_a
ts_b[index(ts_a)]
au <- as.xts(austres)
au
am <- as.matrix(au)
am2 <- as.matrix(austres)
tmp_file <- "http://s3.amazonaws.com/assets.datacamp.com/production/course_1127/datasets/tmp_file.csv"
tmp_file <- "http://s3.amazonaws.com/assets.datacamp.com/production/course_1127/datasets/tmp_file.csv"
# Create dat by reading tmp_file
dat <- read.csv(tmp_file)
# Convert dat into xts
xts(dat, order.by = as.Date(rownames(dat), "%m/%d/%Y"))
# Read tmp_file using read.zoo
dat_zoo <- read.zoo(tmp_file, index.column = 0, sep = ",", format = "%m/%d/%Y")
# Convert dat_zoo to xts
dat_xts <- as.xts(dat_zoo)
# Convert sunspots to xts using as.xts(). Save this as sunspots_xts
sunspots_xts <- as.xts(sunspots)
# Get the temporary file name
tmp <- tempfile()
# Write the xts object using zoo to tmp 
write.zoo(sunspots_xts, sep = ",", file = tmp)
# Read the tmp file. FUN = as.yearmon converts strings such as Jan 1749 into a proper time class
sun <- read.zoo(tmp, sep = ",", FUN = as.yearmon)
# Convert sun into xts. Save this as sun_xts
sun_xts <- as.xts(sun)
# Get the temporary file name
tmp <- tempfile()
# Write the xts object using zoo to tmp 
write.zoo(sunspots_xts, sep = ",", file = tmp)
getwd()
RPROJ <- list(HOME = normalizePath(getwd()), DATA = normalizePath("DataCamp\\importing.data\\data\\"))
RPROJ <- list(HOME = normalizePath(getwd()), DATA = normalizePath("DataCamp\\time.series\\data\\"))
RPROJ$DATA
RPROJ$HOME
install.packages("TeachBayes")
install.packages("TeachBayes")
library(TeachBayes)
insta
install.packages("TeachBayes")
install.packages("D:\GitHub\TeachBayes", repos = NULL, type = "source")
install.packages("D:\\GitHub\\TeachBayes", repos = NULL, type = "source")
install.packages("D:\\GitHub\\TeachBayes\\TeachBayes_1.0.tar.gz", repos = NULL, type = "source")
install.packages("https://cran.r-project.org/web/packages/TeachBayes/TeachBayes.pdf", repos = NULL, type = "source")
install.packages("https://cran.r-project.org/web/packages/TeachBayes/TeachBayes.pdf", repos = NULL, type = "source", dependencies = TRUE)
install.packages("https://cran.r-project.org/web/packages/TeachBayes/TeachBayes.pdf", repos = NULL, type = "source", dependencies = TRUE)
install.packages("https://cran.r-project.org/src/contrib/TeachBayes_1.0.tar.gz", repos = NULL, type = "source", dependencies = TRUE)
install.packages("https://cran.r-project.org/src/contrib/TeachBayes_1.0.tar.gz", repos = NULL, type = "source", dependencies = TRUE)
install.packages("TeachBayes")
install.packages("TeachBayes")
install.packages("https://cran.r-project.org/src/contrib/TeachBayes_1.0.tar.gz", repos = NULL, type = "source", dependencies = TRUE)
install.packages("D:\\GitHub\\TeachBayes\\TeachBayes_1.0.tar.gz", repos = NULL, type = "source")
install.packages("gridExtra")
install.packages("learnBayes")
install.packages("LearnBayes")
install.packages("D:\\GitHub\\TeachBayes\\TeachBayes_1.0.tar.gz", repos = NULL, type = "source")
install.packages("D:\\GitHub\\TeachBayes\\TeachBayes_1.0.tar.gz", repos = NULL, type = "source")
install.packages("D:\\GitHub\\TeachBayes\\TeachBayes_1.0.tar.gz", repos = NULL, type = "source")
install.packages("D:\GitHub\TeachBayes\TeachBayes_1.0.zip", repos = NULL, type = "source")
install.packages("D:\\GitHub\\TeachBayes\\TeachBayes_1.0.zip", repos = NULL, type = "source")
library(TeachBayes)
library(LearnBayes)
Model <- seq(250, 290, by = 10)
Model <- seq(250, 290, by = 10)
library(TeachBayes)
prob_plot(Model)
Prior1 <- seq(0, 1, by = .2)
Prior1 <- seq(0, 5, by = .2)
Prior1 <- rep(.2,5)
sum(Prior1)
prob_plot(Model, Prior1)
prob_plot(Prior1)
prob_plot(data.frame(Model,Prior1))
Prior2 <- c(.266, .266, .2, .133,.133)
prob_plot(data.frame(Model,Prior2))
sum(Prior2)
Prior2 <- c((((1 - .2) / 2) / 3) * 2, (((1 - .2) / 2) / 3) * 2, .2, ((1 - .2) / 2) / 3, ((1 - .2) / 2) / 3)
prob_plot(data.frame(Model, Prior2))
Prior2 <- c(.3,.3,.2,.1,.1)
# Graph the prior using function prob_plot()
prob_plot(data.frame(Model, Prior2))
# Define models and prior: M, Prior
M <- seq(250, 290, by = 10)
Prior <- rep(.2, 5)
# Collect observations
times <- c(240, 267, 308, 275, 271,
		   268, 258, 295, 315, 262)
# Compute ybar and standard error
ybar <- mean(times);
n <- 10
sigma <- 20;
se <- sigma / sqrt(n)
library(TeachBayes)
Likelihood <- dnorm(n,sigma, se)
bayes_df <- data.frame(M, Prior, Likelihood)
bayes_df <- bayesian_crank(bayes_df)
prior_post_plot(bayes_df)
# Define models and prior: M, Prior
M <- seq(250, 290, by = 10)
Prior <- rep(.2, 5)
# Collect observations
times <- c(240, 267, 308, 275, 271,
		   268, 258, 295, 315, 262)
# Compute ybar and standard error
ybar <- mean(times);
n <- 10
sigma <- 20;
se <- sigma / sqrt(n)
# Compute likelihoods using dnorm(): Likelihood
Likelihood <- dnorm(n,sigma, se)
# Collect the vectors M, Prior, Likelihood in a data frame: bayes_df
bayes_df <- data.frame(M, Prior, Likelihood)
# Use bayesian_crank to compute the posterior probabilities: bayes_df
bayes_df <- bayesian_crank(bayes_df)
# Use prior_post_plot() to graph the prior and posterior probabilities
prior_post_plot(bayes_df # Define models and prior: M, Prior
M <- seq(250, 290, by = 10)
Prior <- rep(.2, 5)
# Collect observations
times <- c(240, 267, 308, 275, 271,
		   268, 258, 295, 315, 262)
# Compute ybar and standard error
ybar <- mean(times);
n <- 10
sigma <- 20;
se <- sigma / sqrt(n)
# Compute likelihoods using dnorm(): Likelihood
Likelihood <- dnorm(n,sigma, se)
# Collect the vectors M, Prior, Likelihood in a data frame: bayes_df
bayes_df <- data.frame(M, Prior, Likelihood)
# Use bayesian_crank to compute the posterior probabilities: bayes_df
bayes_df <- bayesian_crank(bayes_df)
# Use prior_post_plot() to graph the prior and posterior probabilities
prior_post_plot(bayes_df)
# Define models and prior: M, Prior
M <- seq(250, 290, by = 10)
Prior <- rep(.2, 5)
# Collect observations
times <- c(240, 267, 308, 275, 271,
		   268, 258, 295, 315, 262)
# Compute ybar and standard error
ybar <- mean(times);
n <- 10
sigma <- 20;
se <- sigma / sqrt(n)
# Compute likelihoods using dnorm(): Likelihood
Likelihood <- dnorm(n,sigma, se)
# Collect the vectors M, Prior, Likelihood in a data frame: bayes_df
bayes_df <- data.frame(M, Prior, Likelihood)
# Use bayesian_crank to compute the posterior probabilities: bayes_df
bayes_df <- bayesian_crank(bayes_df)
# Use prior_post_plot() to graph the prior and posterior probabilities
prior_post_plot(bayes_df)
barplot(Likelihood)
Likelihood <- dnorm(n,sigma, se)
# Define models and prior: M, Prior
M <- seq(250, 290, by = 10)
Prior <- rep(.2, 5)
# Collect observations
times <- c(240, 267, 308, 275, 271,
		   268, 258, 295, 315, 262)
# Compute ybar and standard error
ybar <- mean(times);
n <- 10
sigma <- 20;
se <- sigma / sqrt(n)
# Compute likelihoods using dnorm(): Likelihood
Likelihood <- dnorm(n,sigma, se)
# Collect the vectors M, Prior, Likelihood in a data frame: bayes_df
bayes_df <- data.frame(M, Prior, Likelihood)
# Use bayesian_crank to compute the posterior probabilities: bayes_df
bayes_df <- bayesian_crank(bayes_df)
# Use prior_post_plot() to graph the prior and posterior probabilities
prior_post_plot(bayes_df)
?dnorm
Likelihood <- dnorm(times, sigma, se)
# Define models and prior: M, Prior
M <- seq(250, 290, by = 10)
Prior <- rep(.2, 5)
# Collect observations
times <- c(240, 267, 308, 275, 271,
		   268, 258, 295, 315, 262)
# Compute ybar and standard error
ybar <- mean(times);
n <- 10
sigma <- 20;
se <- sigma / sqrt(n)
# Compute likelihoods using dnorm(): Likelihood
Likelihood <- dnorm(times, sigma, se)
# Collect the vectors M, Prior, Likelihood in a data frame: bayes_df
bayes_df <- data.frame(M, Prior, Likelihood)
# Use bayesian_crank to compute the posterior probabilities: bayes_df
bayes_df <- bayesian_crank(bayes_df)
# Use prior_post_plot() to graph the prior and posterior probabilities
prior_post_plot(bayes_df)
# Collect observations
times <- c(240, 267, 308, 275, 271,
		   268, 258, 295, 315, 262)
# Compute ybar and standard error
ybar <- mean(times);
n <- 10
sigma <- 20;
se <- sigma / sqrt(n)
# Compute likelihoods using dnorm(): Likelihood
Likelihood <- dnorm(times, sigma, se)
# Collect the vectors M, Prior, Likelihood in a data frame: bayes_df
bayes_df <- data.frame(M, Prior, Likelihood)
# Use bayesian_crank to compute the posterior probabilities: bayes_df
bayes_df <- bayesian_crank(bayes_df)
# Use prior_post_plot() to graph the prior and posterior probabilities
prior_post_plot(bayes_df)
Likelihood <- dnorm(n, ybar, se)
Likelihood <- dnorm(sigma, ybar, se)
Likelihood <- dnorm(ybar, ybar, se)
Likelihood <- dnorm(n, ybar, se)
Likelihood <- dnorm(sigma, ybar, se)
Likelihood <- dnorm(sigma, ybar, se)
Likelihood <- dnorm(ybar, sigma, se)
Likelihood <- dnorm(ybar, mean = Prior, se)
Likelihood <- dnorm(ybar, M, se)
# Define models and prior: M, Prior
M <- seq(250, 290, by = 10)
Prior <- rep(.2, 5)
# Collect observations
times <- c(240, 267, 308, 275, 271,
		   268, 258, 295, 315, 262)
# Compute ybar and standard error
ybar <- mean(times);
n <- 10
sigma <- 20;
se <- sigma / sqrt(n)
# Compute likelihoods using dnorm(): Likelihood
Likelihood <- dnorm(ybar, M, se)
# Collect the vectors M, Prior, Likelihood in a data frame: bayes_df
bayes_df <- data.frame(M, Prior, Likelihood)
# Use bayesian_crank to compute the posterior probabilities: bayes_df
bayes_df <- bayesian_crank(bayes_df)
# Use prior_post_plot() to graph the prior and posterior probabilities
prior_post_plot(bayes_df)
bayes_df
normal_par <- normal.select( quantile1, quantile2 )
# Specify the 0.02 quantile of M: quantile1
quantile1 <- 0.02
# Specify the 0.60 quantile of M: quantile2
quantile2 <- 0.60
# Find the normal parameters that match the two quantiles
normal_par <- normal.select( quantile1, quantile2 )
normal_par <- normal.select( quantile1, quantile2 )
# Specify the 0.02 quantile of M: quantile1
quantile1 <- c(0.02)
# Specify the 0.60 quantile of M: quantile2
quantile2 <- c(0.60)
# Find the normal parameters that match the two quantiles
normal_par <- normal.select( quantile1, quantile2 )
# Specify the 0.02 quantile of M: quantile1
quantile1 <- list(p = 0.02, x = 240 )
# Specify the 0.60 quantile of M: quantile2
quantile2 <- list(p = 0.60, x = 280)
normal_par <- normal.select(quantile1, quantile2 )
normal_draw(normal_par)
# Collect observations
times <- c(240, 267, 308, 275, 271,
		   268, 258, 295, 315, 262)
ybar <- mean(times)
sigma <- 20;
se <- sigma / sqrt(10)
Data <- c(ybar, se)
# Collect observations
times <- c(240, 267, 308, 275, 271,
		   268, 258, 295, 315, 262)
# Compute ybar and standard error
ybar <- mean(times)
sigma <- 20;
se <- sigma / sqrt(10)
Data <- c(ybar, se)
Prior <- c(prior[1], Prior[1])
Prior <- c(prior[1], prior[1])
prior <- c(240, 15)
Prior <- c(prior[1], prior[2])
Posterior <- normal_update(Prior, Data)
many_normal_plots(Posterior)
many_normal_plots(list(Prior,Data))
sd(prior)
library(TeachBayes) # Place possible values of M in a vector: Model
Model <- seq(250, 290, by = 10)
# Construct a uniform probability vector: Prior1
Prior1 <- rep(.2,5)
# Graph the prior using function prob_plot()
prob_plot(data.frame(Model,Prior1))
# Construct a different probability distribution: Prior2
Prior2 <- c(.3,.3,.2,.1,.1)
# Graph the prior using function prob_plot()
prob_plot(data.frame(Model, Prior2))
## ################################
## Bayes Rule, Normal Uniform Prior
## ################################
# Define models and prior: M, Prior
M <- seq(250, 290, by = 10)
Prior <- rep(.2, 5)
# Collect observations
times <- c(240, 267, 308, 275, 271,
		   268, 258, 295, 315, 262)
# Compute ybar and standard error
ybar <- mean(times);
n <- 10
sigma <- 20;
se <- sigma / sqrt(n)
# Compute likelihoods using dnorm(): Likelihood
Likelihood <- dnorm(ybar, M, se)
# Collect the vectors M, Prior, Likelihood in a data frame: bayes_df
bayes_df <- data.frame(M, Prior, Likelihood)
# Use bayesian_crank to compute the posterior probabilities: bayes_df
bayes_df <- bayesian_crank(bayes_df)
bayes_df
# Use prior_post_plot() to graph the prior and posterior probabilities
prior_post_plot(bayes_df)
## ################################
## Bayes Rule, Continuous Prior
## ################################
# Specify the 0.02 quantile of M: quantile1
quantile1 <- list(p = 0.02, x = 240 )
# Specify the 0.60 quantile of M: quantile2
quantile2 <- list(p = 0.60, x = 280)
# Find the normal parameters that match the two quantiles
normal_par <- normal.select(quantile1, quantile2 )
# Plot the normal curve using the normal_draw() function
normal_draw(normal_par)
# Bayes
prior <- c(240, 15)
# Collect observations
times <- c(240, 267, 308, 275, 271,
		   268, 258, 295, 315, 262)
# Compute ybar and standard error
ybar <- mean(times)
sigma <- 20;
se <- sigma / sqrt(10)
# Define mean and standard error: Data
Data <- c(ybar, se)
# Define mean and standard deviation of prior: Prior
Prior <- c(260, 10)
# Use normal_update() function: Posterior
Posterior <- normal_update(Prior, Data)
# Construct plot of prior and posterior
many_normal_plots(list(Prior, Posterior))
# Collect observations
times <- c(240, 267, 308, 275, 271,
		   268, 258, 295, 315, 262)
# Compute ybar and standard error
ybar <- mean(times)
sigma <- 20;
se <- sigma / sqrt(10)
# Define mean and standard error: Data
Data <- c(ybar, se)
# Define mean and standard deviation of prior: Prior
Prior <- c(260, 10)
# Use normal_update() function: Posterior
Posterior <- normal_update(Prior, Data)
# Construct plot of prior and posterior
many_normal_plots(list(Prior, Posterior))
many_normal_plots(list(c(Prior[1], Prior[2]), c(Posterior[1], Posterior[2])))
C_Interval <- qnorm(.9, Data[1], Data[2])
C_Interval <- dnorm(.9, Data[1], Data[2])
C_Interval <- qnorm(.9, Data[1], Data[2])
C_Interval <- c(Data[1] - 1.645 * Data[2], Data[1] + 1.645 * Data[2])
length(C_Interval)
normal_interval(.9, Posterior)
normal_interval(.9, Posterior)
B_Interval <- qnorm(c(262.565, 280.149), mean = 271.25, sd = 5.35)
B_Interval <- qnorm(c(262.565, 280.149), mean = 271.25, sd = 5.35)
B_Interval <- qnorm(c(0.05, 0.90), mean = 271.25, sd = 5.35)
B_Interval <- qnorm(c(0.1, 0.90), mean = 271.25, sd = 5.35)
B_Interval <- qnorm(c(0.05, 0.90), mean = 271.25, sd = 5.35)
B_Interval <- qnorm(c(0.05, 0.85), mean = 271.25, sd = 5.35)
diff(B_Interval)
# Define mean and standard error: Data
Data <- c(275.9, 6.32)
# Compute 90% confidence interval: C_Interval
C_Interval <- c(Data[1] - 1.645 * Data[2], Data[1] + 1.645 * Data[2])
# Find the length of the confidence interval
diff(C_Interval)
# Define mean and standard deviation of posterior: Posterior
Posterior <- c(271.35, 5.34)
# Display a 90% probability interval
normal_interval(.9, Posterior)
# Compute the 90% probability interval: B_Interval
B_Interval <- qnorm(c(0.05, 0.95), mean = Posterior[1], sd = Posterior[2])
# Compute the length of the Bayesian interval
diff(B_Interval)
pnorm(.3, 270.5, 5.8)
pnorm(3, 270.5, 5.8)
?pnorm
pnorm(1 -.3, 270.5, 5.8)
pnorm(.7, 270.5, 5.8)
pnorm(.9, 270.5, 5.8)
pnorm(.9, mean = 270.5, sd = 5.8)
pnorm(.9, mean = 270.5, sd = 5.8, lower.tail = FALSE)
pnorm(.3, mean = 270.5, sd = 5.8, lower.tail = FALSE)
pnorm(.1, mean = 270.5, sd = 5.8, lower.tail = FALSE)
pnorm(275, mean = 270.5, sd = 5.8, lower.tail = FALSE)
M_sim <- rnorm(1000, 270.5, 5.8)
sd(M_sim)
mean(M_sim) / sqrt(1000)
M_sim <- rnorm(1000, 270.5, 5.8)
# Compute the posterior standard deviation 
sd(M_sim)
M_sim <- rnorm(1000, 270.5, 5.8)
# Compute the posterior standard deviation 
sd(M_sim)
M_sim <- rnorm(1000, 270.5, 5.8)
# Compute the posterior standard deviation 
sd(M_sim)
qnorm(260, 270.5, 5.8, lower.tail = TRUE)
qnorm(260, 270.5, 5.8, lower.tail = TRUE)
qnorm(260, 270.5, 5.8)
dnorm(260, 270.5, 5.8)
1 - dnorm(260, 270.5, 5.8)
qnorm(c(.15,.85), 270.5, 5.8)
qnorm(c(.15,.85), 270.5, 5.8)
# Compute the probability that M is smaller than 260
1 - dnorm(260, 270.5, 5.8)
sum(M_sim < 260) / 1000
dnorm(260, 270.5, 5.8)
sum(M_sim < 260) / 1000
1 - dnorm(260, 270.5, 5.8)
sum(M_sim < 260) / 1000
quantile(M_sim, c(.15, .85))
qnorm(c(.15, .85), 270.5, 5.8)
quantile(M_sim, c(.15, .85))
M_sim <- rnorm(1000, 270.5, 5.8)
y_sim <- rnorm(1000, M_sim, 20)
# Simulate 1000 draws from John's posterior density: M_sim
M_sim <- rnorm(1000, 270.5, 5.8)
# Simulate 1000 draws from the predictive density: y_sim
y_sim <- rnorm(1000, M_sim, 20)
sum( y_sim < 250 ) / 1000
quantile(c(.05,0.95), y_sim)
quantile(c(.05,0.95), y_sim)
quantile(y_sim, c(.05,0.95))
library(TeachBayes)
library(TeachBayes)
prior <- testing_prior(lo = .1, hi = .9, 						np = 9, pequal = .5)
library(TeachBayes) prior <- testing_prior(lo = .1, hi = .9, 						np = 9, pequal = .5)
						n_values = 9, pequal = .5)
prior <- testing_prior(lo = .1, hi = .9, 						n_values = 9, pequal = .5)
round(prior, 3)
draw_two_p(prior)
pW <- .5
pM <- .5
pW <- .5 pM <- .5 prior <- testing_prior(lo = .1, hi = .9, 						n_values = 9, pequal = mean(pW,pM)) round(prior, 3) draw_two_p(prior) Likelihood <- dbinom( 10, size = 20, prob = pW)
Likelihood <- dbinom( 10, size = 20, prob = pW) * dbinom( 14, size = 20, pM)
post <- two_p_update( prior, c(10,10), c(14, 6))
draw_two_p(post)
two_p_summarize(post)
d <- two_p_summarize(post)
prob_plot(d)
prior <- testing_prior( 0.1, 0.9, 5, uniform = TRUE)
prior
draw_two_p(prior)
two_p_summarize(prior)
d_NS = two_p_summarize(prior)
draw_two_p(d_NS)
prob_plot(d_NS)
# Define a uniform prior on all 25 pairs: prior
prior <- testing_prior(0.1, 0.9, 5, uniform = TRUE)
# Define the data: s1f1, s2f2
s1f1 <- 12
s2f2 <- 17
# Compute the posterior: post
post <- two_p_update(prior, s1f1, s2f2)
draw_two_p(post)
prob_plot(post)
post <- two_p_update(prior, s1f1, s2f2)
# Define the data: s1f1, s2f2
s1f1 <- c(12,20)
s2f2 <- c(17,20)
# Compute the posterior: post
post <- two_p_update(prior, s1f1, s2f2)
prob_plot(post)
# Define the data: s1f1, s2f2
s1f1 <- c(12,8)
s2f2 <- c(17,3)
# Compute the posterior: post
post <- two_p_update(prior, s1f1, s2f2)
prob_plot(post)
# Define a uniform prior on all 25 pairs: prior
prior <- testing_prior(0.1, 0.9, 5, uniform = TRUE)
# Define the data: s1f1, s2f2
s1f1 <- c(12,8)
s2f2 <- c(17,3)
# Compute the posterior: post
post <- two_p_update(prior, s1f1, s2f2)
# Graph the posterior
prob_plot(post)
draw_two_p(post)
# Find the probability distribution of pN - pS: d_NS
d_NS <- two_p_summarize(prior)
# Graph this distribution
prob_plot(d_NS)
d_NS <- two_p_summarize(post)
prob_plot(d_NS)
sim_pS <- rbeta(1000, 4.91, 3.38)
sim_pN <- rbeta(1000, 4.91, 3.38)
d_NS <- diff(c(sim_pN, sim_pS))
his(d_NS)
hist(d_NS)
sum( d_NS < 0 ) / 1000
quantile(d_NS, c(0.05, 0.95))
d_NS <- sim_pN - sim_pS
# For each pair of proportions, compute the difference: d_NS
d_NS <- sim_pN - sim_pS
# Plot a histogram of the values in d_NS
hist(d_NS)
# Find the probability d_NS is positive
sum( d_NS < 0 ) / 1000
# Find a 90% probability interval for d_NS
quantile(d_NS, c(0.05, 0.95))
sum( d_NS > 0 ) / 1000
quantile(d_NS, c(0.05, 0.95))
# Define the number of successes and number of failures: s1f1, s2f2
s1f1 <- c(12, 8)
s2f2 <- c(17, 3)
# Find the prior beta shape parameters for pS and pN:
pS_prior <- c(1, 1)
pN_prior <- c(1, 1)
# Define the number of successes and number of failures: s1f1, s2f2
s1f1 <- c(12, 8)
s2f2 <- c(17, 3)
# Find the prior beta shape parameters for pS and pN:
pS_prior <- c(1, 1)
pN_prior <- c(1, 1)
# Find the posterior beta shape parameters for pS: pS_shape
pS_shape <- c( 1 + 12, 1 + 8)
# Find the posterior beta shape parameters for pN: pN_shape
pN_shape <- c( 1 + 17, 1 + 3)
# Simulate 1000 draws from the posterior: sim_pS, sim_pN
sim_pS <- rbeta(1000, pS_prior, pS_shape)
sim_pN <- rbeta(1000, pN_prior, pN_shape)
plot(sim_pS, sim_pN)
sim_pS <- rbeta(1000, 13, 9)
sim_pN <- rbeta(1000, 18, 4)
plot(sim_pS, sim_pN)
r_NS <- sim_pS / sim_pN
hist(r_NS)
sum(r_NS > 1) / 1000
quantile(r_NS, c(.1,.9))
# Simulate 1000 draws from the posterior: sim_pS, sim_pN
sim_pS <- rbeta(1000, 13, 9)
sim_pN <- rbeta(1000, 18, 4)
# For each pair of proportions, compute the ratio: r_NS
r_NS <- sim_pN / sim_pS
# Plot a histogram of the values in r_NS
hist(r_NS)
# Find the probability r_NS is larger than 1
sum(r_NS > 1) / 1000
# Find a 80% probability interval for r_NS
quantile(r_NS, c(.1,.9))
install.packages("arm")
library(arm)
# Collect reaction times: times
times <- c(240, 267, 308, 275, 271,
		   268, 258, 295, 315, 262)
# Fit a normal model: fit
fit <- lm(times ~ 1)
sim(fit,1000)
sim_fit <- sim(fit, 1000)
M_sim <- coef(sim_fit)
s_sim <- sigma.hat(sim_fit)
plot(M_sim,s_sim)
sim_fit <- sim(fit, n.sims = 1000)
# Collect reaction times: times
times <- c(240, 267, 308, 275, 271,
		   268, 258, 295, 315, 262)
# Fit a normal model: fit
fit <- lm(times ~ 1)
# Simulate 1000 from posterior:  sim_fit
sim_fit <- sim(fit, n.sims = 1000)
s_sim <- sigma.hat(sim_fit)
quantile(sim_fit, c(.125,.875))
quantile(sim_fit, c(.125,.875))
quantile(sim_fit, c(0.125, 0.875))
# Collect reaction times: times
times <- c(240, 267, 308, 275, 271,
		   268, 258, 295, 315, 262)
# Fit a normal model: fit
fit <- lm(times ~ 1)
# Simulate 1000 from posterior:  sim_fit
sim_fit <- sim(fit, n.sims = 1000)
# Extract the simulated values of M and S: M_sim, s_sim
M_sim <- coef(sim_fit)
s_sim <- sigma.hat(sim_fit)
# Compute values of the 75th percentile: Q75
quantile(sim_fit, c(0.125, 0.875))
Q75 <- M_sim + 0.674 * s_sim
hist(Q75)
quantile(Q75, c(.15,.85))
dd <- data.frame(Jim = c(240, 267, 308, 275, 271, 268, 258, 295, 315, 262))
dd <- data.frame(
	Jim = c(240, 267, 308, 275, 271, 268, 258, 295, 315, 262),
	Steven = c(279, 241, 225, 252, 288, 242, 281, 254, 263, 276)
)
# Perform a regression fit of Time with Person as a covariate: fit
fit <- lm(Time ~ Person, data = dd)
dd <- data.frame(
	Person = "Jim", Time = c(240, 267, 308, 275, 271, 268, 258, 295, 315, 262),
	Person = "Steven", Time = c(279, 241, 225, 252, 288, 242, 281, 254, 263, 276)
)
dd
jim <- data.frame(
	Person = "Jim", Time = c(240, 267, 308, 275, 271, 268, 258, 295, 315, 262),
)
steve <- data.frame(
	Person = "Steven", Time = c(279, 241, 225, 252, 288, 242, 281, 254, 263, 276)
)
jim <- data.frame(
	Person = "Jim", Time = c(240, 267, 308, 275, 271, 268, 258, 295, 315, 262),
)
jim <- data.frame(Person = "Jim", Time = c(240, 267, 308, 275, 271, 268, 258, 295, 315, 262))
steve <- data.frame(Person = "Steven", Time = c(279, 241, 225, 252, 288, 242, 281, 254, 263, 276))
dd <- rbind(c(jim,steve))
dd <- rbind(jim,steve)
fit <- lm(Time ~ Person, data = dd)
sim_fit <- sim(fit, n.sims = 1000 )
s_sim <- sigma.hat(sim_fit)
beta_sim <- coef(sim_fit)
s_sim <- sigma.hat(sim_fit)
plot(beta_sim, s_sim)
# Extract simulated draws of beta and S: beta_sim, s_sim
beta_sim <- coef(sim_fit)
s_sim <- sigma.hat(sim_fit)
# Construct a scatterplot of the posterior distribution of (beta0, beta1)
plot(beta_sim, s_sim)
plot(beta_sim)
fit <- lm(Time ~ Person, data = dd)
sim_fit <- sim(fit, n.sims = 1000)
# Extract simulated draws of beta and S:  beta_sim, s_sim
beta_sim <- coef(sim_fit)
s_sim <- sigma.hat(sim_fit)
s_delta <- beta_sim / s_sim
quantile(s_delta, c(.05,.95))
beta_sim
s_delta <- beta_sim / s_sim
quantile(s_delta, c(.05,.95))
s_delta <- beta_sim[2] / s_sim
beta_sim
quantile(s_delta, c(.05,.95))
s_delta <- beta_sim$PersonSteven / s_sim
s_delta <- beta_sim[2] / s_sim
s_delta <- beta_sim[2] / s_sim[2]
s_delta <- names(beta_sim)[2] / s_sim[2]
beta_sim[1]
beta_sim[2]
beta_sim <- coef(sim_fit)
beta_sim[2]
# Perform a regression fit of Time with Person as a covariate: fit
fit <- lm(Time ~ Person, data = dd)
# Simulate 1000 values from the posterior distribution: sim_fit
sim_fit <- sim(fit, n.sims = 1000)
# Extract simulated draws of beta and S:  beta_sim, s_sim
beta_sim <- coef(sim_fit)
s_sim <- sigma.hat(sim_fit)
beta_sim[2]
s_sim
s_delta <- s_sim / beta_sim[2]
# Compute simulated values of the standardized change: s_delta
s_delta <- s_sim / beta_sim[2]
# Find 90% interval estimate for s_delta
quantile(s_delta, c(.05, .95))
beta_sim[2]
hist(s_delta)
# Compute simulated values of the standardized change: s_delta
s_delta <- beta_sim[2] / s_sim
# Find 90% interval estimate for s_delta
quantile(s_delta, c(.05, .95))
beta_sim
names(beta_sim)
beta_sim[2,]
beta_sim[2]
s_sim[1]
s_sim[2]
s_sim
# Compute simulated values of the standardized change: s_delta
s_delta <- beta_sim[2] / s_sim
# Compute simulated values of the standardized change: s_delta
s_delta <- beta_sim[,2] / s_sim
# Find 90% interval estimate for s_delta
quantile(s_delta, c(.05, .95))
# Perform a regression fit of Time with Person as a covariate: fit
fit <- lm(Time ~ Person, data = dd)
# Simulate 1000 values from the posterior distribution: sim_fit
sim_fit <- sim(fit, n.sims = 1000)
# Extract simulated draws of beta and S:  beta_sim, s_sim
beta_sim <- coef(sim_fit)
s_sim <- sigma.hat(sim_fit)
# Compute simulated values of the standardized change: s_delta
s_delta <- beta_sim[, 2] / s_sim
# Find 90% interval estimate for s_delta
quantile(s_delta, c(0.05, 0.95))
# micr
micr <- 57.44
# Fill in the blanks
if( micr < 55 ) {
    print("Buy!")
} else {
    print("Sell!")
}
# micr
micr <- 105.67
# Fill in the blanks
if( micr < 55 ) {
    print("Buy!")
} else if( micr < 75 & micr >= 55 ){
    print("Do nothing!")
} else { 
    print("Sell!")
}
# micr
micr <- 105.67
shares <- 1
# Fill in the blanks
if( micr < 55 ) {
    print("Buy!")
} else if( micr >= 55 & micr < 75 ) {
    print("Do nothing!")
} else { 
    if( shares >= 1 ) {
        print("Sell!")
    } else {
        print("Do Nothing!")
    }
}
opar <- par( mfrow = c(2,2), mex= 0.8, mar=c(3,3,2,1) + .1)
stripchart(expend ~ stature)
library(ISwR)
install.packages("ISwR")
library(ISwR)
opar <- par(mfrow = c(2, 2), mex = 0.8, mar = c(3, 3, 2, 1) + .1) stripchart(expend ~ stature)
attach(energy)
opar <- par(mfrow = c(2, 2), mex = 0.8, mar = c(3, 3, 2, 1) + .1)
stripchart(expend ~ stature)
stripchart( expend ~ stature, method = "stack")
stripchart(expend ~ stature, method = "jitter")
stripchart(expend ~ stature, method = "jitter", jitter = 0.3)
stripchart(list(lean=expend.lean,obease=expend.obese))
stripchart(list(lean=expend.lean,obease=expend.obese))
attach(energy) expend.lean <- expend[stature == "lean"] expend.obese <- expend[stature == "obese"]
expend.lean <- expend[stature == "lean"]
expend.obese <- expend[stature == "obese"]
stripchart(list(lean=expend.lean,obease=expend.obese))
opar <- par(mfrow = c(2, 2), mex = 0.8, mar = c(3, 3, 2, 1) + .1) stripchart(expend ~ stature) stripchart(expend ~ stature, method = "stack") stripchart(expend ~ stature, method = "jitter") stripchart(expend ~ stature, method = "jitter", jitter = 0.3)
stripchart(list(lean = expend.lean, obease = expend.obese))
caff.marital <- matrix( c(652,1537, 598, 242, 36, 46, 38, 21, 218, 327, 106, 67))
caff.marital <- matrix(c(652, 1537, 598, 242, 36, 46, 38, 21, 218, 327, 106, 67), 	nrow = 3, byrow = TRUE)
caff.marital
colnames(caff.marital) <- c("0", "1-150", "151-300", ">300")
rownames(caff.marital) <- c("Married", "Prev.married", "Single")
caff.marital
as.table(caff.marital)
as.data.frame(as.table(caff.marital))
attach(juul)
table(sex)
table(sex,menarche)
table(menarche,tanner)
xtabs(~tanner + sex, data = juul)
xtabs( ~dng + diab + coma, data = stroke)
xtabs( ~dgn + diab + coma, data = stroke)
xtabs(~dgn + diab + coma, data = stroke),,coma = NO
xtabs(~dgn + diab + coma, data = stroke),,coma = No
xtabs(~dgn + diab + coma, data = stroke)
ftable( coma + diab ~ dgn, data=stroke)
t(caff.marital)
aperm(caff.marital)
tanner.sex <- table(tanner,sex)
tanner.sex
colnames(tanner.sex) <- c("M", "F") rownames(tanner.sex) <- c("I", "II", "III", "IV", "V")
tanner.sex
margin.table(tanner.sex)
margin.table(tanner.sex,1)
margin.table(tanner.sex, 2)
prop.table(tanner.sex, 1)
total.caff <- margin.table(caff.marital,2)
total.caff
barplot(total.caff, col="white")
par <- NULL
barplot(total.caff, col = "white")
library(ISwR)
caff.marital <- matrix(c(652, 1537, 598, 242, 36, 46, 38, 21, 218, 327, 106, 67), 	nrow = 3, byrow = TRUE)
total.caff <- margin.table(caff.marital, 2) total.caff barplot(total.caff, col = "white")
par(mfrow=c(2,2))
barplot(caff.marital, col="white")
barplot(t(caff.marital), col="white")
barplot(t(caff.marital), col="white", beside = TRUE)
barplot(prop.table(t(caff.marital), 2), col="white", beside = TRUE)
par(mfrow=c(1,1))
barplot(total.caff, col = "white")
par(mfrow = c(2, 2)) barplot(caff.marital, col = "white") barplot(t(caff.marital), col = "white") barplot(t(caff.marital), col = "white", beside = TRUE) barplot(prop.table(t(caff.marital), 2), col = "white", beside = TRUE)
par(mfrow = c(1, 1))
barplot(prop.table(t(caff.marital), 2), beside = TRUE, legend.text = colnames(caff.marital), col=c("white","grey80","grey50","black"))
caff.marital <- matrix(c(652, 1537, 598, 242, 36, 46, 38, 21, 218, 327, 106, 67), 	nrow = 3, byrow = TRUE) caff.marital colnames(caff.marital) <- c("0", "1-150", "151-300", ">300") rownames(caff.marital) <- c("Married", "Prev.married", "Single")
barplot(prop.table(t(caff.marital), 2), beside = TRUE, legend.text = colnames(caff.marital), col = c("white", "grey80", "grey50", "black"))
par(mfrow = c(1, 1)) barplot(prop.table(t(caff.marital), 2), 	beside = TRUE, 	legend.text = colnames(caff.marital), 	col = c("white", "grey80", "grey50", "black") )
dotchart(t(caff.marital), lcolor = "black")
dotchart(caff.marital, lcolor = "black")
opar <- par(mfrow=c(2,2), mex = 0.8, mar = c(1,1,2,1))
slices <- c("white","grey80","grey50","black")
opar <- par(mfrow=c(2,2), mex = 0.8, mar = c(1,1,2,1)) slices <- c("white", "grey80", "grey50", "black") pie(caff.marital["Married"], main = "Married", col = slices)
opar <- par(mfrow=c(2,2), mex = 0.8, mar = c(1,1,2,1))
slices <- c("white", "grey80", "grey50", "black")
pie(caff.marital["Married"], main = "Married", col = slices)
caff.marital["Married"]
pie(caff.marital["Married"], main = "Married", col = slices)
colnames(caff.marital) <- c("0", "1-150", "151-300", ">300") rownames(caff.marital) <- c("Married", "Prev.married", "Single")
opar <- par(mfrow=c(2,2), mex = 0.8, mar = c(1,1,2,1)) slices <- c("white", "grey80", "grey50", "black") pie(caff.marital["Married"], main = "Married", col = slices)
caff.marital["Married"]
caff.marital <- matrix(c(652, 1537, 598, 242, 36, 46, 38, 21, 218, 327, 106, 67), 	nrow = 3, byrow = TRUE) caff.marital colnames(caff.marital) <- c("0", "1-150", "151-300", ">300") rownames(caff.marital) <- c("Married", "Prev.married", "Single")
caff.marital <- matrix(c(652, 1537, 598, 242, 36, 46, 38, 21, 218, 327, 106, 67), 	nrow = 3, byrow = TRUE) caff.marital colnames(caff.marital) <- c("0", "1-150", "151-300", ">300") rownames(caff.marital) <- c("Married", "Prev.married", "Single") caff.marital
caff.marital["Married"]
pie(caff.marital["Married",], main = "Married", col = slices)
opar <- par(mfrow=c(2,2), mex = 0.8, mar = c(1,1,2,1)) slices <- c("white", "grey80", "grey50", "black") pie(caff.marital["Married",], main = "Married", col = slices) pie(caff.marital["Prev.Married",], main = "Prev.Married", col = slices) pie(caff.marital["Single",], main = "Single", col = slices) par(opar)
opar <- par(mfrow=c(2,2), mex = 0.8, mar = c(1,1,2,1)) slices <- c("white", "grey80", "grey50", "black") pie(caff.marital["Married",], main = "Married", col = slices) pie(caff.marital["Prev.Married",], main = "Prev.Married", col = slices) pie(caff.marital["Single",], main = "Single", col = slices) par(opar)
caff.marital <- matrix(c(652, 1537, 598, 242, 36, 46, 38, 21, 218, 327, 106, 67), 	nrow = 3, byrow = TRUE) caff.marital colnames(caff.marital) <- c("0", "1-150", "151-300", ">300") rownames(caff.marital) <- c("Married", "Prev.Married", "Single")
opar <- par(mfrow=c(2,2), mex = 0.8, mar = c(1,1,2,1)) slices <- c("white", "grey80", "grey50", "black") pie(caff.marital["Married",], main = "Married", col = slices) pie(caff.marital["Prev.Married",], main = "Prev.Married", col = slices) pie(caff.marital["Single",], main = "Single", col = slices) par(opar)
plot(rnorm(10), type="o")
par(mar= 0.8)
par(mex= 0.8)
plot(rnorm(10), type = "o")
?plot
par(margin = c(1,1,1,1))
par(mar= c(1,1,1,1))
plot(rnorm(10), type = "o")
par(mar= c(2,2,2,2))
plot(rnorm(10), type = "o")
?par
par(ljoin="round")
plot(rnorm(10), type = "o")
par(ljoin="bevel")
plot(rnorm(10), type = "o")
par(lty="twodash")
plot(rnorm(10), type = "o")
par(lwd="2")
plot(rnorm(10), type = "o")
par(mfg="2")
plot(rnorm(10), type = "o")
rm(opar, envir = as.environment(".GlobalEnv"))
par(mfg="2") plot(rnorm(10), type = "o")
# 4.1 # 4.2 par(mfg="2") plot(rnorm(10), type = "o") ?plot ?par
par(mfg="4")
plot(rnorm(10), type = "o")
par(mfg="4")
plot(rnorm(10), type = "o")
par(ljoin="2")
plot(rnorm(10), type = "o")
install.packages("MASS> install.packages("MASS")")
install.packages("MASS")
library(MASS)
library(MASS)
install.packages("MASS")
install.packages("MASS")
library(MASS)
z <- runif(5)
quantile(z,curve(z))
curve(z)
quantile(z,curve(z))
curve(z)
z <- runif(5)
curve(z)
z <- runif(5)
curve(z)
curve(z,0,1)
curve(z,0,1)
curve(z,from = 0, to = 1)
curve(plot,from = 0, to = 1)
curve(plot,z)
quantile(z)
curve(plot(quantile(z), 0, 1))
curve(plot(quantile(z)), 0, 1))
curve(plot(quantile(z)), 0, 1)
quantile(z)
z <- runif(5) quantile(z)
q <- quantile(z)
plot(z,q)
plot(q,z)
x <- 1:5; y <- rep(5,1)
x <- 1:5; y <- rep(5,1); opar <- par(mfrow=c(2,2))
x <- 1:5; y <- rep(5,1); opar <- par(mfrow=c(2,2))
plot(x, y, pch = 15)
x <- 1:5; y <- rep(5,1); opar <- par(mfrow=c(2,2))
plot(x, y, pch = 15)
x <- 1:5; y <- rexp(5,1); opar <- par(mfrow=c(2,2))
plot(x, y, pch = 15)
plot(x, y, type = "b")
plot(x, y, lwd = 3)
plot(x, y, type = "o", col="blue")
x <- 1:5; y <- rexp(5,1); opar <- par(mfrow=c(2,2)) plot(x, y, pch = 15) plot(x, y, type = "b") plot(x, y, lwd = 3) plot(x, y, type = "o", col="blue") par(opar)
plot(rnorm(10), type="o")
plot(rnorm(10), type="o", pch = 21, bg ="white")
plot(rnorm(10), type="o", pch = 21, bg ="white")
par(c(1,1))
par(c(1, 1))
plot(rnorm(10), type="o", pch = 21, bg ="white")
par(mfrow=c(1, 1))
plot(rnorm(10), type="o", pch = 21, bg ="white")
plot(rnorm(10), type="o", pch = 21, bg ="white")
plot(rnorm(10), type="o", pch = 21, bg ="white")
plot(rnorm(10), type="o", pch = 21, bg ="white")
plot(rnorm(10), type="o", pch = 21, bg ="white")
plot(rnorm(10), type="o", pch = 21, bg ="white")
x <- 1:5; y <- rexp(5,1); opar <- par(mfrow=c(2,2)) plot(x, y, pch = 15) plot(x, y, type = "b") plot(x, y, lwd = 3) plot(x, y, type = "o", col="grey40") par(opar)
# 4.1 x <- 1:5; y <- rexp(5,1); opar <- par(mfrow=c(2,2)) plot(x, y, pch = 10) plot(x, y, type = "b") plot(x, y, lwd = 3) plot(x, y, type = "o", col="grey40") par(opar) # 4.2 par(mfrow=c(1, 1)) plot(rnorm(10), type = "o", pch = 21, bg = "white") # 4.3
x1 <- rnorm(20); x2 <- rnorm(10) + 1
x1 <- rnorm(20); x2 <- rnorm(10) + 1
xr <- range(q1$x, q2$y)
q1 <- qqplot(x1, plot.it = F) q2 <- qqplot(x2, plot.it = F) xr <- range(q1$x, q2$y)
q1 <- qqplot(x1, plot.it = F)
q2 <- qqnorm(x2, plot.it = F)
q1 <- qqnorm(x1, plot.it = F)
q2 <- qqnorm(x2, plot.it = F)
xr <- range(q1$x, q2$y)
xr <- range(q1$x, q2$x)
yr <- range(q1$x, q2$y)
yr <- range(q1$x, q2$y)
x1 <- rnorm(20); x2 <- rnorm(10) + 1 q1 <- qqnorm(x1, plot.it = F) q2 <- qqnorm(x2, plot.it = F) xr <- range(q1$x, q2$x) yr <- range(q1$x, q2$y) qqnorm(x1, xlim = xr, ylim = yr) points(q2, col="red")
points(q2, col = "red", type = "l")
qqnorm(x1, xlim = xr, ylim = yr)
points(q2, col = "red", type = "l")
sort(x1); sort(x2)
qqnorm(x1, xlim = xr, ylim = yr)
points(q2, col = "red", type = "l")
sort(x1); sort(x2)
qqnorm(x1, xlim = xr, ylim = yr)
points(q2, col = "red", type = "l")
sort(x1);
sort(x2);
qqnorm(x1, xlim = xr, ylim = yr)
points(q2, col = "red", type = "l")
x1 <- rnorm(20); x2 <- rnorm(10) + 1
sort(x1); sort(x2)
q1 <- qqnorm(x1, plot.it = F)
q2 <- qqnorm(x2, plot.it = F)
xr <- range(q1$x, q2$x)
yr <- range(q1$x, q2$y)
qqnorm(x1, xlim = xr, ylim = yr)
points(q2, col = "red", type = "l")
x1 <- sort( rnorm(20) ); x2 <- sort( rnorm(10) + 1 )
q1 <- qqnorm(x1, plot.it = F)
q2 <- qqnorm(x2, plot.it = F)
xr <- range(q1$x, q2$x)
yr <- range(q1$x, q2$y)
qqnorm(x1, xlim = xr, ylim = yr)
points(q2, col = "red", type = "l")
x1 <- rnorm(20); x2 <- rnorm(10) + 1
x1 <-sort(x1); x2 <-sort(x2)
q1 <- qqnorm(x1, plot.it = F)
q2 <- qqnorm(x2, plot.it = F)
xr <- range(q1$x, q2$x)
yr <- range(q1$x, q2$y)
qqnorm(x1, xlim = xr, ylim = yr)
points(q2, col = "red", type = "l")
install.packages("MASS")
library(MASS)
hist(react)
library(ISwR)
hist(react)
truehist(react, h = 1, x0 = .5)
hist(react)
truehist(react, h = 1, x0 = .5)
hist(react)
truehist(react, h = 1, x0 = .5)
hist(react)
truehist(react, h = 1, x0 = .5)
z <- runif(5) curve(quantile(z,x), from = 0, to = 1 )
z <- runif(5) curve(quantile(z, x), from = 0, to = 1)
z <- runif(5) curve(quantile(z, x), from = 0, to = 1)
z <- runif(5) curve(quantile(z, x), from = 0, to = 1)
z <- runif(5) curve(quantile(z, x), from = 0, to = 1)
z <- runif(5) curve(quantile(z, x), from = 0, to = 1)
z <- runif(5) curve(quantile(z, x), from = 0, to = 1)
library(ISwR) library(MASS) # 4.1 x <- 1:5; y <- rexp(5,1); opar <- par(mfrow=c(2,2)) plot(x, y, pch = 10) plot(x, y, type = "b") plot(x, y, lwd = 3) plot(x, y, type = "o", col="grey40") par(opar) # 4.2 par(mfrow=c(1, 1)) plot(rnorm(10), type = "o", pch = 21, bg = "white") # 4.3 x1 <- rnorm(20); x2 <- rnorm(10) + 1 x1 <-sort(x1); x2 <-sort(x2) q1 <- qqnorm(x1, plot.it = F) q2 <- qqnorm(x2, plot.it = F) xr <- range(q1$x, q2$x) yr <- range(q1$x, q2$y) qqnorm(x1, xlim = xr, ylim = yr) points(q2, col = "red", type = "l") # 4.4 hist(react) truehist(react, h = 1, x0 = .5) # 4.5 z <- runif(5) curve(quantile(z, x), from = 0, to = 1)
install.packages("mosaicData")
library(mosaicData)
attach(CPS85)
head(CPS85)
install.packages("pdftools")
install.packages("tabulizer")
install.packages("mosiacData")
install.packages("mosaicData")
install.packages("tabulizer")
install.packages("rpart")
library(rpart)
library(rpart)
rpart
load(rpart)
library(rpart)
R.home(> R.home())
R.home
R.home()
